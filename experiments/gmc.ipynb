{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\anaconda\\envs\\proplace\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n",
      "[WARNING] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      " [lazy_loader.py _load]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import check_random_state\n",
    "import pandas as pd\n",
    "from proplace.clfutils import HiddenPrints\n",
    "import proplace\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# load dataset utils\n",
    "dataset = proplace.InnDataSet(\"give_me_some_credit\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Epoch 0: train loss: 0.7437196969985962\n",
      "Epoch 0: train loss: 0.7191342711448669\n",
      "Epoch 0: train loss: 0.69671231508255\n",
      "Epoch 0: train loss: 0.6771828532218933\n",
      "Epoch 0: train loss: 0.6518386602401733\n",
      "Epoch 0: train loss: 0.6321981549263\n",
      "Epoch 0: train loss: 0.6206355690956116\n",
      "Epoch 0: train loss: 0.5932130217552185\n",
      "Epoch 0: train loss: 0.5650101900100708\n",
      "Epoch 0: train loss: 0.5645900964736938\n",
      "Epoch 0: train loss: 0.5264307856559753\n",
      "Epoch 0: train loss: 0.4796767234802246\n",
      "Epoch 0: train loss: 0.5112673044204712\n",
      "Epoch 0: train loss: 0.4141991138458252\n",
      "Epoch 0: train loss: 0.3740864396095276\n",
      "Epoch 0: train loss: 0.3177039623260498\n",
      "Epoch 0: train loss: 0.41362762451171875\n",
      "Epoch 0: train loss: 0.3273945152759552\n",
      "Epoch 0: train loss: 0.21375000476837158\n",
      "Epoch 0: train loss: 0.26735934615135193\n",
      "Epoch 0: train loss: 0.21889716386795044\n",
      "Epoch 0: train loss: 0.2784709334373474\n",
      "Epoch 0: train loss: 0.31628987193107605\n",
      "Epoch 0: train loss: 0.23128177225589752\n",
      "Epoch 0: train loss: 0.22920842468738556\n",
      "Epoch 0: train loss: 0.04145393893122673\n",
      "Epoch 0: train loss: 0.11094503849744797\n",
      "Epoch 0: train loss: 0.37824514508247375\n",
      "Epoch 0: train loss: 0.4962877035140991\n",
      "Epoch 0: train loss: 0.027096573263406754\n",
      "Epoch 0: train loss: 0.24607819318771362\n",
      "Epoch 0: train loss: 0.1536533385515213\n",
      "Epoch 0: train loss: 0.24555234611034393\n",
      "Epoch 0: train loss: 0.2470105141401291\n",
      "Epoch 0: train loss: 0.1613471657037735\n",
      "Epoch 0: train loss: 0.34189772605895996\n",
      "Epoch 0: train loss: 0.11004205793142319\n",
      "Epoch 0: train loss: 0.24127277731895447\n",
      "Epoch 0: train loss: 0.1310383528470993\n",
      "Epoch 0: train loss: 0.20649489760398865\n",
      "Epoch 0: train loss: 0.13753922283649445\n",
      "Epoch 0: train loss: 0.5101615190505981\n",
      "Epoch 0: train loss: 0.13320258259773254\n",
      "Epoch 0: train loss: 0.06412489712238312\n",
      "Epoch 0: train loss: 0.06364189088344574\n",
      "Epoch 0: train loss: 0.2126167267560959\n",
      "Epoch 0: train loss: 0.31335529685020447\n",
      "Epoch 0: train loss: 0.3782084882259369\n",
      "Epoch 0: train loss: 0.22983647882938385\n",
      "Epoch 0: train loss: 0.12770849466323853\n",
      "Epoch 0: train loss: 0.13853640854358673\n",
      "Epoch 0: train loss: 0.26387035846710205\n",
      "Epoch 0: train loss: 0.2226056009531021\n",
      "Epoch 0: train loss: 0.13763876259326935\n",
      "Epoch 0: train loss: 0.2124817967414856\n",
      "Epoch 0: train loss: 0.4505608379840851\n",
      "Epoch 0: train loss: 0.1305055320262909\n",
      "Epoch 0: train loss: 0.1265924572944641\n",
      "Epoch 0: train loss: 0.25275227427482605\n",
      "Epoch 0: train loss: 0.28736627101898193\n",
      "Epoch 0: train loss: 0.1519402712583542\n",
      "Epoch 0: train loss: 0.16880261898040771\n",
      "Epoch 0: train loss: 0.3106209337711334\n",
      "Epoch 0: train loss: 0.13762840628623962\n",
      "Epoch 0: train loss: 0.20068129897117615\n",
      "Epoch 0: train loss: 0.07121171057224274\n",
      "Epoch 0: train loss: 0.2858026623725891\n",
      "Epoch 0: train loss: 0.1985531896352768\n",
      "Epoch 0: train loss: 0.4024449288845062\n",
      "Epoch 0: train loss: 0.32548657059669495\n",
      "Epoch 0: train loss: 0.3757096230983734\n",
      "Epoch 0: train loss: 0.19619815051555634\n",
      "Epoch 0: train loss: 0.2229027897119522\n",
      "Epoch 0: train loss: 0.1841236650943756\n",
      "Epoch 0: train loss: 0.4221162497997284\n",
      "Epoch 0: train loss: 0.12380518764257431\n",
      "Epoch 0: train loss: 0.14372898638248444\n",
      "Epoch 0: train loss: 0.184051051735878\n",
      "Epoch 0: train loss: 0.31825119256973267\n",
      "Epoch 0: train loss: 0.1536470204591751\n",
      "Epoch 0: train loss: 0.14100994169712067\n",
      "Epoch 0: train loss: 0.2170650213956833\n",
      "Epoch 0: train loss: 0.11566991358995438\n",
      "Epoch 0: train loss: 0.2478179633617401\n",
      "Epoch 0: train loss: 0.25719258189201355\n",
      "Epoch 0: train loss: 0.15578852593898773\n",
      "Epoch 0: train loss: 0.23440523445606232\n",
      "Epoch 0: train loss: 0.04553033784031868\n",
      "Epoch 0: train loss: 0.06840410828590393\n",
      "Epoch 0: train loss: 0.04168334975838661\n",
      "Epoch 0: train loss: 0.163473978638649\n",
      "Epoch 0: train loss: 0.10067487508058548\n",
      "Epoch 0: train loss: 0.031665388494729996\n",
      "Epoch 0: train loss: 0.4122794270515442\n",
      "Epoch 0: train loss: 0.15231174230575562\n",
      "Epoch 0: train loss: 0.4438868761062622\n",
      "Epoch 0: train loss: 0.24499820172786713\n",
      "Epoch 0: train loss: 0.15918554365634918\n",
      "Epoch 0: train loss: 0.28924068808555603\n",
      "Epoch 0: train loss: 0.17584724724292755\n",
      "Epoch 0: train loss: 0.2600780129432678\n",
      "Epoch 0: train loss: 0.040671005845069885\n",
      "Epoch 0: train loss: 0.22323191165924072\n",
      "Epoch 0: train loss: 0.0938040241599083\n",
      "Epoch 0: train loss: 0.2533218264579773\n",
      "Epoch 0: train loss: 0.32924097776412964\n",
      "Epoch 0: train loss: 0.19812962412834167\n",
      "Epoch 0: train loss: 0.16787105798721313\n",
      "Epoch 0: train loss: 0.2763492465019226\n",
      "Epoch 0: train loss: 0.4991319477558136\n",
      "Epoch 0: train loss: 0.267457515001297\n",
      "Epoch 0: train loss: 0.21843945980072021\n",
      "Epoch 0: train loss: 0.16808177530765533\n",
      "Epoch 0: train loss: 0.2888176143169403\n",
      "Epoch 0: train loss: 0.14665089547634125\n",
      "Epoch 0: train loss: 0.21803446114063263\n",
      "Epoch 0: train loss: 0.18766021728515625\n",
      "Epoch 0: train loss: 0.33933117985725403\n",
      "Epoch 0: train loss: 0.20695650577545166\n",
      "Epoch 0: train loss: 0.14167839288711548\n",
      "Epoch 0: train loss: 0.2753032445907593\n",
      "Epoch 0: train loss: 0.16578400135040283\n",
      "Epoch 0: train loss: 0.19903793931007385\n",
      "Epoch 0: train loss: 0.20017370581626892\n",
      "Epoch 0: train loss: 0.4422585368156433\n",
      "Epoch 0: train loss: 0.2598145008087158\n",
      "Epoch 0: train loss: 0.15026457607746124\n",
      "Epoch 0: train loss: 0.07959067821502686\n",
      "Epoch 0: train loss: 0.17130349576473236\n",
      "Epoch 0: train loss: 0.1667557656764984\n",
      "Epoch 0: train loss: 0.07678930461406708\n",
      "Epoch 0: train loss: 0.28537312150001526\n",
      "Epoch 0: train loss: 0.3232705891132355\n",
      "Epoch 0: train loss: 0.2254694700241089\n",
      "Epoch 0: train loss: 0.20497435331344604\n",
      "Epoch 0: train loss: 0.13847120106220245\n",
      "Epoch 0: train loss: 0.09754165261983871\n",
      "Epoch 0: train loss: 0.262558251619339\n",
      "Epoch 0: train loss: 0.1369943618774414\n",
      "Epoch 0: train loss: 0.11167971789836884\n",
      "Epoch 0: train loss: 0.17371182143688202\n",
      "Epoch 0: train loss: 0.19506913423538208\n",
      "Epoch 0: train loss: 0.18626517057418823\n",
      "Epoch 0: train loss: 0.06721996515989304\n",
      "Epoch 0: train loss: 0.08694645017385483\n",
      "Epoch 0: train loss: 0.4233253300189972\n",
      "Epoch 0: train loss: 0.4248800575733185\n",
      "Epoch 0: train loss: 0.03143785148859024\n",
      "Epoch 0: train loss: 0.09209004044532776\n",
      "Epoch 0: train loss: 0.04153244569897652\n",
      "Epoch 0: train loss: 0.30562782287597656\n",
      "Epoch 0: train loss: 0.03899192810058594\n",
      "Epoch 0: train loss: 0.30255234241485596\n",
      "Epoch 0: train loss: 0.1889720857143402\n",
      "Epoch 0: train loss: 0.17273689806461334\n",
      "Epoch 0: train loss: 0.2640683054924011\n",
      "Epoch 0: train loss: 0.15941190719604492\n",
      "Epoch 0: train loss: 0.13829223811626434\n",
      "Epoch 0: train loss: 0.051121149212121964\n",
      "Epoch 0: train loss: 0.37028345465660095\n",
      "Epoch 0: train loss: 0.34831827878952026\n",
      "Epoch 0: train loss: 0.15545813739299774\n",
      "Epoch 0: train loss: 0.08365713804960251\n",
      "Epoch 0: train loss: 0.19043448567390442\n",
      "Epoch 0: train loss: 0.11604437232017517\n",
      "Epoch 0: train loss: 0.17729683220386505\n",
      "Epoch 0: train loss: 0.1596296727657318\n",
      "Epoch 0: train loss: 0.2332553267478943\n",
      "Epoch 0: train loss: 0.1691732257604599\n",
      "Epoch 0: train loss: 0.09037307649850845\n",
      "Epoch 0: train loss: 0.47702401876449585\n",
      "Epoch 0: train loss: 0.14730465412139893\n",
      "Epoch 0: train loss: 0.06956283748149872\n",
      "Epoch 0: train loss: 0.07614526897668839\n",
      "Epoch 0: train loss: 0.33377930521965027\n",
      "Epoch 0: train loss: 0.23927927017211914\n",
      "Epoch 0: train loss: 0.04117203503847122\n",
      "Epoch 0: train loss: 0.212080717086792\n",
      "Epoch 0: train loss: 0.23407894372940063\n",
      "Epoch 0: train loss: 0.27424943447113037\n",
      "Epoch 0: train loss: 0.29327505826950073\n",
      "Epoch 0: train loss: 0.16624657809734344\n",
      "Epoch 0: train loss: 0.08581429719924927\n",
      "Epoch 0: train loss: 0.29172420501708984\n",
      "Epoch 0: train loss: 0.44371646642684937\n",
      "Epoch 0: train loss: 0.06564414501190186\n",
      "Epoch 0: train loss: 0.26124969124794006\n",
      "Epoch 0: train loss: 0.1490866243839264\n",
      "Epoch 0: train loss: 0.2925056219100952\n",
      "Epoch 0: train loss: 0.233382448554039\n",
      "Epoch 0: train loss: 0.15273429453372955\n",
      "Epoch 0: train loss: 0.1418725997209549\n",
      "Epoch 0: train loss: 0.07191764563322067\n",
      "Epoch 0: train loss: 0.07550205290317535\n",
      "Epoch 0: train loss: 0.382630854845047\n",
      "Epoch 0: train loss: 0.09149382263422012\n",
      "Epoch 0: train loss: 0.14300031960010529\n",
      "Epoch 0: train loss: 0.19930677115917206\n",
      "Epoch 0: train loss: 0.4492461383342743\n",
      "Epoch 0: train loss: 0.375973641872406\n",
      "Epoch 0: train loss: 0.08687878400087357\n",
      "Epoch 0: train loss: 0.11770442128181458\n",
      "Epoch 0: train loss: 0.12292228639125824\n",
      "Epoch 0: train loss: 0.35694682598114014\n",
      "Epoch 0: train loss: 0.2132522612810135\n",
      "Epoch 0: train loss: 0.14475210011005402\n",
      "Epoch 0: train loss: 0.22176498174667358\n",
      "Epoch 0: train loss: 0.13592389225959778\n",
      "Epoch 0: train loss: 0.2502802312374115\n",
      "Epoch 0: train loss: 0.28151407837867737\n",
      "Epoch 0: train loss: 0.34886425733566284\n",
      "Epoch 0: train loss: 0.1287461370229721\n",
      "Epoch 0: train loss: 0.057537056505680084\n",
      "Epoch 0: train loss: 0.27128151059150696\n",
      "Epoch 0: train loss: 0.1777857542037964\n",
      "Epoch 0: train loss: 0.06607361137866974\n",
      "Epoch 0: train loss: 0.30631908774375916\n",
      "Epoch 0: train loss: 0.19077467918395996\n",
      "Epoch 0: train loss: 0.17541535198688507\n",
      "Epoch 0: train loss: 0.20710264146327972\n",
      "Epoch 0: train loss: 0.12466790527105331\n",
      "Epoch 0: train loss: 0.18121445178985596\n",
      "Epoch 0: train loss: 0.05600174516439438\n",
      "Epoch 0: train loss: 0.3485278785228729\n",
      "Epoch 0: train loss: 0.12031015008687973\n",
      "Epoch 0: train loss: 0.12880559265613556\n",
      "Epoch 0: train loss: 0.23788388073444366\n",
      "Epoch 0: train loss: 0.16786925494670868\n",
      "Epoch 0: train loss: 0.1354454904794693\n",
      "Epoch 0: train loss: 0.440168559551239\n",
      "Epoch 0: train loss: 0.2501194477081299\n",
      "Epoch 0: train loss: 0.15528452396392822\n",
      "Epoch 0: train loss: 0.16500388085842133\n",
      "Epoch 0: train loss: 0.20930896699428558\n",
      "Epoch 0: train loss: 0.09399161487817764\n",
      "Epoch 0: train loss: 0.10499566793441772\n",
      "Epoch 0: train loss: 0.5770008563995361\n",
      "Epoch 0: train loss: 0.3083229660987854\n",
      "Epoch 0: train loss: 0.28730952739715576\n",
      "Epoch 0: train loss: 0.22527986764907837\n",
      "Epoch 0: train loss: 0.1498943418264389\n",
      "Epoch 0: train loss: 0.1790456920862198\n",
      "Epoch 0: train loss: 0.3205239772796631\n",
      "Epoch 0: train loss: 0.16531093418598175\n",
      "Epoch 0: train loss: 0.23635436594486237\n",
      "Epoch 0: train loss: 0.2236061990261078\n",
      "Epoch 0: train loss: 0.10099687427282333\n",
      "Epoch 0: train loss: 0.19834044575691223\n",
      "Epoch 0: train loss: 0.5073568820953369\n",
      "Epoch 0: train loss: 0.5188949108123779\n",
      "Epoch 0: train loss: 0.5140674710273743\n",
      "Epoch 0: train loss: 0.28391119837760925\n",
      "Epoch 0: train loss: 0.032851818948984146\n",
      "Epoch 0: train loss: 0.16224481165409088\n",
      "Epoch 0: train loss: 0.2630215883255005\n",
      "Epoch 0: train loss: 0.06934669613838196\n",
      "Epoch 0: train loss: 0.18639089167118073\n",
      "Epoch 0: train loss: 0.050647567957639694\n",
      "Epoch 0: train loss: 0.2859809696674347\n",
      "Epoch 0: train loss: 0.2369334101676941\n",
      "Epoch 0: train loss: 0.19465628266334534\n",
      "Epoch 0: train loss: 0.23075611889362335\n",
      "Epoch 0: train loss: 0.3161325454711914\n",
      "Epoch 0: train loss: 0.05345529317855835\n",
      "Epoch 0: train loss: 0.1370936930179596\n",
      "Epoch 0: train loss: 0.22926153242588043\n",
      "Epoch 0: train loss: 0.14561575651168823\n",
      "Epoch 0: train loss: 0.2251843512058258\n",
      "Epoch 0: train loss: 0.24422132968902588\n",
      "Epoch 0: train loss: 0.12991875410079956\n",
      "Epoch 0: train loss: 0.30628806352615356\n",
      "Epoch 0: train loss: 0.05345001071691513\n",
      "Epoch 0: train loss: 0.20096330344676971\n",
      "Epoch 0: train loss: 0.2865411043167114\n",
      "Epoch 0: train loss: 0.1931709200143814\n",
      "Epoch 0: train loss: 0.29541054368019104\n",
      "Epoch 0: train loss: 0.07500491291284561\n",
      "Epoch 0: train loss: 0.12335147708654404\n",
      "Epoch 0: train loss: 0.2930602729320526\n",
      "Epoch 0: train loss: 0.27769407629966736\n",
      "Epoch 0: train loss: 0.14871518313884735\n",
      "Epoch 0: train loss: 0.26946502923965454\n",
      "Epoch 0: train loss: 0.27267298102378845\n",
      "Epoch 0: train loss: 0.4013729393482208\n",
      "Epoch 0: train loss: 0.08428256213665009\n",
      "Epoch 0: train loss: 0.25995221734046936\n",
      "Epoch 0: train loss: 0.16314660012722015\n",
      "Epoch 0: train loss: 0.08041698485612869\n",
      "Epoch 0: train loss: 0.38627079129219055\n",
      "Epoch 0: train loss: 0.17381909489631653\n",
      "Epoch 0: train loss: 0.1288185715675354\n",
      "Epoch 0: train loss: 0.2230667620897293\n",
      "Epoch 0: train loss: 0.08475537598133087\n",
      "Epoch 0: train loss: 0.7490354776382446\n",
      "Epoch 0: train loss: 0.17783570289611816\n",
      "Epoch 0: train loss: 0.16927409172058105\n",
      "Epoch 0: train loss: 0.20058417320251465\n",
      "Epoch 0: train loss: 0.11490710824728012\n",
      "Epoch 0: train loss: 0.24413256347179413\n",
      "Epoch 0: train loss: 0.19672290980815887\n",
      "Epoch 0: train loss: 0.0812055692076683\n",
      "Epoch 0: train loss: 0.1539762318134308\n",
      "Epoch 0: train loss: 0.17450951039791107\n",
      "Epoch 0: train loss: 0.17291788756847382\n",
      "Epoch 0: train loss: 0.34517040848731995\n",
      "Epoch 0: train loss: 0.23272134363651276\n",
      "Epoch 0: train loss: 0.24804335832595825\n",
      "Epoch 0: train loss: 0.47507163882255554\n",
      "Epoch 0: train loss: 0.2103147953748703\n",
      "Epoch 0: train loss: 0.19935978949069977\n",
      "Epoch 0: train loss: 0.16010212898254395\n",
      "Epoch 0: train loss: 0.17901396751403809\n",
      "Epoch 0: train loss: 0.28284400701522827\n",
      "Epoch 0: train loss: 0.2830713093280792\n",
      "Epoch 0: train loss: 0.2822718322277069\n",
      "Epoch 0: train loss: 0.15372779965400696\n",
      "Epoch 0: train loss: 0.10206480324268341\n",
      "Epoch 0: train loss: 0.4327299892902374\n",
      "Epoch 0: train loss: 0.12785500288009644\n",
      "Epoch 0: train loss: 0.3408011496067047\n",
      "Epoch 0: train loss: 0.2577151954174042\n",
      "Epoch 0: train loss: 0.12260725349187851\n",
      "Epoch 0: train loss: 0.24592503905296326\n",
      "Epoch 0: train loss: 0.2610096037387848\n",
      "Epoch 0: train loss: 0.2903248965740204\n",
      "Epoch 0: train loss: 0.5018457770347595\n",
      "Epoch 0: train loss: 0.24787761270999908\n",
      "Epoch 0: train loss: 0.23514501750469208\n",
      "Epoch 0: train loss: 0.2722747027873993\n",
      "Epoch 0: train loss: 0.06434044241905212\n",
      "Epoch 0: train loss: 0.21471437811851501\n",
      "Epoch 0: train loss: 0.15573850274085999\n",
      "Epoch 0: train loss: 0.30082187056541443\n",
      "Epoch 0: train loss: 0.17298203706741333\n",
      "Epoch 0: train loss: 0.07413458824157715\n",
      "Epoch 0: train loss: 0.17619889974594116\n",
      "Epoch 0: train loss: 0.1747504472732544\n",
      "Epoch 0: train loss: 0.4191102981567383\n",
      "Epoch 0: train loss: 0.2634250223636627\n",
      "Epoch 0: train loss: 0.34706929326057434\n",
      "Epoch 0: train loss: 0.2959652841091156\n",
      "Epoch 0: train loss: 0.13990525901317596\n",
      "Epoch 0: train loss: 0.07140491902828217\n",
      "Epoch 0: train loss: 0.291841059923172\n",
      "Epoch 0: train loss: 0.1497032344341278\n",
      "Epoch 0: train loss: 0.05976253002882004\n",
      "Epoch 0: train loss: 0.31579500436782837\n",
      "Epoch 0: train loss: 0.21326172351837158\n",
      "Epoch 0: train loss: 0.17349788546562195\n",
      "Epoch 0: train loss: 0.22648218274116516\n",
      "Epoch 0: train loss: 0.39080509543418884\n",
      "Epoch 0: train loss: 0.21241146326065063\n",
      "Epoch 0: train loss: 0.28541502356529236\n",
      "Epoch 0: train loss: 0.5121946334838867\n",
      "Epoch 0: train loss: 0.2064930498600006\n",
      "Epoch 0: train loss: 0.141173854470253\n",
      "Epoch 0: train loss: 0.288394570350647\n",
      "Epoch 0: train loss: 0.31636670231819153\n",
      "Epoch 0: train loss: 0.12954506278038025\n",
      "Epoch 0: train loss: 0.189750537276268\n",
      "Epoch 0: train loss: 0.4649873375892639\n",
      "Epoch 0: train loss: 0.10225211828947067\n",
      "Epoch 0: train loss: 0.13966624438762665\n",
      "Epoch 0: train loss: 0.06665372848510742\n",
      "Epoch 0: train loss: 0.12584242224693298\n",
      "Epoch 0: train loss: 0.19364112615585327\n",
      "Epoch 0: train loss: 0.3040139079093933\n",
      "Epoch 0: train loss: 0.18618136644363403\n",
      "Epoch 0: train loss: 0.141799196600914\n",
      "Epoch 0: train loss: 0.4153537452220917\n",
      "Epoch 0: train loss: 0.29117223620414734\n",
      "Epoch 0: train loss: 0.15548411011695862\n",
      "Epoch 0: train loss: 0.11815690994262695\n",
      "Epoch 0: train loss: 0.21055768430233002\n",
      "Epoch 0: train loss: 0.15718311071395874\n",
      "Epoch 0: train loss: 0.3104325234889984\n",
      "Epoch 0: train loss: 0.09602757543325424\n",
      "Epoch 0: train loss: 0.16811953485012054\n",
      "Epoch 0: train loss: 0.17565152049064636\n",
      "Epoch 0: train loss: 0.08134469389915466\n",
      "Epoch 0: train loss: 0.16184446215629578\n",
      "Epoch 0: train loss: 0.12240701913833618\n",
      "Epoch 0: train loss: 0.18791747093200684\n",
      "Epoch 0: train loss: 0.04459628462791443\n",
      "Epoch 0: train loss: 0.12689587473869324\n",
      "Epoch 0: train loss: 0.24364566802978516\n",
      "Epoch 0: train loss: 0.2796196937561035\n",
      "Epoch 0: train loss: 0.15927135944366455\n",
      "Epoch 0: train loss: 0.06725955009460449\n",
      "Epoch 0: train loss: 0.32190805673599243\n",
      "Epoch 0: train loss: 0.130001962184906\n",
      "Epoch 0: train loss: 0.16182036697864532\n",
      "Epoch 0: train loss: 0.03369078040122986\n",
      "Epoch 0: train loss: 0.2428257316350937\n",
      "Epoch 0: train loss: 0.14459306001663208\n",
      "Epoch 0: train loss: 0.1504230797290802\n",
      "Epoch 0: train loss: 0.16139692068099976\n",
      "Epoch 0: train loss: 0.1838729828596115\n",
      "Epoch 0: train loss: 0.05631153658032417\n",
      "Epoch 0: train loss: 0.2648123502731323\n",
      "Epoch 0: train loss: 0.15752246975898743\n",
      "Epoch 0: train loss: 0.04520728439092636\n",
      "Epoch 0: train loss: 0.3126925230026245\n",
      "Epoch 0: train loss: 0.041265975683927536\n",
      "Epoch 0: train loss: 0.05275378376245499\n",
      "Epoch 0: train loss: 0.26100078225135803\n",
      "Epoch 0: train loss: 0.05167579650878906\n",
      "Epoch 0: train loss: 0.18973644077777863\n",
      "Epoch 0: train loss: 0.2804225981235504\n",
      "Epoch 0: train loss: 0.1786653846502304\n",
      "Epoch 0: train loss: 0.13575829565525055\n",
      "Epoch 0: train loss: 0.3028530776500702\n",
      "Epoch 0: train loss: 0.5704911351203918\n",
      "Epoch 0: train loss: 0.23335343599319458\n",
      "Epoch 0: train loss: 0.16566120088100433\n",
      "Epoch 0: train loss: 0.18540124595165253\n",
      "Epoch 0: train loss: 0.10441212356090546\n",
      "Epoch 0: train loss: 0.25320905447006226\n",
      "Epoch 0: train loss: 0.1074560359120369\n",
      "Epoch 0: train loss: 0.10878545045852661\n",
      "Epoch 0: train loss: 0.09676557779312134\n",
      "Epoch 0: train loss: 0.16498485207557678\n",
      "Epoch 0: train loss: 0.18190084397792816\n",
      "Epoch 0: train loss: 0.21654920279979706\n",
      "Epoch 0: train loss: 0.27207162976264954\n",
      "Epoch 0: train loss: 0.4938983619213104\n",
      "Epoch 0: train loss: 0.3343273103237152\n",
      "Epoch 0: train loss: 0.1102805808186531\n",
      "Epoch 0: train loss: 0.19519762694835663\n",
      "Epoch 0: train loss: 0.19278660416603088\n",
      "Epoch 0: train loss: 0.21909569203853607\n",
      "Epoch 0: train loss: 0.3594958782196045\n",
      "Epoch 0: train loss: 0.2080100029706955\n",
      "Epoch 0: train loss: 0.16752058267593384\n",
      "Epoch 0: train loss: 0.18901817500591278\n",
      "Epoch 0: train loss: 0.12394925206899643\n",
      "Epoch 0: train loss: 0.19215846061706543\n",
      "Epoch 0: train loss: 0.20595736801624298\n",
      "Epoch 0: train loss: 0.1270495057106018\n",
      "Epoch 0: train loss: 0.24221888184547424\n",
      "Epoch 0: train loss: 0.05177392065525055\n",
      "Epoch 0: train loss: 0.29281190037727356\n",
      "Epoch 0: train loss: 0.0684475228190422\n",
      "Epoch 0: train loss: 0.10337596386671066\n",
      "Epoch 0: train loss: 0.1819373518228531\n",
      "Epoch 0: train loss: 0.188127338886261\n",
      "Epoch 0: train loss: 0.05043061077594757\n",
      "Epoch 0: train loss: 0.20865648984909058\n",
      "Epoch 0: train loss: 0.4761742055416107\n",
      "Epoch 0: train loss: 0.05296505615115166\n",
      "Epoch 0: train loss: 0.18988092243671417\n",
      "Epoch 0: train loss: 0.042064812034368515\n",
      "Epoch 0: train loss: 0.14075253903865814\n",
      "Epoch 0: train loss: 0.18043281137943268\n",
      "Epoch 0: train loss: 0.09765919297933578\n",
      "Epoch 0: train loss: 0.34294450283050537\n",
      "Epoch 0: train loss: 0.3057691752910614\n",
      "Epoch 0: train loss: 0.13709421455860138\n",
      "Epoch 0: train loss: 0.2863285541534424\n",
      "Epoch 0: train loss: 0.2888939082622528\n",
      "Epoch 0: train loss: 0.09848996996879578\n",
      "Epoch 0: train loss: 0.29955774545669556\n",
      "Epoch 0: train loss: 0.12090162932872772\n",
      "Epoch 0: train loss: 0.18546253442764282\n",
      "Epoch 0: train loss: 0.15968744456768036\n",
      "Epoch 0: train loss: 0.06972657144069672\n",
      "Epoch 0: train loss: 0.286750465631485\n",
      "Epoch 0: train loss: 0.19475257396697998\n",
      "Epoch 0: train loss: 0.17840835452079773\n",
      "Epoch 0: train loss: 0.1639804095029831\n",
      "Epoch 0: train loss: 0.32320067286491394\n",
      "Epoch 0: train loss: 0.1056891456246376\n",
      "Epoch 0: train loss: 0.16122694313526154\n",
      "Epoch 0: train loss: 0.2180338054895401\n",
      "Epoch 0: train loss: 0.04807405546307564\n",
      "Epoch 0: train loss: 0.11132615804672241\n",
      "Epoch 0: train loss: 0.1640268862247467\n",
      "Epoch 0: train loss: 0.05528663843870163\n",
      "Epoch 0: train loss: 0.3301399052143097\n",
      "Epoch 0: train loss: 0.3469574451446533\n",
      "Epoch 0: train loss: 0.0964687243103981\n",
      "Epoch 0: train loss: 0.12344279140233994\n",
      "Epoch 0: train loss: 0.342678427696228\n",
      "Epoch 0: train loss: 0.21907398104667664\n",
      "Epoch 0: train loss: 0.31694528460502625\n",
      "Epoch 0: train loss: 0.32733121514320374\n",
      "Epoch 0: train loss: 0.18726713955402374\n",
      "Epoch 0: train loss: 0.18906962871551514\n",
      "Epoch 0: train loss: 0.14933085441589355\n",
      "Epoch 0: train loss: 0.19341647624969482\n",
      "Epoch 0: train loss: 0.11162807047367096\n",
      "Epoch 0: train loss: 0.10834404081106186\n",
      "Epoch 0: train loss: 0.15097016096115112\n",
      "Epoch 0: train loss: 0.22056598961353302\n",
      "Epoch 0: train loss: 0.11847880482673645\n",
      "Epoch 0: train loss: 0.08131065219640732\n",
      "Epoch 0: train loss: 0.18030883371829987\n",
      "Epoch 0: train loss: 0.6583952307701111\n",
      "Epoch 0: train loss: 0.27389922738075256\n",
      "Epoch 0: train loss: 0.2094079703092575\n",
      "Epoch 0: train loss: 0.18087168037891388\n",
      "Epoch 0: train loss: 0.03886312618851662\n",
      "Epoch 0: train loss: 0.12926948070526123\n",
      "Epoch 0: train loss: 0.11169007420539856\n",
      "Epoch 0: train loss: 0.16415005922317505\n",
      "Epoch 0: train loss: 0.1915697604417801\n",
      "Epoch 0: train loss: 0.2262265980243683\n",
      "Epoch 0: train loss: 0.10737773776054382\n",
      "Epoch 0: train loss: 0.17049333453178406\n",
      "Epoch 0: train loss: 0.28616148233413696\n",
      "Epoch 0: train loss: 0.047757428139448166\n",
      "Epoch 0: train loss: 0.13862599432468414\n",
      "Epoch 0: train loss: 0.09127978980541229\n",
      "Epoch 0: train loss: 0.32908353209495544\n",
      "Epoch 0: train loss: 0.047078415751457214\n",
      "Epoch 0: train loss: 0.2388973981142044\n",
      "Epoch 0: train loss: 0.13713409006595612\n",
      "Epoch 0: train loss: 0.2825191020965576\n",
      "Epoch 0: train loss: 0.37670034170150757\n",
      "Epoch 0: train loss: 0.15375590324401855\n",
      "Epoch 0: train loss: 0.13422946631908417\n",
      "Epoch 0: train loss: 0.08408655226230621\n",
      "Epoch 0: train loss: 0.28017690777778625\n",
      "Epoch 0: train loss: 0.21680030226707458\n",
      "Epoch 0: train loss: 0.08861515671014786\n",
      "Epoch 0: train loss: 0.1399468183517456\n",
      "Epoch 0: train loss: 0.16325190663337708\n",
      "Epoch 0: train loss: 0.35469475388526917\n",
      "Epoch 0: train loss: 0.24663935601711273\n",
      "Epoch 0: train loss: 0.24608300626277924\n",
      "Epoch 0: train loss: 0.17245449125766754\n",
      "Epoch 0: train loss: 0.2026805728673935\n",
      "Epoch 0: train loss: 0.21898242831230164\n",
      "Epoch 0: train loss: 0.26306331157684326\n",
      "Epoch 0: train loss: 0.11299735307693481\n",
      "Epoch 0: train loss: 0.16532953083515167\n",
      "Epoch 0: train loss: 0.11528590321540833\n",
      "Epoch 0: train loss: 0.10110923647880554\n",
      "Epoch 0: train loss: 0.14519470930099487\n",
      "Epoch 0: train loss: 0.22680430114269257\n",
      "Epoch 0: train loss: 0.2831270396709442\n",
      "Epoch 0: train loss: 0.3148983418941498\n",
      "Epoch 0: train loss: 0.3692716658115387\n",
      "Epoch 0: train loss: 0.16970697045326233\n",
      "Epoch 0: train loss: 0.09849007427692413\n",
      "Epoch 0: train loss: 0.25743716955184937\n",
      "Epoch 0: train loss: 0.12675632536411285\n",
      "Epoch 0: train loss: 0.13878341019153595\n",
      "Epoch 0: train loss: 0.04994753748178482\n",
      "Epoch 0: train loss: 0.2919990122318268\n",
      "Epoch 0: train loss: 0.14001162350177765\n",
      "Epoch 0: train loss: 0.226034477353096\n",
      "Epoch 0: train loss: 0.17668132483959198\n",
      "Epoch 0: train loss: 0.3739563822746277\n",
      "Epoch 0: train loss: 0.2785981595516205\n",
      "Epoch 0: train loss: 0.1361723393201828\n",
      "Epoch 0: train loss: 0.09137781709432602\n",
      "Epoch 0: train loss: 0.30568671226501465\n",
      "Epoch 0: train loss: 0.08863645046949387\n",
      "Epoch 0: train loss: 0.11495595425367355\n",
      "Epoch 0: train loss: 0.24552224576473236\n",
      "Epoch 0: train loss: 0.03912012651562691\n",
      "Epoch 0: train loss: 0.20029373466968536\n",
      "Epoch 0: train loss: 0.23395097255706787\n",
      "Epoch 0: train loss: 0.20557260513305664\n",
      "Epoch 0: train loss: 0.18340519070625305\n",
      "Epoch 0: train loss: 0.10104675590991974\n",
      "Epoch 0: train loss: 0.20168237388134003\n",
      "Epoch 0: train loss: 0.4782768189907074\n",
      "Epoch 0: train loss: 0.3631254732608795\n",
      "Epoch 0: train loss: 0.2531804144382477\n",
      "Epoch 0: train loss: 0.31163290143013\n",
      "Epoch 0: train loss: 0.15572373569011688\n",
      "Epoch 0: train loss: 0.29203829169273376\n",
      "Epoch 0: train loss: 0.11844363063573837\n",
      "Epoch 0: train loss: 0.18110550940036774\n",
      "Epoch 0: train loss: 0.3459951877593994\n",
      "Epoch 0: train loss: 0.18218320608139038\n",
      "Epoch 0: train loss: 0.09515216201543808\n",
      "Epoch 0: train loss: 0.2216106355190277\n",
      "Epoch 0: train loss: 0.18774846196174622\n",
      "Epoch 0: train loss: 0.23195672035217285\n",
      "Epoch 0: train loss: 0.178056538105011\n",
      "Epoch 0: train loss: 0.20876282453536987\n",
      "Epoch 0: train loss: 0.3405919075012207\n",
      "Epoch 0: train loss: 0.07636314630508423\n",
      "Epoch 0: train loss: 0.08576814830303192\n",
      "Epoch 0: train loss: 0.38079744577407837\n",
      "Epoch 0: train loss: 0.33637967705726624\n",
      "Epoch 0: train loss: 0.2606666088104248\n",
      "Epoch 0: train loss: 0.06220044568181038\n",
      "Epoch 0: train loss: 0.4750345051288605\n",
      "Epoch 0: train loss: 0.0830850601196289\n",
      "Epoch 0: train loss: 0.21148449182510376\n",
      "Epoch 0: train loss: 0.3177715837955475\n",
      "Epoch 0: train loss: 0.07257593423128128\n",
      "Epoch 0: train loss: 0.07068983465433121\n",
      "Epoch 0: train loss: 0.0695282593369484\n",
      "Epoch 0: train loss: 0.09046676009893417\n",
      "Epoch 0: train loss: 0.24632862210273743\n",
      "Epoch 0: train loss: 0.15215739607810974\n",
      "Epoch 0: train loss: 0.10206436365842819\n",
      "Epoch 0: train loss: 0.5060145258903503\n",
      "Epoch 0: train loss: 0.25245800614356995\n",
      "Epoch 0: train loss: 0.31174618005752563\n",
      "Epoch 0: train loss: 0.22473081946372986\n",
      "Epoch 0: train loss: 0.473319411277771\n",
      "Epoch 0: train loss: 0.2005111575126648\n",
      "Epoch 0: train loss: 0.36095455288887024\n",
      "Epoch 0: train loss: 0.06958697736263275\n",
      "Epoch 0: train loss: 0.14919200539588928\n",
      "Epoch 0: train loss: 0.11819706857204437\n",
      "Epoch 0: train loss: 0.16534769535064697\n",
      "Epoch 0: train loss: 0.258186399936676\n",
      "Epoch 0: train loss: 0.16576877236366272\n",
      "Epoch 0: train loss: 0.18897365033626556\n",
      "Epoch 0: train loss: 0.2754005789756775\n",
      "Epoch 0: train loss: 0.16395531594753265\n",
      "Epoch 0: train loss: 0.16187314689159393\n",
      "Epoch 0: train loss: 0.22750915586948395\n",
      "Epoch 0: train loss: 0.40353265404701233\n",
      "Epoch 0: train loss: 0.43288832902908325\n",
      "Epoch 0: train loss: 0.09312919527292252\n",
      "Epoch 0: train loss: 0.15248452126979828\n",
      "Epoch 0: train loss: 0.49733802676200867\n",
      "Epoch 0: train loss: 0.195531964302063\n",
      "Epoch 0: train loss: 0.11962000280618668\n",
      "Epoch 0: train loss: 0.279873788356781\n",
      "Epoch 0: train loss: 0.18606023490428925\n",
      "Epoch 0: train loss: 0.2720955014228821\n",
      "Epoch 0: train loss: 0.1435248851776123\n",
      "Epoch 0: train loss: 0.14103488624095917\n",
      "Epoch 0: train loss: 0.3462091088294983\n",
      "Epoch 0: train loss: 0.25052520632743835\n",
      "Epoch 0: train loss: 0.32525011897087097\n",
      "Epoch 0: train loss: 0.3078279495239258\n",
      "Epoch 0: train loss: 0.20148061215877533\n",
      "Epoch 0: train loss: 0.1629341095685959\n",
      "Epoch 0: train loss: 0.15457217395305634\n",
      "Epoch 0: train loss: 0.27144545316696167\n",
      "Epoch 0: train loss: 0.21058332920074463\n",
      "Epoch 0: train loss: 0.4601840078830719\n",
      "Epoch 0: train loss: 0.1894833892583847\n",
      "Epoch 0: train loss: 0.33821403980255127\n",
      "Epoch 0: train loss: 0.1763181835412979\n",
      "Epoch 0: train loss: 0.06640684604644775\n",
      "Epoch 0: train loss: 0.14623840153217316\n",
      "Epoch 0: train loss: 0.07058566808700562\n",
      "Epoch 0: train loss: 0.20739635825157166\n",
      "Epoch 0: train loss: 0.33031412959098816\n",
      "Epoch 0: train loss: 0.2686798572540283\n",
      "Epoch 0: train loss: 0.21572822332382202\n",
      "Epoch 0: train loss: 0.27801695466041565\n",
      "Epoch 0: train loss: 0.26815909147262573\n",
      "Epoch 0: train loss: 0.10930517315864563\n",
      "Epoch 0: train loss: 0.3038051426410675\n",
      "Epoch 0: train loss: 0.37814420461654663\n",
      "Epoch 0: train loss: 0.06686285138130188\n",
      "Epoch 0: train loss: 0.41420090198516846\n",
      "Epoch 0: train loss: 0.0774773433804512\n",
      "Epoch 0: train loss: 0.25062933564186096\n",
      "Epoch 0: train loss: 0.15725955367088318\n",
      "Epoch 0: train loss: 0.10786591470241547\n",
      "Epoch 0: train loss: 0.08375096321105957\n",
      "Epoch 0: train loss: 0.0669102817773819\n",
      "Epoch 0: train loss: 0.2797590494155884\n",
      "Epoch 0: train loss: 0.48696550726890564\n",
      "Epoch 0: train loss: 0.3939824402332306\n",
      "Epoch 0: train loss: 0.06596210598945618\n",
      "Epoch 0: train loss: 0.16860736906528473\n",
      "Epoch 0: train loss: 0.14660578966140747\n",
      "Epoch 0: train loss: 0.15858206152915955\n",
      "Epoch 0: train loss: 0.08826331049203873\n",
      "Epoch 0: train loss: 0.21721431612968445\n",
      "Epoch 0: train loss: 0.1282082051038742\n",
      "Epoch 0: train loss: 0.08081851154565811\n",
      "Epoch 0: train loss: 0.2573182284832001\n",
      "Epoch 0: train loss: 0.0745224580168724\n",
      "Epoch 0: train loss: 0.17327645421028137\n",
      "Epoch 0: train loss: 0.26537829637527466\n",
      "Epoch 0: train loss: 0.29124677181243896\n",
      "Epoch 0: train loss: 0.2659565806388855\n",
      "Epoch 0: train loss: 0.36334922909736633\n",
      "Epoch 0: train loss: 0.1741185486316681\n",
      "Epoch 0: train loss: 0.14576832950115204\n",
      "Epoch 0: train loss: 0.18685832619667053\n",
      "Epoch 0: train loss: 0.3524538278579712\n",
      "Epoch 0: train loss: 0.330166757106781\n",
      "Epoch 0: train loss: 0.32007041573524475\n",
      "Epoch 0: train loss: 0.21482619643211365\n",
      "Epoch 0: train loss: 0.28779464960098267\n",
      "Epoch 0: train loss: 0.21912330389022827\n",
      "Epoch 0: train loss: 0.1317218393087387\n",
      "Epoch 0: train loss: 0.20134732127189636\n",
      "Epoch 0: train loss: 0.3887867331504822\n",
      "Epoch 0: train loss: 0.25708070397377014\n",
      "Epoch 0: train loss: 0.24032782018184662\n",
      "Epoch 0: train loss: 0.23851452767848969\n",
      "Epoch 0: train loss: 0.14620216190814972\n",
      "Epoch 0: train loss: 0.2304198443889618\n",
      "Epoch 0: train loss: 0.1576564908027649\n",
      "Epoch 0: train loss: 0.2087213099002838\n",
      "Epoch 0: train loss: 0.07175365090370178\n",
      "Epoch 0: train loss: 0.20064981281757355\n",
      "Epoch 0: train loss: 0.18818879127502441\n",
      "Epoch 0: train loss: 0.3519127368927002\n",
      "Epoch 0: train loss: 0.20453038811683655\n",
      "Epoch 0: train loss: 0.06167176365852356\n",
      "Epoch 0: train loss: 0.3386613428592682\n",
      "Epoch 0: train loss: 0.3601885437965393\n",
      "Epoch 0: train loss: 0.11069090664386749\n",
      "Epoch 0: train loss: 0.16415825486183167\n",
      "Epoch 0: train loss: 0.06735698878765106\n",
      "Epoch 0: train loss: 0.43699803948402405\n",
      "Epoch 0: train loss: 0.16595599055290222\n",
      "Epoch 0: train loss: 0.22482477128505707\n",
      "Epoch 0: train loss: 0.23372258245944977\n",
      "Epoch 0: train loss: 0.1882995069026947\n",
      "Epoch 0: train loss: 0.14515599608421326\n",
      "Epoch 0: train loss: 0.3391741216182709\n",
      "Epoch 0: train loss: 0.23493339121341705\n",
      "Epoch 0: train loss: 0.13980188965797424\n",
      "Epoch 0: train loss: 0.1679447591304779\n",
      "Epoch 0: train loss: 0.2312445193529129\n",
      "Epoch 0: train loss: 0.26570168137550354\n",
      "Epoch 0: train loss: 0.22613322734832764\n",
      "Epoch 0: train loss: 0.07366147637367249\n",
      "Epoch 0: train loss: 0.42199188470840454\n",
      "Epoch 0: train loss: 0.14258885383605957\n",
      "Epoch 0: train loss: 0.27040764689445496\n",
      "Epoch 0: train loss: 0.148520365357399\n",
      "Epoch 0: train loss: 0.40676459670066833\n",
      "Epoch 0: train loss: 0.23834489285945892\n",
      "Epoch 0: train loss: 0.14719682931900024\n",
      "Epoch 0: train loss: 0.32761481404304504\n",
      "Epoch 0: train loss: 0.2666908800601959\n",
      "Epoch 0: train loss: 0.17110171914100647\n",
      "Epoch 0: train loss: 0.2107938975095749\n",
      "Epoch 0: train loss: 0.24380415678024292\n",
      "Epoch 0: train loss: 0.2576439678668976\n",
      "Epoch 0: train loss: 0.2751453220844269\n",
      "Epoch 0: train loss: 0.09450691193342209\n",
      "Epoch 0: train loss: 0.10127273201942444\n",
      "Epoch 0: train loss: 0.12157401442527771\n",
      "Epoch 0: train loss: 0.09417726844549179\n",
      "Epoch 0: train loss: 0.530415415763855\n",
      "Epoch 0: train loss: 0.6040027737617493\n",
      "Epoch 0: train loss: 0.18579687178134918\n",
      "Epoch 0: train loss: 0.13022193312644958\n",
      "Epoch 0: train loss: 0.23801273107528687\n",
      "Epoch 0: train loss: 0.18837036192417145\n",
      "Epoch 0: train loss: 0.27118349075317383\n",
      "Epoch 0: train loss: 0.06883630901575089\n",
      "Epoch 0: train loss: 0.15524861216545105\n",
      "Epoch 0: train loss: 0.15183515846729279\n",
      "Epoch 0: train loss: 0.1542360931634903\n",
      "Epoch 0: train loss: 0.2282632291316986\n",
      "Epoch 0: train loss: 0.06975924968719482\n",
      "Epoch 0: train loss: 0.12660366296768188\n",
      "Epoch 0: train loss: 0.24879205226898193\n",
      "Epoch 0: train loss: 0.09250060468912125\n",
      "Epoch 0: train loss: 0.2766457796096802\n",
      "Epoch 0: train loss: 0.17711476981639862\n",
      "Epoch 0: train loss: 0.3277771770954132\n",
      "Epoch 0: train loss: 0.17786303162574768\n",
      "Epoch 0: train loss: 0.062498316168785095\n",
      "Epoch 0: train loss: 0.021869638934731483\n",
      "Epoch 0: train loss: 0.12620118260383606\n",
      "Epoch 0: train loss: 0.09579942375421524\n",
      "Epoch 0: train loss: 0.2871410846710205\n",
      "Epoch 0: train loss: 0.3695211112499237\n",
      "Epoch 0: train loss: 0.151408851146698\n",
      "Epoch 0: train loss: 0.2727827727794647\n",
      "Epoch 0: train loss: 0.2151067852973938\n",
      "Epoch 0: train loss: 0.13001245260238647\n",
      "Epoch 0: train loss: 0.14772596955299377\n",
      "Epoch 0: train loss: 0.21687129139900208\n",
      "Epoch 0: train loss: 0.23482471704483032\n",
      "Epoch 0: train loss: 0.2497899979352951\n",
      "Epoch 0: train loss: 0.2873915433883667\n",
      "Epoch 0: train loss: 0.14304324984550476\n",
      "Epoch 0: train loss: 0.2594190835952759\n",
      "Epoch 0: train loss: 0.18851861357688904\n",
      "Epoch 0: train loss: 0.20130547881126404\n",
      "Epoch 0: train loss: 0.23718315362930298\n",
      "Epoch 0: train loss: 0.111119344830513\n",
      "Epoch 0: train loss: 0.26210716366767883\n",
      "Epoch 0: train loss: 0.29157862067222595\n",
      "Epoch 0: train loss: 0.11712384223937988\n",
      "Epoch 0: train loss: 0.25226449966430664\n",
      "Epoch 0: train loss: 0.1506287157535553\n",
      "Epoch 0: train loss: 0.2825772166252136\n",
      "Epoch 0: train loss: 0.2938246726989746\n",
      "Epoch 0: train loss: 0.048525772988796234\n",
      "Epoch 0: train loss: 0.2282041758298874\n",
      "Epoch 0: train loss: 0.296365886926651\n",
      "Epoch 0: train loss: 0.24497002363204956\n",
      "Epoch 0: train loss: 0.0323653370141983\n",
      "Epoch 0: train loss: 0.23749767243862152\n",
      "Epoch 0: train loss: 0.0989895835518837\n",
      "Epoch 0: train loss: 0.16121380031108856\n",
      "Epoch 0: train loss: 0.2116425484418869\n",
      "Epoch 0: train loss: 0.0680578425526619\n",
      "Epoch 0: train loss: 0.05803568288683891\n",
      "Epoch 0: train loss: 0.19998902082443237\n",
      "Epoch 0: train loss: 0.3823677599430084\n",
      "Epoch 0: train loss: 0.1770412027835846\n",
      "Epoch 0: train loss: 0.349828839302063\n",
      "Epoch 0: train loss: 0.233692929148674\n",
      "Epoch 0: train loss: 0.17298318445682526\n",
      "Epoch 0: train loss: 0.143168643116951\n",
      "Epoch 0: train loss: 0.27826106548309326\n",
      "Epoch 0: train loss: 0.20213741064071655\n",
      "Epoch 0: train loss: 0.23058199882507324\n",
      "Epoch 0: train loss: 0.27488279342651367\n",
      "Epoch 0: train loss: 0.09478744864463806\n",
      "Epoch 0: train loss: 0.35020938515663147\n",
      "Epoch 0: train loss: 0.23753121495246887\n",
      "Epoch 0: train loss: 0.4717376232147217\n",
      "Epoch 0: train loss: 0.14820346236228943\n",
      "Epoch 0: train loss: 0.14862598478794098\n",
      "Epoch 0: train loss: 0.3957541882991791\n",
      "Epoch 0: train loss: 0.10072623938322067\n",
      "Epoch 0: train loss: 0.16186395287513733\n",
      "Epoch 0: train loss: 0.1049719899892807\n",
      "Epoch 0: train loss: 0.3708657920360565\n",
      "Epoch 0: train loss: 0.2625890374183655\n",
      "Epoch 0: train loss: 0.16094104945659637\n",
      "Epoch 0: train loss: 0.3103002607822418\n",
      "Epoch 0: train loss: 0.32149797677993774\n",
      "Epoch 0: train loss: 0.07117990404367447\n",
      "Epoch 0: train loss: 0.15537849068641663\n",
      "Epoch 0: train loss: 0.29068657755851746\n",
      "Epoch 0: train loss: 0.04542284458875656\n",
      "Epoch 0: train loss: 0.19026316702365875\n",
      "Epoch 0: train loss: 0.48407724499702454\n",
      "Epoch 0: train loss: 0.12850208580493927\n",
      "Epoch 0: train loss: 0.1335603892803192\n",
      "Epoch 0: train loss: 0.13025066256523132\n",
      "Epoch 0: train loss: 0.08524079620838165\n",
      "Epoch 0: train loss: 0.41296619176864624\n",
      "Epoch 0: train loss: 0.06331200152635574\n",
      "Epoch 0: train loss: 0.03630976378917694\n",
      "Epoch 0: train loss: 0.11664943397045135\n",
      "Epoch 0: train loss: 0.2856910228729248\n",
      "Epoch 0: train loss: 0.2574784457683563\n",
      "Epoch 0: train loss: 0.27769649028778076\n",
      "Epoch 0: train loss: 0.062168631702661514\n",
      "Epoch 0: train loss: 0.1670871376991272\n",
      "Epoch 0: train loss: 0.19780278205871582\n",
      "Epoch 0: train loss: 0.0562225878238678\n",
      "Epoch 0: train loss: 0.38699719309806824\n",
      "Epoch 0: train loss: 0.17414748668670654\n",
      "Epoch 0: train loss: 0.1908530741930008\n",
      "Epoch 0: train loss: 0.40392759442329407\n",
      "Epoch 0: train loss: 0.13962890207767487\n",
      "Epoch 0: train loss: 0.08946721255779266\n",
      "Epoch 0: train loss: 0.24405723810195923\n",
      "Epoch 0: train loss: 0.2719690203666687\n",
      "Epoch 0: train loss: 0.29080507159233093\n",
      "Epoch 0: train loss: 0.16382601857185364\n",
      "Epoch 0: train loss: 0.24415843188762665\n",
      "Epoch 0: train loss: 0.20686426758766174\n",
      "Epoch 0: train loss: 0.17407259345054626\n",
      "Epoch 0: train loss: 0.38338667154312134\n",
      "Epoch 0: train loss: 0.0961621031165123\n",
      "Epoch 0: train loss: 0.20594878494739532\n",
      "Epoch 0: train loss: 0.22836284339427948\n",
      "Epoch 0: train loss: 0.3618999719619751\n",
      "Epoch 0: train loss: 0.40752914547920227\n",
      "Epoch 0: train loss: 0.26806965470314026\n",
      "Epoch 0: train loss: 0.27998805046081543\n",
      "Epoch 0: train loss: 0.2852654457092285\n",
      "Epoch 0: train loss: 0.16047309339046478\n",
      "Epoch 0: train loss: 0.30987608432769775\n",
      "Epoch 0: train loss: 0.11589636653661728\n",
      "Epoch 0: train loss: 0.16900309920310974\n",
      "Epoch 0: train loss: 0.20670334994792938\n",
      "Epoch 0: train loss: 0.3253917694091797\n",
      "Epoch 0: train loss: 0.2998228669166565\n",
      "Epoch 0: train loss: 0.10236683487892151\n",
      "Epoch 0: train loss: 0.2818196415901184\n",
      "Epoch 0: train loss: 0.2484269142150879\n",
      "Epoch 0: train loss: 0.12783266603946686\n",
      "Epoch 0: train loss: 0.14488466084003448\n",
      "Epoch 0: train loss: 0.09848475456237793\n",
      "Epoch 0: train loss: 0.10881093889474869\n",
      "Epoch 0: train loss: 0.17500172555446625\n",
      "Epoch 0: train loss: 0.21420444548130035\n",
      "Epoch 0: train loss: 0.08412614464759827\n",
      "Epoch 0: train loss: 0.34007376432418823\n",
      "Epoch 0: train loss: 0.17037469148635864\n",
      "Epoch 0: train loss: 0.16546814143657684\n",
      "Epoch 0: train loss: 0.03518958017230034\n",
      "Epoch 0: train loss: 0.32447075843811035\n",
      "Epoch 0: train loss: 0.5207943320274353\n",
      "Epoch 0: train loss: 0.1610308587551117\n",
      "Epoch 0: train loss: 0.17870259284973145\n",
      "Epoch 0: train loss: 0.06763844937086105\n",
      "Epoch 0: train loss: 0.056053027510643005\n",
      "Epoch 0: train loss: 0.14398229122161865\n",
      "Epoch 0: train loss: 0.08014465868473053\n",
      "Epoch 0: train loss: 0.11144531518220901\n",
      "Epoch 0: train loss: 0.35575470328330994\n",
      "Epoch 0: train loss: 0.3097781836986542\n",
      "Epoch 0: train loss: 0.1157362088561058\n",
      "Epoch 0: train loss: 0.3284286856651306\n",
      "Epoch 0: train loss: 0.12174499034881592\n",
      "Epoch 0: train loss: 0.18322116136550903\n",
      "Epoch 0: train loss: 0.2486964613199234\n",
      "Epoch 0: train loss: 0.07052451372146606\n",
      "Epoch 0: train loss: 0.09937155246734619\n",
      "Epoch 0: train loss: 0.13564953207969666\n",
      "Epoch 0: train loss: 0.2094106674194336\n",
      "Epoch 0: train loss: 0.17345024645328522\n",
      "Epoch 0: train loss: 0.24017234146595\n",
      "Epoch 0: train loss: 0.2595805823802948\n",
      "Epoch 0: train loss: 0.13627660274505615\n",
      "Epoch 0: train loss: 0.2339649647474289\n",
      "Epoch 0: train loss: 0.1496649980545044\n",
      "Epoch 0: train loss: 0.45584097504615784\n",
      "Epoch 0: train loss: 0.33338505029678345\n",
      "Epoch 0: train loss: 0.1722632646560669\n",
      "Epoch 0: train loss: 0.15036030113697052\n",
      "Epoch 0: train loss: 0.13010534644126892\n",
      "Epoch 0: train loss: 0.3522695302963257\n",
      "Epoch 0: train loss: 0.14793874323368073\n",
      "Epoch 0: train loss: 0.3664892613887787\n",
      "Epoch 0: train loss: 0.22200992703437805\n",
      "Epoch 0: train loss: 0.11832726746797562\n",
      "Epoch 0: train loss: 0.1597384661436081\n",
      "Epoch 0: train loss: 0.28706657886505127\n",
      "Epoch 0: train loss: 0.2075391709804535\n",
      "Epoch 0: train loss: 0.2396770715713501\n",
      "Epoch 0: train loss: 0.18860773742198944\n",
      "Epoch 0: train loss: 0.12976691126823425\n",
      "Epoch 0: train loss: 0.17730079591274261\n",
      "Epoch 0: train loss: 0.16013658046722412\n",
      "Epoch 0: train loss: 0.05668294429779053\n",
      "Epoch 0: train loss: 0.09046109765768051\n",
      "Epoch 0: train loss: 0.19226928055286407\n",
      "Epoch 0: train loss: 0.3677816092967987\n",
      "Epoch 0: train loss: 0.22341790795326233\n",
      "Epoch 0: train loss: 0.24306535720825195\n",
      "Epoch 0: train loss: 0.18985114991664886\n",
      "Epoch 0: train loss: 0.20035862922668457\n",
      "Epoch 0: train loss: 0.15543532371520996\n",
      "Epoch 0: train loss: 0.2254842072725296\n",
      "Epoch 0: train loss: 0.2556014955043793\n",
      "Epoch 0: train loss: 0.3089806139469147\n",
      "Epoch 0: train loss: 0.1403873711824417\n",
      "Epoch 0: train loss: 0.0906805768609047\n",
      "Epoch 0: train loss: 0.21688368916511536\n",
      "Epoch 0: train loss: 0.18640173971652985\n",
      "Epoch 0: train loss: 0.19865106046199799\n",
      "Epoch 0: train loss: 0.15476353466510773\n",
      "Epoch 0: train loss: 0.09144904464483261\n",
      "Epoch 0: train loss: 0.2558372914791107\n",
      "Epoch 0: train loss: 0.12408912181854248\n",
      "Epoch 0: train loss: 0.3428838849067688\n",
      "Epoch 0: train loss: 0.502189040184021\n",
      "Epoch 0: train loss: 0.0649590715765953\n",
      "Epoch 0: train loss: 0.2137356996536255\n",
      "Epoch 0: train loss: 0.3391944468021393\n",
      "Epoch 0: train loss: 0.13941197097301483\n",
      "Epoch 0: train loss: 0.19647370278835297\n",
      "Epoch 0: train loss: 0.08465179800987244\n",
      "Epoch 0: train loss: 0.2701670229434967\n",
      "Epoch 0: train loss: 0.11661385744810104\n",
      "Epoch 0: train loss: 0.34691789746284485\n",
      "Epoch 0: train loss: 0.08543482422828674\n",
      "Epoch 0: train loss: 0.1975041925907135\n",
      "Epoch 0: train loss: 0.07009994983673096\n",
      "Epoch 0: train loss: 0.16109922528266907\n",
      "Epoch 0: train loss: 0.25428009033203125\n",
      "Epoch 0: train loss: 0.17899128794670105\n",
      "Epoch 0: train loss: 0.13641908764839172\n",
      "Epoch 0: train loss: 0.20096628367900848\n",
      "Epoch 0: train loss: 0.11357952654361725\n",
      "Epoch 0: train loss: 0.26619452238082886\n",
      "Epoch 0: train loss: 0.18851934373378754\n",
      "Epoch 0: train loss: 0.25154832005500793\n",
      "Epoch 0: train loss: 0.14305610954761505\n",
      "Epoch 0: train loss: 0.16202694177627563\n",
      "Epoch 0: train loss: 0.32217103242874146\n",
      "Epoch 0: train loss: 0.26650363206863403\n",
      "Epoch 0: train loss: 0.07558614760637283\n",
      "Epoch 0: train loss: 0.3140409290790558\n",
      "Epoch 0: train loss: 0.16226831078529358\n",
      "Epoch 0: train loss: 0.14433759450912476\n",
      "Epoch 0: train loss: 0.127973273396492\n",
      "Epoch 0: train loss: 0.22056256234645844\n",
      "Epoch 0: train loss: 0.25425684452056885\n",
      "Epoch 0: train loss: 0.1849910318851471\n",
      "Epoch 0: train loss: 0.13085682690143585\n",
      "Epoch 0: train loss: 0.41291019320487976\n",
      "Epoch 0: train loss: 0.2185109704732895\n",
      "Epoch 0: train loss: 0.2676078975200653\n",
      "Epoch 0: train loss: 0.2624545097351074\n",
      "Epoch 0: train loss: 0.2960449755191803\n",
      "Epoch 0: train loss: 0.1935131996870041\n",
      "Epoch 0: train loss: 0.13600905239582062\n",
      "Epoch 0: train loss: 0.2463415414094925\n",
      "Epoch 0: train loss: 0.1377081274986267\n",
      "Epoch 0: train loss: 0.12606410682201385\n",
      "Epoch 0: train loss: 0.1508989781141281\n",
      "Epoch 0: train loss: 0.2939893305301666\n",
      "Epoch 0: train loss: 0.27829599380493164\n",
      "Epoch 0: train loss: 0.18983079493045807\n",
      "Epoch 0: train loss: 0.1980147808790207\n",
      "Epoch 0: train loss: 0.15417541563510895\n",
      "Epoch 0: train loss: 0.48730555176734924\n",
      "Epoch 0: train loss: 0.3032120168209076\n",
      "Epoch 0: train loss: 0.5260742902755737\n",
      "Epoch 0: train loss: 0.24571120738983154\n",
      "Epoch 0: train loss: 0.1049601137638092\n",
      "Epoch 0: train loss: 0.21855352818965912\n",
      "Epoch 0: train loss: 0.258480966091156\n",
      "Epoch 0: train loss: 0.10885830223560333\n",
      "Epoch 0: train loss: 0.20343245565891266\n",
      "Epoch 0: train loss: 0.11970032006502151\n",
      "Epoch 0: train loss: 0.21632105112075806\n",
      "Epoch 0: train loss: 0.22243954241275787\n",
      "Epoch 0: train loss: 0.16530491411685944\n",
      "Epoch 0: train loss: 0.06525100767612457\n",
      "Epoch 0: train loss: 0.2531425952911377\n",
      "Epoch 0: train loss: 0.19972530007362366\n",
      "Epoch 0: train loss: 0.46262162923812866\n",
      "Epoch 0: train loss: 0.1790480762720108\n",
      "Epoch 0: train loss: 0.6271124482154846\n",
      "Epoch 0: train loss: 0.13391362130641937\n",
      "Epoch 0: train loss: 0.187938392162323\n",
      "Epoch 0: train loss: 0.20025759935379028\n",
      "Epoch 0: train loss: 0.10378891229629517\n",
      "Epoch 0: train loss: 0.336631715297699\n",
      "Epoch 0: train loss: 0.11249731481075287\n",
      "Epoch 0: train loss: 0.2433333843946457\n",
      "Epoch 0: train loss: 0.17076879739761353\n",
      "Epoch 0: train loss: 0.17300304770469666\n",
      "Epoch 0: train loss: 0.19420866668224335\n",
      "Epoch 0: train loss: 0.27939367294311523\n",
      "Epoch 0: train loss: 0.11760525405406952\n",
      "Epoch 0: train loss: 0.37510281801223755\n",
      "Epoch 0: train loss: 0.1478268802165985\n",
      "Epoch 0: train loss: 0.21793493628501892\n",
      "Epoch 0: train loss: 0.2933027446269989\n",
      "Epoch 0: train loss: 0.09369604289531708\n",
      "Epoch 0: train loss: 0.31078219413757324\n",
      "Epoch 0: train loss: 0.4263167679309845\n",
      "Epoch 0: train loss: 0.14111018180847168\n",
      "Epoch 0: train loss: 0.22863419353961945\n",
      "Epoch 0: train loss: 0.18181663751602173\n",
      "Epoch 0: train loss: 0.17113417387008667\n",
      "Epoch 0: train loss: 0.21216948330402374\n",
      "Epoch 0: train loss: 0.5100048780441284\n",
      "Epoch 0: train loss: 0.08035928755998611\n",
      "Epoch 0: train loss: 0.15748223662376404\n",
      "Epoch 0: train loss: 0.23077061772346497\n",
      "Epoch 0: train loss: 0.2676886320114136\n",
      "Epoch 0: train loss: 0.19479559361934662\n",
      "Epoch 0: train loss: 0.24436762928962708\n",
      "Epoch 0: train loss: 0.1272299736738205\n",
      "Epoch 0: train loss: 0.17934396862983704\n",
      "Epoch 0: train loss: 0.17773738503456116\n",
      "Epoch 0: train loss: 0.09620898216962814\n",
      "Epoch 0: train loss: 0.03092932514846325\n",
      "Epoch 0: train loss: 0.054872866719961166\n",
      "Epoch 0: train loss: 0.27174055576324463\n",
      "Epoch 0: train loss: 0.06582798063755035\n",
      "Epoch 0: train loss: 0.1438480168581009\n",
      "Epoch 0: train loss: 0.3228171169757843\n",
      "Epoch 0: train loss: 0.22481699287891388\n",
      "Epoch 0: train loss: 0.15922974050045013\n",
      "Epoch 0: train loss: 0.031916163861751556\n",
      "Epoch 0: train loss: 0.09820574522018433\n",
      "Epoch 0: train loss: 0.17506350576877594\n",
      "Epoch 0: train loss: 0.12837645411491394\n",
      "Epoch 0: train loss: 0.5324471592903137\n",
      "Epoch 0: train loss: 0.2049764096736908\n",
      "Epoch 0: train loss: 0.1368142068386078\n",
      "Epoch 0: train loss: 0.21356570720672607\n",
      "Epoch 0: train loss: 0.06990592181682587\n",
      "Epoch 0: train loss: 0.14120665192604065\n",
      "Epoch 0: train loss: 0.043883927166461945\n",
      "Epoch 0: train loss: 0.05106998234987259\n",
      "Epoch 0: train loss: 0.14213572442531586\n",
      "Epoch 0: train loss: 0.04213511943817139\n",
      "Epoch 0: train loss: 0.35719743371009827\n",
      "Epoch 0: train loss: 0.2452581822872162\n",
      "Epoch 0: train loss: 0.20442630350589752\n",
      "Epoch 0: train loss: 0.11049037426710129\n",
      "Epoch 0: train loss: 0.19703221321105957\n",
      "Epoch 0: train loss: 0.05914659798145294\n",
      "Epoch 0: train loss: 0.30303946137428284\n",
      "Epoch 0: train loss: 0.33721309900283813\n",
      "Epoch 0: train loss: 0.17873439192771912\n",
      "Epoch 0: train loss: 0.16500695049762726\n",
      "Epoch 0: train loss: 0.3165864944458008\n",
      "Epoch 0: train loss: 0.10418028384447098\n",
      "Epoch 0: train loss: 0.41161414980888367\n",
      "Epoch 0: train loss: 0.2169802337884903\n",
      "Epoch 0: train loss: 0.23235659301280975\n",
      "Epoch 0: train loss: 0.1345941126346588\n",
      "Epoch 0: train loss: 0.1687212884426117\n",
      "Epoch 0: train loss: 0.14876006543636322\n",
      "Epoch 0: train loss: 0.2248278707265854\n",
      "Epoch 0: train loss: 0.12526759505271912\n",
      "Epoch 0: train loss: 0.2976848781108856\n",
      "Epoch 0: train loss: 0.2967756986618042\n",
      "Epoch 0: train loss: 0.17903552949428558\n",
      "Epoch 0: train loss: 0.24998292326927185\n",
      "Epoch 0: train loss: 0.24135473370552063\n",
      "Epoch 0: train loss: 0.2793537974357605\n",
      "Epoch 0: train loss: 0.08221167325973511\n",
      "Epoch 0: train loss: 0.17589348554611206\n",
      "Epoch 0: train loss: 0.22570766508579254\n",
      "Epoch 0: train loss: 0.40847647190093994\n",
      "Epoch 0: train loss: 0.046224575489759445\n",
      "Epoch 0: train loss: 0.23790967464447021\n",
      "Epoch 0: train loss: 0.5018801093101501\n",
      "Epoch 0: train loss: 0.1450790911912918\n",
      "Epoch 0: train loss: 0.13889740407466888\n",
      "Epoch 0: train loss: 0.23279942572116852\n",
      "Epoch 0: train loss: 0.11212940514087677\n",
      "Epoch 0: train loss: 0.12568417191505432\n",
      "Epoch 0: train loss: 0.449166476726532\n",
      "Epoch 0: train loss: 0.180155411362648\n",
      "Epoch 0: train loss: 0.05214707553386688\n",
      "Epoch 0: train loss: 0.16500914096832275\n",
      "Epoch 0: train loss: 0.2866347134113312\n",
      "Epoch 0: train loss: 0.05096415430307388\n",
      "Epoch 0: train loss: 0.20212973654270172\n",
      "Epoch 0: train loss: 0.2668791115283966\n",
      "Epoch 0: train loss: 0.13298073410987854\n",
      "Epoch 0: train loss: 0.4001062214374542\n",
      "Epoch 0: train loss: 0.029522312805056572\n",
      "Epoch 0: train loss: 0.21194975078105927\n",
      "Epoch 0: train loss: 0.34169119596481323\n",
      "Epoch 0: train loss: 0.06212673708796501\n",
      "Epoch 0: train loss: 0.2231876701116562\n",
      "Epoch 0: train loss: 0.20442673563957214\n",
      "Epoch 0: train loss: 0.13870388269424438\n",
      "Epoch 0: train loss: 0.17671096324920654\n",
      "Epoch 0: train loss: 0.19093765318393707\n",
      "Epoch 0: train loss: 0.21592995524406433\n",
      "Epoch 0: train loss: 0.26947006583213806\n",
      "Epoch 0: train loss: 0.17273098230361938\n",
      "Epoch 0: train loss: 0.26910269260406494\n",
      "Epoch 0: train loss: 0.3129875361919403\n",
      "Epoch 0: train loss: 0.1311141699552536\n",
      "Epoch 0: train loss: 0.2508983612060547\n",
      "Epoch 0: train loss: 0.19678232073783875\n",
      "Epoch 0: train loss: 0.1782994270324707\n",
      "Epoch 0: train loss: 0.22030246257781982\n",
      "Epoch 0: train loss: 0.1892673373222351\n",
      "Epoch 0: train loss: 0.16125208139419556\n",
      "Epoch 0: train loss: 0.3181554973125458\n",
      "Epoch 0: train loss: 0.10014624893665314\n",
      "Epoch 0: train loss: 0.2717736065387726\n",
      "Epoch 0: train loss: 0.07238585501909256\n",
      "Epoch 0: train loss: 0.2001599222421646\n",
      "Epoch 0: train loss: 0.20339170098304749\n",
      "Epoch 0: train loss: 0.28243231773376465\n",
      "Epoch 0: train loss: 0.05215468257665634\n",
      "Epoch 0: train loss: 0.16811129450798035\n",
      "Epoch 0: train loss: 0.06268782168626785\n",
      "Epoch 0: train loss: 0.1361878216266632\n",
      "Epoch 0: train loss: 0.12134901434183121\n",
      "Epoch 0: train loss: 0.14553621411323547\n",
      "Epoch 0: train loss: 0.4680580198764801\n",
      "Epoch 0: train loss: 0.31578657031059265\n",
      "Epoch 0: train loss: 0.47491979598999023\n",
      "Epoch 0: train loss: 0.0809955820441246\n",
      "Epoch 0: train loss: 0.07267355918884277\n",
      "Epoch 0: train loss: 0.15532110631465912\n",
      "Epoch 0: train loss: 0.3653492033481598\n",
      "Epoch 0: train loss: 0.2719256281852722\n",
      "Epoch 0: train loss: 0.14335758984088898\n",
      "Epoch 0: train loss: 0.21817821264266968\n",
      "Epoch 0: train loss: 0.25811171531677246\n",
      "Epoch 0: train loss: 0.3134903609752655\n",
      "Epoch 0: train loss: 0.1473475694656372\n",
      "Epoch 0: train loss: 0.18705977499485016\n",
      "Epoch 0: train loss: 0.15518133342266083\n",
      "Epoch 0: train loss: 0.2675539553165436\n",
      "Epoch 0: train loss: 0.21686801314353943\n",
      "Epoch 0: train loss: 0.1144869476556778\n",
      "Epoch 0: train loss: 0.28853639960289\n",
      "Epoch 0: train loss: 0.12394789606332779\n",
      "Epoch 0: train loss: 0.27416014671325684\n",
      "Epoch 0: train loss: 0.23812873661518097\n",
      "Epoch 0: train loss: 0.06344297528266907\n",
      "Epoch 0: train loss: 0.29979655146598816\n",
      "Epoch 0: train loss: 0.08869049698114395\n",
      "Epoch 0: train loss: 0.15433979034423828\n",
      "Epoch 0: train loss: 0.27245497703552246\n",
      "Epoch 0: train loss: 0.04369286447763443\n",
      "Epoch 0: train loss: 0.03180449828505516\n",
      "Epoch 0: train loss: 0.2898554503917694\n",
      "Epoch 0: train loss: 0.1714581549167633\n",
      "Epoch 0: train loss: 0.05025387555360794\n",
      "Epoch 0: train loss: 0.18235962092876434\n",
      "Epoch 0: train loss: 0.13781431317329407\n",
      "Epoch 0: train loss: 0.2675623297691345\n",
      "Epoch 0: train loss: 0.16077503561973572\n",
      "Epoch 0: train loss: 0.1719486266374588\n",
      "Epoch 0: train loss: 0.21745985746383667\n",
      "Epoch 0: train loss: 0.37527236342430115\n",
      "Epoch 0: train loss: 0.048071861267089844\n",
      "Epoch 0: train loss: 0.13714629411697388\n",
      "Epoch 0: train loss: 0.2630576193332672\n",
      "Epoch 0: train loss: 0.189430832862854\n",
      "Epoch 0: train loss: 0.19808903336524963\n",
      "Epoch 0: train loss: 0.057582370936870575\n",
      "Epoch 0: train loss: 0.2762715518474579\n",
      "Epoch 0: train loss: 0.16298405826091766\n",
      "Epoch 0: train loss: 0.17319181561470032\n",
      "Epoch 0: train loss: 0.0787733793258667\n",
      "Epoch 0: train loss: 0.11972970515489578\n",
      "Epoch 0: train loss: 0.10270917415618896\n",
      "Epoch 0: train loss: 0.08728008717298508\n",
      "Epoch 0: train loss: 0.05124813690781593\n",
      "Epoch 0: train loss: 0.21740840375423431\n",
      "Epoch 0: train loss: 0.36904069781303406\n",
      "Epoch 0: train loss: 0.27335426211357117\n",
      "Epoch 0: train loss: 0.21849089860916138\n",
      "Epoch 0: train loss: 0.07401666790246964\n",
      "Epoch 0: train loss: 0.10464001446962357\n",
      "Epoch 0: train loss: 0.08919793367385864\n",
      "Epoch 0: train loss: 0.2530277967453003\n",
      "Epoch 0: train loss: 0.24229015409946442\n",
      "Epoch 0: train loss: 0.3193665146827698\n",
      "Epoch 0: train loss: 0.05691635608673096\n",
      "Epoch 0: train loss: 0.10610276460647583\n",
      "Epoch 0: train loss: 0.18434621393680573\n",
      "Epoch 0: train loss: 0.29045864939689636\n",
      "Epoch 0: train loss: 0.5466934442520142\n",
      "Epoch 0: train loss: 0.07339543104171753\n",
      "Epoch 0: train loss: 0.12025637924671173\n",
      "Epoch 0: train loss: 0.3600010871887207\n",
      "Epoch 0: train loss: 0.28926268219947815\n",
      "Epoch 0: train loss: 0.0860493928194046\n",
      "Epoch 0: train loss: 0.21636289358139038\n",
      "Epoch 0: train loss: 0.05330128222703934\n",
      "Epoch 0: train loss: 0.2766973078250885\n",
      "Epoch 0: train loss: 0.31923216581344604\n",
      "Epoch 0: train loss: 0.07786768674850464\n",
      "Epoch 0: train loss: 0.1641232967376709\n",
      "Epoch 0: train loss: 0.25775739550590515\n",
      "Epoch 0: train loss: 0.22606350481510162\n",
      "Epoch 0: train loss: 0.08783634752035141\n",
      "Epoch 0: train loss: 0.1535705327987671\n",
      "Epoch 0: train loss: 0.10565394908189774\n",
      "Epoch 0: train loss: 0.24543264508247375\n",
      "Epoch 0: train loss: 0.1326865553855896\n",
      "Epoch 0: train loss: 0.2173626720905304\n",
      "Epoch 0: train loss: 0.31611353158950806\n",
      "Epoch 0: train loss: 0.09548823535442352\n",
      "Epoch 0: train loss: 0.3300504684448242\n",
      "Epoch 0: train loss: 0.27635061740875244\n",
      "Epoch 0: train loss: 0.1508658230304718\n",
      "Epoch 0: train loss: 0.3199463188648224\n",
      "Epoch 0: train loss: 0.1625041961669922\n",
      "Epoch 0: train loss: 0.1614166498184204\n",
      "Epoch 0: train loss: 0.2098444551229477\n",
      "Epoch 0: train loss: 0.10740161687135696\n",
      "Epoch 0: train loss: 0.2657361924648285\n",
      "Epoch 0: train loss: 0.09773032367229462\n",
      "Epoch 0: train loss: 0.16146621108055115\n",
      "Epoch 0: train loss: 0.28025901317596436\n",
      "Epoch 0: train loss: 0.37992921471595764\n",
      "Epoch 0: train loss: 0.12226233631372452\n",
      "Epoch 0: train loss: 0.3613922894001007\n",
      "Epoch 0: train loss: 0.06833488494157791\n",
      "Epoch 0: train loss: 0.3914521634578705\n",
      "Epoch 0: train loss: 0.33638083934783936\n",
      "Epoch 0: train loss: 0.2235080748796463\n",
      "Epoch 0: train loss: 0.21114785969257355\n",
      "Epoch 0: train loss: 0.12268191576004028\n",
      "Epoch 0: train loss: 0.19310909509658813\n",
      "Epoch 0: train loss: 0.17836356163024902\n",
      "Epoch 0: train loss: 0.1547766923904419\n",
      "Epoch 0: train loss: 0.09217162430286407\n",
      "Epoch 0: train loss: 0.32391422986984253\n",
      "Epoch 0: train loss: 0.24410898983478546\n",
      "Epoch 0: train loss: 0.1548469513654709\n",
      "Epoch 0: train loss: 0.3993009924888611\n",
      "Epoch 0: train loss: 0.15744030475616455\n",
      "Epoch 0: train loss: 0.11696804314851761\n",
      "Epoch 0: train loss: 0.11690285056829453\n",
      "Epoch 0: train loss: 0.1426054686307907\n",
      "Epoch 0: train loss: 0.3085286617279053\n",
      "Epoch 0: train loss: 0.22955279052257538\n",
      "Epoch 0: train loss: 0.12881587445735931\n",
      "Epoch 0: train loss: 0.17637817561626434\n",
      "Epoch 0: train loss: 0.19592422246932983\n",
      "Epoch 0: train loss: 0.17009009420871735\n",
      "Epoch 0: train loss: 0.036523547023534775\n",
      "Epoch 0: train loss: 0.2104749232530594\n",
      "Epoch 0: train loss: 0.3181079626083374\n",
      "Epoch 0: train loss: 0.2516884207725525\n",
      "Epoch 0: train loss: 0.029137415811419487\n",
      "Epoch 0: train loss: 0.07840333878993988\n",
      "Epoch 0: train loss: 0.05662309005856514\n",
      "Epoch 0: train loss: 0.19631710648536682\n",
      "Epoch 0: train loss: 0.3349637985229492\n",
      "Epoch 0: train loss: 0.07444243878126144\n",
      "Epoch 0: train loss: 0.2482418715953827\n",
      "Epoch 0: train loss: 0.05578998848795891\n",
      "Epoch 0: train loss: 0.27978211641311646\n",
      "Epoch 0: train loss: 0.22968067228794098\n",
      "Epoch 0: train loss: 0.1562611311674118\n",
      "Epoch 0: train loss: 0.1349296271800995\n",
      "Epoch 0: train loss: 0.43822354078292847\n",
      "Epoch 0: train loss: 0.1342647224664688\n",
      "Epoch 0: train loss: 0.20485429465770721\n",
      "Epoch 0: train loss: 0.23630070686340332\n",
      "Epoch 0: train loss: 0.23706161975860596\n",
      "Epoch 0: train loss: 0.21403449773788452\n",
      "Epoch 0: train loss: 0.21778209507465363\n",
      "Epoch 0: train loss: 0.22175182402133942\n",
      "Epoch 0: train loss: 0.2058769017457962\n",
      "Epoch 0: train loss: 0.1206563413143158\n",
      "Epoch 0: train loss: 0.31121566891670227\n",
      "Epoch 0: train loss: 0.26685526967048645\n",
      "Epoch 0: train loss: 0.2804096043109894\n",
      "Epoch 0: train loss: 0.16484057903289795\n",
      "Epoch 0: train loss: 0.05458231642842293\n",
      "Epoch 0: train loss: 0.18315677344799042\n",
      "Epoch 0: train loss: 0.07855357229709625\n",
      "Epoch 0: train loss: 0.2956882119178772\n",
      "Epoch 0: train loss: 0.23627997934818268\n",
      "Epoch 0: train loss: 0.09165489673614502\n",
      "Epoch 0: train loss: 0.2035798579454422\n",
      "Epoch 0: train loss: 0.06481707096099854\n",
      "Epoch 0: train loss: 0.15504240989685059\n",
      "Epoch 0: train loss: 0.22133088111877441\n",
      "Epoch 0: train loss: 0.14496080577373505\n",
      "Epoch 0: train loss: 0.13069571554660797\n",
      "Epoch 0: train loss: 0.15096527338027954\n",
      "Epoch 0: train loss: 0.07435683161020279\n",
      "Epoch 0: train loss: 0.14538034796714783\n",
      "Epoch 0: train loss: 0.2889372706413269\n",
      "Epoch 0: train loss: 0.3284071087837219\n",
      "Epoch 0: train loss: 0.4756048619747162\n",
      "Epoch 0: train loss: 0.12094411998987198\n",
      "Epoch 0: train loss: 0.11835955083370209\n",
      "Epoch 0: train loss: 0.16009269654750824\n",
      "Epoch 0: train loss: 0.13060612976551056\n",
      "Epoch 0: train loss: 0.10056328773498535\n",
      "Epoch 0: train loss: 0.1279354840517044\n",
      "Epoch 0: train loss: 0.23893654346466064\n",
      "Epoch 0: train loss: 0.05429328233003616\n",
      "Epoch 0: train loss: 0.3175080716609955\n",
      "Epoch 0: train loss: 0.1118156686425209\n",
      "Epoch 0: train loss: 0.49995729327201843\n",
      "Epoch 0: train loss: 0.27067556977272034\n",
      "Epoch 0: train loss: 0.1615932732820511\n",
      "Epoch 0: train loss: 0.07621525973081589\n",
      "Epoch 0: train loss: 0.08567535132169724\n",
      "Epoch 0: train loss: 0.2453046441078186\n",
      "Epoch 0: train loss: 0.1446821689605713\n",
      "Epoch 0: train loss: 0.23812143504619598\n",
      "Epoch 0: train loss: 0.0644713044166565\n",
      "Epoch 0: train loss: 0.1526830792427063\n",
      "Epoch 0: train loss: 0.2781192660331726\n",
      "Epoch 0: train loss: 0.14002099633216858\n",
      "Epoch 0: train loss: 0.12194626778364182\n",
      "Epoch 0: train loss: 0.06340420246124268\n",
      "Epoch 0: train loss: 0.34006357192993164\n",
      "Epoch 0: train loss: 0.058683715760707855\n",
      "Epoch 0: train loss: 0.029223226010799408\n",
      "Epoch 0: train loss: 0.025471042841672897\n",
      "Epoch 0: train loss: 0.2592979967594147\n",
      "Epoch 0: train loss: 0.21273598074913025\n",
      "Epoch 0: train loss: 0.22981339693069458\n",
      "Epoch 0: train loss: 0.41392698884010315\n",
      "Epoch 0: train loss: 0.31647104024887085\n",
      "Epoch 0: train loss: 0.04061207175254822\n",
      "Epoch 0: train loss: 0.17454101145267487\n",
      "Epoch 0: train loss: 0.284440815448761\n",
      "Epoch 0: train loss: 0.1313256174325943\n",
      "Epoch 0: train loss: 0.34929218888282776\n",
      "Epoch 0: train loss: 0.07262088358402252\n",
      "Epoch 0: train loss: 0.0675184428691864\n",
      "Epoch 0: train loss: 0.2609747648239136\n",
      "Epoch 0: train loss: 0.21822789311408997\n",
      "Epoch 0: train loss: 0.4132453203201294\n",
      "Epoch 0: train loss: 0.1427893340587616\n",
      "Epoch 0: train loss: 0.30789023637771606\n",
      "Epoch 0: train loss: 0.2057000696659088\n",
      "Epoch 0: train loss: 0.0590038038790226\n",
      "Epoch 0: train loss: 0.249892920255661\n",
      "Epoch 0: train loss: 0.21425162255764008\n",
      "Epoch 0: train loss: 0.26100829243659973\n",
      "Epoch 0: train loss: 0.19097639620304108\n",
      "Epoch 0: train loss: 0.05614829435944557\n",
      "Epoch 0: train loss: 0.20018327236175537\n",
      "Epoch 0: train loss: 0.3083442747592926\n",
      "Epoch 0: train loss: 0.17259836196899414\n",
      "Epoch 0: train loss: 0.03914956375956535\n",
      "Epoch 0: train loss: 0.13035352528095245\n",
      "Epoch 0: train loss: 0.22635820508003235\n",
      "Epoch 0: train loss: 0.14970077574253082\n",
      "Epoch 0: train loss: 0.2596151530742645\n",
      "Epoch 0: train loss: 0.10397152602672577\n",
      "Epoch 0: train loss: 0.14256368577480316\n",
      "Epoch 0: train loss: 0.03757458180189133\n",
      "Epoch 0: train loss: 0.308798223733902\n",
      "Epoch 0: train loss: 0.1605175882577896\n",
      "Epoch 0: train loss: 0.03455662727355957\n",
      "Epoch 0: train loss: 0.07266601175069809\n",
      "Epoch 0: train loss: 0.608633279800415\n",
      "Epoch 0: train loss: 0.1378268599510193\n",
      "Epoch 0: train loss: 0.19504420459270477\n",
      "Epoch 0: train loss: 0.4027368128299713\n",
      "Epoch 0: train loss: 0.15482495725154877\n",
      "Epoch 0: train loss: 0.19893839955329895\n",
      "Epoch 0: train loss: 0.2688138484954834\n",
      "Epoch 0: train loss: 0.1594085544347763\n",
      "Epoch 0: train loss: 0.38755810260772705\n",
      "Epoch 0: train loss: 0.16456124186515808\n",
      "Epoch 0: train loss: 0.08112820237874985\n",
      "Epoch 0: train loss: 0.15218190848827362\n",
      "Epoch 0: train loss: 0.20816971361637115\n",
      "Epoch 0: train loss: 0.33742713928222656\n",
      "Epoch 0: train loss: 0.1367129236459732\n",
      "Epoch 0: train loss: 0.23032580316066742\n",
      "Epoch 0: train loss: 0.1669621467590332\n",
      "Epoch 0: train loss: 0.12582997977733612\n",
      "Epoch 0: train loss: 0.0719977393746376\n",
      "Epoch 0: train loss: 0.16771522164344788\n",
      "Epoch 0: train loss: 0.22380781173706055\n",
      "Epoch 0: train loss: 0.25312158465385437\n",
      "Epoch 0: train loss: 0.25627657771110535\n",
      "Epoch 0: train loss: 0.21431690454483032\n",
      "Epoch 0: train loss: 0.515550434589386\n",
      "Epoch 0: train loss: 0.10002339631319046\n",
      "Epoch 0: train loss: 0.1334347426891327\n",
      "Epoch 0: train loss: 0.18284118175506592\n",
      "Epoch 0: train loss: 0.0838242918252945\n",
      "Epoch 0: train loss: 0.3093443214893341\n",
      "Epoch 0: train loss: 0.3217983543872833\n",
      "Epoch 0: train loss: 0.13327853381633759\n",
      "Epoch 0: train loss: 0.04166188836097717\n",
      "Epoch 1: train loss: 0.2741669714450836\n",
      "Epoch 1: train loss: 0.31384187936782837\n",
      "Epoch 1: train loss: 0.22002634406089783\n",
      "Epoch 1: train loss: 0.16385579109191895\n",
      "Epoch 1: train loss: 0.11063825339078903\n",
      "Epoch 1: train loss: 0.12633727490901947\n",
      "Epoch 1: train loss: 0.20319804549217224\n",
      "Epoch 1: train loss: 0.14907528460025787\n",
      "Epoch 1: train loss: 0.15891948342323303\n",
      "Epoch 1: train loss: 0.17239244282245636\n",
      "Epoch 1: train loss: 0.06575678288936615\n",
      "Epoch 1: train loss: 0.18279851973056793\n",
      "Epoch 1: train loss: 0.13675768673419952\n",
      "Epoch 1: train loss: 0.14889636635780334\n",
      "Epoch 1: train loss: 0.2359105348587036\n",
      "Epoch 1: train loss: 0.12760598957538605\n",
      "Epoch 1: train loss: 0.07943805307149887\n",
      "Epoch 1: train loss: 0.6431731581687927\n",
      "Epoch 1: train loss: 0.19105444848537445\n",
      "Epoch 1: train loss: 0.21262359619140625\n",
      "Epoch 1: train loss: 0.11161737143993378\n",
      "Epoch 1: train loss: 0.30354079604148865\n",
      "Epoch 1: train loss: 0.18978412449359894\n",
      "Epoch 1: train loss: 0.3530295193195343\n",
      "Epoch 1: train loss: 0.12577582895755768\n",
      "Epoch 1: train loss: 0.18260551989078522\n",
      "Epoch 1: train loss: 0.19897325336933136\n",
      "Epoch 1: train loss: 0.2646949589252472\n",
      "Epoch 1: train loss: 0.22942091524600983\n",
      "Epoch 1: train loss: 0.11555906385183334\n",
      "Epoch 1: train loss: 0.3868839144706726\n",
      "Epoch 1: train loss: 0.15447521209716797\n",
      "Epoch 1: train loss: 0.21299409866333008\n",
      "Epoch 1: train loss: 0.04983590170741081\n",
      "Epoch 1: train loss: 0.10352024435997009\n",
      "Epoch 1: train loss: 0.16132409870624542\n",
      "Epoch 1: train loss: 0.09748262912034988\n",
      "Epoch 1: train loss: 0.10843688249588013\n",
      "Epoch 1: train loss: 0.4155946373939514\n",
      "Epoch 1: train loss: 0.05040600150823593\n",
      "Epoch 1: train loss: 0.17936941981315613\n",
      "Epoch 1: train loss: 0.041183654218912125\n",
      "Epoch 1: train loss: 0.05045151710510254\n",
      "Epoch 1: train loss: 0.18135122954845428\n",
      "Epoch 1: train loss: 0.4499537944793701\n",
      "Epoch 1: train loss: 0.1284453123807907\n",
      "Epoch 1: train loss: 0.06263720244169235\n",
      "Epoch 1: train loss: 0.05888507887721062\n",
      "Epoch 1: train loss: 0.30391019582748413\n",
      "Epoch 1: train loss: 0.16542766988277435\n",
      "Epoch 1: train loss: 0.05758543685078621\n",
      "Epoch 1: train loss: 0.1406320035457611\n",
      "Epoch 1: train loss: 0.08257489651441574\n",
      "Epoch 1: train loss: 0.11629859358072281\n",
      "Epoch 1: train loss: 0.5221672654151917\n",
      "Epoch 1: train loss: 0.37044137716293335\n",
      "Epoch 1: train loss: 0.22199027240276337\n",
      "Epoch 1: train loss: 0.18291285634040833\n",
      "Epoch 1: train loss: 0.11691229045391083\n",
      "Epoch 1: train loss: 0.26600009202957153\n",
      "Epoch 1: train loss: 0.11862053722143173\n",
      "Epoch 1: train loss: 0.10211385041475296\n",
      "Epoch 1: train loss: 0.32314878702163696\n",
      "Epoch 1: train loss: 0.12334839254617691\n",
      "Epoch 1: train loss: 0.2760861814022064\n",
      "Epoch 1: train loss: 0.28223007917404175\n",
      "Epoch 1: train loss: 0.2517227530479431\n",
      "Epoch 1: train loss: 0.0790049135684967\n",
      "Epoch 1: train loss: 0.14034974575042725\n",
      "Epoch 1: train loss: 0.08634887635707855\n",
      "Epoch 1: train loss: 0.354117214679718\n",
      "Epoch 1: train loss: 0.21255770325660706\n",
      "Epoch 1: train loss: 0.20376256108283997\n",
      "Epoch 1: train loss: 0.061656951904296875\n",
      "Epoch 1: train loss: 0.052227940410375595\n",
      "Epoch 1: train loss: 0.3414521813392639\n",
      "Epoch 1: train loss: 0.26382777094841003\n",
      "Epoch 1: train loss: 0.17138272523880005\n",
      "Epoch 1: train loss: 0.23736034333705902\n",
      "Epoch 1: train loss: 0.3020308017730713\n",
      "Epoch 1: train loss: 0.1310829520225525\n",
      "Epoch 1: train loss: 0.17686665058135986\n",
      "Epoch 1: train loss: 0.29231590032577515\n",
      "Epoch 1: train loss: 0.08183130621910095\n",
      "Epoch 1: train loss: 0.15653422474861145\n",
      "Epoch 1: train loss: 0.041143275797367096\n",
      "Epoch 1: train loss: 0.38766199350357056\n",
      "Epoch 1: train loss: 0.18401221930980682\n",
      "Epoch 1: train loss: 0.05314459279179573\n",
      "Epoch 1: train loss: 0.15495465695858002\n",
      "Epoch 1: train loss: 0.11901450902223587\n",
      "Epoch 1: train loss: 0.2131933569908142\n",
      "Epoch 1: train loss: 0.3159133195877075\n",
      "Epoch 1: train loss: 0.1267145872116089\n",
      "Epoch 1: train loss: 0.19053839147090912\n",
      "Epoch 1: train loss: 0.24003277719020844\n",
      "Epoch 1: train loss: 0.28387394547462463\n",
      "Epoch 1: train loss: 0.3562301993370056\n",
      "Epoch 1: train loss: 0.10949438810348511\n",
      "Epoch 1: train loss: 0.13898314535617828\n",
      "Epoch 1: train loss: 0.2973434031009674\n",
      "Epoch 1: train loss: 0.33360689878463745\n",
      "Epoch 1: train loss: 0.42041969299316406\n",
      "Epoch 1: train loss: 0.07088098675012589\n",
      "Epoch 1: train loss: 0.25642699003219604\n",
      "Epoch 1: train loss: 0.361409068107605\n",
      "Epoch 1: train loss: 0.2935967445373535\n",
      "Epoch 1: train loss: 0.19445908069610596\n",
      "Epoch 1: train loss: 0.2526910901069641\n",
      "Epoch 1: train loss: 0.14433342218399048\n",
      "Epoch 1: train loss: 0.19645532965660095\n",
      "Epoch 1: train loss: 0.24823209643363953\n",
      "Epoch 1: train loss: 0.14653095602989197\n",
      "Epoch 1: train loss: 0.25566399097442627\n",
      "Epoch 1: train loss: 0.4284895956516266\n",
      "Epoch 1: train loss: 0.17105808854103088\n",
      "Epoch 1: train loss: 0.1750849336385727\n",
      "Epoch 1: train loss: 0.15031270682811737\n",
      "Epoch 1: train loss: 0.2769727408885956\n",
      "Epoch 1: train loss: 0.09586310386657715\n",
      "Epoch 1: train loss: 0.35853585600852966\n",
      "Epoch 1: train loss: 0.14705513417720795\n",
      "Epoch 1: train loss: 0.15654726326465607\n",
      "Epoch 1: train loss: 0.04003150761127472\n",
      "Epoch 1: train loss: 0.30434492230415344\n",
      "Epoch 1: train loss: 0.06273838132619858\n",
      "Epoch 1: train loss: 0.25756463408470154\n",
      "Epoch 1: train loss: 0.1479927897453308\n",
      "Epoch 1: train loss: 0.17605671286582947\n",
      "Epoch 1: train loss: 0.11317390948534012\n",
      "Epoch 1: train loss: 0.11429738998413086\n",
      "Epoch 1: train loss: 0.024220487102866173\n",
      "Epoch 1: train loss: 0.42348310351371765\n",
      "Epoch 1: train loss: 0.07861576974391937\n",
      "Epoch 1: train loss: 0.44203656911849976\n",
      "Epoch 1: train loss: 0.28093793988227844\n",
      "Epoch 1: train loss: 0.06776611506938934\n",
      "Epoch 1: train loss: 0.36436495184898376\n",
      "Epoch 1: train loss: 0.24909161031246185\n",
      "Epoch 1: train loss: 0.2036711424589157\n",
      "Epoch 1: train loss: 0.22501511871814728\n",
      "Epoch 1: train loss: 0.32796189188957214\n",
      "Epoch 1: train loss: 0.2572247385978699\n",
      "Epoch 1: train loss: 0.300639808177948\n",
      "Epoch 1: train loss: 0.23492440581321716\n",
      "Epoch 1: train loss: 0.22987675666809082\n",
      "Epoch 1: train loss: 0.11681904643774033\n",
      "Epoch 1: train loss: 0.08488006144762039\n",
      "Epoch 1: train loss: 0.23311786353588104\n",
      "Epoch 1: train loss: 0.10959083586931229\n",
      "Epoch 1: train loss: 0.2671608030796051\n",
      "Epoch 1: train loss: 0.1795865297317505\n",
      "Epoch 1: train loss: 0.13356409966945648\n",
      "Epoch 1: train loss: 0.1240747943520546\n",
      "Epoch 1: train loss: 0.0849306657910347\n",
      "Epoch 1: train loss: 0.15658457577228546\n",
      "Epoch 1: train loss: 0.14490948617458344\n",
      "Epoch 1: train loss: 0.30570006370544434\n",
      "Epoch 1: train loss: 0.21470873057842255\n",
      "Epoch 1: train loss: 0.2893747389316559\n",
      "Epoch 1: train loss: 0.20922447741031647\n",
      "Epoch 1: train loss: 0.16927894949913025\n",
      "Epoch 1: train loss: 0.10188573598861694\n",
      "Epoch 1: train loss: 0.24429799616336823\n",
      "Epoch 1: train loss: 0.043405931442976\n",
      "Epoch 1: train loss: 0.042376816272735596\n",
      "Epoch 1: train loss: 0.18979594111442566\n",
      "Epoch 1: train loss: 0.43569672107696533\n",
      "Epoch 1: train loss: 0.23700156807899475\n",
      "Epoch 1: train loss: 0.114066943526268\n",
      "Epoch 1: train loss: 0.31534484028816223\n",
      "Epoch 1: train loss: 0.1437850147485733\n",
      "Epoch 1: train loss: 0.14252018928527832\n",
      "Epoch 1: train loss: 0.19418935477733612\n",
      "Epoch 1: train loss: 0.07450930774211884\n",
      "Epoch 1: train loss: 0.21368344128131866\n",
      "Epoch 1: train loss: 0.20445525646209717\n",
      "Epoch 1: train loss: 0.1607864648103714\n",
      "Epoch 1: train loss: 0.05315738171339035\n",
      "Epoch 1: train loss: 0.11066560447216034\n",
      "Epoch 1: train loss: 0.2832717299461365\n",
      "Epoch 1: train loss: 0.035284291952848434\n",
      "Epoch 1: train loss: 0.26979026198387146\n",
      "Epoch 1: train loss: 0.03884217515587807\n",
      "Epoch 1: train loss: 0.09411655366420746\n",
      "Epoch 1: train loss: 0.03277980908751488\n",
      "Epoch 1: train loss: 0.04659552499651909\n",
      "Epoch 1: train loss: 0.09697301685810089\n",
      "Epoch 1: train loss: 0.057112015783786774\n",
      "Epoch 1: train loss: 0.39009711146354675\n",
      "Epoch 1: train loss: 0.7064813375473022\n",
      "Epoch 1: train loss: 0.16045109927654266\n",
      "Epoch 1: train loss: 0.15186765789985657\n",
      "Epoch 1: train loss: 0.24663081765174866\n",
      "Epoch 1: train loss: 0.28432491421699524\n",
      "Epoch 1: train loss: 0.2346944957971573\n",
      "Epoch 1: train loss: 0.24390967190265656\n",
      "Epoch 1: train loss: 0.1378549337387085\n",
      "Epoch 1: train loss: 0.24584762752056122\n",
      "Epoch 1: train loss: 0.06589136272668839\n",
      "Epoch 1: train loss: 0.20476463437080383\n",
      "Epoch 1: train loss: 0.332579106092453\n",
      "Epoch 1: train loss: 0.09091924130916595\n",
      "Epoch 1: train loss: 0.16158746182918549\n",
      "Epoch 1: train loss: 0.08788451552391052\n",
      "Epoch 1: train loss: 0.313321590423584\n",
      "Epoch 1: train loss: 0.22967487573623657\n",
      "Epoch 1: train loss: 0.10245215892791748\n",
      "Epoch 1: train loss: 0.15296849608421326\n",
      "Epoch 1: train loss: 0.16158580780029297\n",
      "Epoch 1: train loss: 0.2732485234737396\n",
      "Epoch 1: train loss: 0.49839797616004944\n",
      "Epoch 1: train loss: 0.19944219291210175\n",
      "Epoch 1: train loss: 0.156476691365242\n",
      "Epoch 1: train loss: 0.11209090799093246\n",
      "Epoch 1: train loss: 0.30413225293159485\n",
      "Epoch 1: train loss: 0.30640342831611633\n",
      "Epoch 1: train loss: 0.17380370199680328\n",
      "Epoch 1: train loss: 0.41048160195350647\n",
      "Epoch 1: train loss: 0.3542116582393646\n",
      "Epoch 1: train loss: 0.055713020265102386\n",
      "Epoch 1: train loss: 0.43599268794059753\n",
      "Epoch 1: train loss: 0.14207151532173157\n",
      "Epoch 1: train loss: 0.1130899116396904\n",
      "Epoch 1: train loss: 0.13977251946926117\n",
      "Epoch 1: train loss: 0.09910783916711807\n",
      "Epoch 1: train loss: 0.1280059665441513\n",
      "Epoch 1: train loss: 0.24393074214458466\n",
      "Epoch 1: train loss: 0.18102699518203735\n",
      "Epoch 1: train loss: 0.1853453516960144\n",
      "Epoch 1: train loss: 0.25281408429145813\n",
      "Epoch 1: train loss: 0.1842728555202484\n",
      "Epoch 1: train loss: 0.17061516642570496\n",
      "Epoch 1: train loss: 0.20459683239459991\n",
      "Epoch 1: train loss: 0.09210029989480972\n",
      "Epoch 1: train loss: 0.034873005002737045\n",
      "Epoch 1: train loss: 0.27711957693099976\n",
      "Epoch 1: train loss: 0.14478173851966858\n",
      "Epoch 1: train loss: 0.09166709333658218\n",
      "Epoch 1: train loss: 0.23471561074256897\n",
      "Epoch 1: train loss: 0.09113539010286331\n",
      "Epoch 1: train loss: 0.22111698985099792\n",
      "Epoch 1: train loss: 0.04481670632958412\n",
      "Epoch 1: train loss: 0.0530538335442543\n",
      "Epoch 1: train loss: 0.14752835035324097\n",
      "Epoch 1: train loss: 0.09784943610429764\n",
      "Epoch 1: train loss: 0.33089905977249146\n",
      "Epoch 1: train loss: 0.05164993181824684\n",
      "Epoch 1: train loss: 0.058944012969732285\n",
      "Epoch 1: train loss: 0.17829659581184387\n",
      "Epoch 1: train loss: 0.3119293451309204\n",
      "Epoch 1: train loss: 0.6217594742774963\n",
      "Epoch 1: train loss: 0.14018435776233673\n",
      "Epoch 1: train loss: 0.29062771797180176\n",
      "Epoch 1: train loss: 0.09169397503137589\n",
      "Epoch 1: train loss: 0.15052132308483124\n",
      "Epoch 1: train loss: 0.1381024718284607\n",
      "Epoch 1: train loss: 0.12141957134008408\n",
      "Epoch 1: train loss: 0.4921870529651642\n",
      "Epoch 1: train loss: 0.1130048856139183\n",
      "Epoch 1: train loss: 0.08186396211385727\n",
      "Epoch 1: train loss: 0.1825588345527649\n",
      "Epoch 1: train loss: 0.11842116713523865\n",
      "Epoch 1: train loss: 0.055899135768413544\n",
      "Epoch 1: train loss: 0.1801758110523224\n",
      "Epoch 1: train loss: 0.18424300849437714\n",
      "Epoch 1: train loss: 0.06228184700012207\n",
      "Epoch 1: train loss: 0.13992489874362946\n",
      "Epoch 1: train loss: 0.05423963442444801\n",
      "Epoch 1: train loss: 0.04679316282272339\n",
      "Epoch 1: train loss: 0.289542555809021\n",
      "Epoch 1: train loss: 0.06182429566979408\n",
      "Epoch 1: train loss: 0.5928170084953308\n",
      "Epoch 1: train loss: 0.3144931197166443\n",
      "Epoch 1: train loss: 0.050063714385032654\n",
      "Epoch 1: train loss: 0.12696199119091034\n",
      "Epoch 1: train loss: 0.11488451808691025\n",
      "Epoch 1: train loss: 0.4814300239086151\n",
      "Epoch 1: train loss: 0.17837831377983093\n",
      "Epoch 1: train loss: 0.16993378102779388\n",
      "Epoch 1: train loss: 0.38044747710227966\n",
      "Epoch 1: train loss: 0.2979060709476471\n",
      "Epoch 1: train loss: 0.048768263310194016\n",
      "Epoch 1: train loss: 0.24455995857715607\n",
      "Epoch 1: train loss: 0.12010867893695831\n",
      "Epoch 1: train loss: 0.12466832250356674\n",
      "Epoch 1: train loss: 0.16336269676685333\n",
      "Epoch 1: train loss: 0.19064342975616455\n",
      "Epoch 1: train loss: 0.2577405571937561\n",
      "Epoch 1: train loss: 0.06564729660749435\n",
      "Epoch 1: train loss: 0.2676685154438019\n",
      "Epoch 1: train loss: 0.22239556908607483\n",
      "Epoch 1: train loss: 0.08803297579288483\n",
      "Epoch 1: train loss: 0.14415565133094788\n",
      "Epoch 1: train loss: 0.1526113897562027\n",
      "Epoch 1: train loss: 0.31770846247673035\n",
      "Epoch 1: train loss: 0.39101842045783997\n",
      "Epoch 1: train loss: 0.1275888830423355\n",
      "Epoch 1: train loss: 0.2918224334716797\n",
      "Epoch 1: train loss: 0.10970903187990189\n",
      "Epoch 1: train loss: 0.11226267367601395\n",
      "Epoch 1: train loss: 0.23680368065834045\n",
      "Epoch 1: train loss: 0.19292014837265015\n",
      "Epoch 1: train loss: 0.16807644069194794\n",
      "Epoch 1: train loss: 0.15437935292720795\n",
      "Epoch 1: train loss: 0.3320280611515045\n",
      "Epoch 1: train loss: 0.2541228234767914\n",
      "Epoch 1: train loss: 0.3133023977279663\n",
      "Epoch 1: train loss: 0.2465239018201828\n",
      "Epoch 1: train loss: 0.10923102498054504\n",
      "Epoch 1: train loss: 0.3521978259086609\n",
      "Epoch 1: train loss: 0.26735618710517883\n",
      "Epoch 1: train loss: 0.3307056725025177\n",
      "Epoch 1: train loss: 0.07234606146812439\n",
      "Epoch 1: train loss: 0.17958132922649384\n",
      "Epoch 1: train loss: 0.22914652526378632\n",
      "Epoch 1: train loss: 0.2048177719116211\n",
      "Epoch 1: train loss: 0.18052814900875092\n",
      "Epoch 1: train loss: 0.09865794330835342\n",
      "Epoch 1: train loss: 0.3735051155090332\n",
      "Epoch 1: train loss: 0.05282419174909592\n",
      "Epoch 1: train loss: 0.2218119353055954\n",
      "Epoch 1: train loss: 0.2922683358192444\n",
      "Epoch 1: train loss: 0.06056898459792137\n",
      "Epoch 1: train loss: 0.09373461455106735\n",
      "Epoch 1: train loss: 0.16088908910751343\n",
      "Epoch 1: train loss: 0.23552609980106354\n",
      "Epoch 1: train loss: 0.20006781816482544\n",
      "Epoch 1: train loss: 0.17310847342014313\n",
      "Epoch 1: train loss: 0.14053216576576233\n",
      "Epoch 1: train loss: 0.18555255234241486\n",
      "Epoch 1: train loss: 0.19752737879753113\n",
      "Epoch 1: train loss: 0.2883068025112152\n",
      "Epoch 1: train loss: 0.14675280451774597\n",
      "Epoch 1: train loss: 0.17131537199020386\n",
      "Epoch 1: train loss: 0.0758771076798439\n",
      "Epoch 1: train loss: 0.4059937298297882\n",
      "Epoch 1: train loss: 0.18735121190547943\n",
      "Epoch 1: train loss: 0.28234437108039856\n",
      "Epoch 1: train loss: 0.2779330611228943\n",
      "Epoch 1: train loss: 0.06895343959331512\n",
      "Epoch 1: train loss: 0.27652180194854736\n",
      "Epoch 1: train loss: 0.1997314840555191\n",
      "Epoch 1: train loss: 0.25423064827919006\n",
      "Epoch 1: train loss: 0.29118812084198\n",
      "Epoch 1: train loss: 0.16104350984096527\n",
      "Epoch 1: train loss: 0.3761482536792755\n",
      "Epoch 1: train loss: 0.16008466482162476\n",
      "Epoch 1: train loss: 0.32849863171577454\n",
      "Epoch 1: train loss: 0.2799969017505646\n",
      "Epoch 1: train loss: 0.14923720061779022\n",
      "Epoch 1: train loss: 0.1423209309577942\n",
      "Epoch 1: train loss: 0.1509695053100586\n",
      "Epoch 1: train loss: 0.20366333425045013\n",
      "Epoch 1: train loss: 0.09836409240961075\n",
      "Epoch 1: train loss: 0.18829315900802612\n",
      "Epoch 1: train loss: 0.04675932973623276\n",
      "Epoch 1: train loss: 0.175344318151474\n",
      "Epoch 1: train loss: 0.28321367502212524\n",
      "Epoch 1: train loss: 0.2419532835483551\n",
      "Epoch 1: train loss: 0.2199678272008896\n",
      "Epoch 1: train loss: 0.09235240519046783\n",
      "Epoch 1: train loss: 0.14849337935447693\n",
      "Epoch 1: train loss: 0.12914152443408966\n",
      "Epoch 1: train loss: 0.15685994923114777\n",
      "Epoch 1: train loss: 0.12148094177246094\n",
      "Epoch 1: train loss: 0.1949630230665207\n",
      "Epoch 1: train loss: 0.22767063975334167\n",
      "Epoch 1: train loss: 0.032206904143095016\n",
      "Epoch 1: train loss: 0.15529407560825348\n",
      "Epoch 1: train loss: 0.09996092319488525\n",
      "Epoch 1: train loss: 0.11660521477460861\n",
      "Epoch 1: train loss: 0.22742585837841034\n",
      "Epoch 1: train loss: 0.22771210968494415\n",
      "Epoch 1: train loss: 0.20980995893478394\n",
      "Epoch 1: train loss: 0.08976307511329651\n",
      "Epoch 1: train loss: 0.26282259821891785\n",
      "Epoch 1: train loss: 0.22733573615550995\n",
      "Epoch 1: train loss: 0.27737560868263245\n",
      "Epoch 1: train loss: 0.27499130368232727\n",
      "Epoch 1: train loss: 0.3005322217941284\n",
      "Epoch 1: train loss: 0.1407364159822464\n",
      "Epoch 1: train loss: 0.1366889625787735\n",
      "Epoch 1: train loss: 0.1786201149225235\n",
      "Epoch 1: train loss: 0.2106664925813675\n",
      "Epoch 1: train loss: 0.4488249719142914\n",
      "Epoch 1: train loss: 0.24167807400226593\n",
      "Epoch 1: train loss: 0.35233259201049805\n",
      "Epoch 1: train loss: 0.1974811851978302\n",
      "Epoch 1: train loss: 0.3355678915977478\n",
      "Epoch 1: train loss: 0.14096280932426453\n",
      "Epoch 1: train loss: 0.13750313222408295\n",
      "Epoch 1: train loss: 0.19007427990436554\n",
      "Epoch 1: train loss: 0.2466105818748474\n",
      "Epoch 1: train loss: 0.11402048170566559\n",
      "Epoch 1: train loss: 0.05213339626789093\n",
      "Epoch 1: train loss: 0.39200687408447266\n",
      "Epoch 1: train loss: 0.12592044472694397\n",
      "Epoch 1: train loss: 0.13530413806438446\n",
      "Epoch 1: train loss: 0.40602365136146545\n",
      "Epoch 1: train loss: 0.14196844398975372\n",
      "Epoch 1: train loss: 0.11140666157007217\n",
      "Epoch 1: train loss: 0.1485663801431656\n",
      "Epoch 1: train loss: 0.05624993517994881\n",
      "Epoch 1: train loss: 0.12011469155550003\n",
      "Epoch 1: train loss: 0.06705176830291748\n",
      "Epoch 1: train loss: 0.24919846653938293\n",
      "Epoch 1: train loss: 0.3829611837863922\n",
      "Epoch 1: train loss: 0.1773166060447693\n",
      "Epoch 1: train loss: 0.1715729981660843\n",
      "Epoch 1: train loss: 0.08777093142271042\n",
      "Epoch 1: train loss: 0.07290888577699661\n",
      "Epoch 1: train loss: 0.16473864018917084\n",
      "Epoch 1: train loss: 0.2572663724422455\n",
      "Epoch 1: train loss: 0.11444855481386185\n",
      "Epoch 1: train loss: 0.09956207126379013\n",
      "Epoch 1: train loss: 0.04262896999716759\n",
      "Epoch 1: train loss: 0.13961398601531982\n",
      "Epoch 1: train loss: 0.3040519654750824\n",
      "Epoch 1: train loss: 0.16607271134853363\n",
      "Epoch 1: train loss: 0.26436159014701843\n",
      "Epoch 1: train loss: 0.16474851965904236\n",
      "Epoch 1: train loss: 0.4450857937335968\n",
      "Epoch 1: train loss: 0.28216302394866943\n",
      "Epoch 1: train loss: 0.16825056076049805\n",
      "Epoch 1: train loss: 0.2372959852218628\n",
      "Epoch 1: train loss: 0.4879428744316101\n",
      "Epoch 1: train loss: 0.20859508216381073\n",
      "Epoch 1: train loss: 0.1667647808790207\n",
      "Epoch 1: train loss: 0.13046228885650635\n",
      "Epoch 1: train loss: 0.11681006848812103\n",
      "Epoch 1: train loss: 0.20266565680503845\n",
      "Epoch 1: train loss: 0.22013163566589355\n",
      "Epoch 1: train loss: 0.10765484720468521\n",
      "Epoch 1: train loss: 0.28591692447662354\n",
      "Epoch 1: train loss: 0.11415605247020721\n",
      "Epoch 1: train loss: 0.2358870953321457\n",
      "Epoch 1: train loss: 0.41904595494270325\n",
      "Epoch 1: train loss: 0.15136712789535522\n",
      "Epoch 1: train loss: 0.17071722447872162\n",
      "Epoch 1: train loss: 0.04587394371628761\n",
      "Epoch 1: train loss: 0.0812823623418808\n",
      "Epoch 1: train loss: 0.09481380134820938\n",
      "Epoch 1: train loss: 0.06588571518659592\n",
      "Epoch 1: train loss: 0.3297536373138428\n",
      "Epoch 1: train loss: 0.2462131381034851\n",
      "Epoch 1: train loss: 0.13261497020721436\n",
      "Epoch 1: train loss: 0.2612709701061249\n",
      "Epoch 1: train loss: 0.07877757400274277\n",
      "Epoch 1: train loss: 0.2098599523305893\n",
      "Epoch 1: train loss: 0.058531202375888824\n",
      "Epoch 1: train loss: 0.14408449828624725\n",
      "Epoch 1: train loss: 0.06842239946126938\n",
      "Epoch 1: train loss: 0.1651208996772766\n",
      "Epoch 1: train loss: 0.06797919422388077\n",
      "Epoch 1: train loss: 0.08408856391906738\n",
      "Epoch 1: train loss: 0.04933333024382591\n",
      "Epoch 1: train loss: 0.41872477531433105\n",
      "Epoch 1: train loss: 0.14663094282150269\n",
      "Epoch 1: train loss: 0.053296975791454315\n",
      "Epoch 1: train loss: 0.21291564404964447\n",
      "Epoch 1: train loss: 0.3516012132167816\n",
      "Epoch 1: train loss: 0.18274760246276855\n",
      "Epoch 1: train loss: 0.42390093207359314\n",
      "Epoch 1: train loss: 0.30178898572921753\n",
      "Epoch 1: train loss: 0.1230519637465477\n",
      "Epoch 1: train loss: 0.18866921961307526\n",
      "Epoch 1: train loss: 0.09961224347352982\n",
      "Epoch 1: train loss: 0.3246438205242157\n",
      "Epoch 1: train loss: 0.08632875978946686\n",
      "Epoch 1: train loss: 0.09367433190345764\n",
      "Epoch 1: train loss: 0.1386081576347351\n",
      "Epoch 1: train loss: 0.3805156946182251\n",
      "Epoch 1: train loss: 0.20095771551132202\n",
      "Epoch 1: train loss: 0.18861614167690277\n",
      "Epoch 1: train loss: 0.3632853925228119\n",
      "Epoch 1: train loss: 0.08913201838731766\n",
      "Epoch 1: train loss: 0.41409045457839966\n",
      "Epoch 1: train loss: 0.2963593900203705\n",
      "Epoch 1: train loss: 0.1748669147491455\n",
      "Epoch 1: train loss: 0.13887254893779755\n",
      "Epoch 1: train loss: 0.08720621466636658\n",
      "Epoch 1: train loss: 0.15384505689144135\n",
      "Epoch 1: train loss: 0.06018275395035744\n",
      "Epoch 1: train loss: 0.09615085273981094\n",
      "Epoch 1: train loss: 0.04989130422472954\n",
      "Epoch 1: train loss: 0.24381855130195618\n",
      "Epoch 1: train loss: 0.24134297668933868\n",
      "Epoch 1: train loss: 0.08374843001365662\n",
      "Epoch 1: train loss: 0.05624757707118988\n",
      "Epoch 1: train loss: 0.14728042483329773\n",
      "Epoch 1: train loss: 0.1538664996623993\n",
      "Epoch 1: train loss: 0.14900170266628265\n",
      "Epoch 1: train loss: 0.03192063421010971\n",
      "Epoch 1: train loss: 0.3217869997024536\n",
      "Epoch 1: train loss: 0.14444907009601593\n",
      "Epoch 1: train loss: 0.10402587801218033\n",
      "Epoch 1: train loss: 0.2645164430141449\n",
      "Epoch 1: train loss: 0.22295328974723816\n",
      "Epoch 1: train loss: 0.18779854476451874\n",
      "Epoch 1: train loss: 0.18036912381649017\n",
      "Epoch 1: train loss: 0.06348592787981033\n",
      "Epoch 1: train loss: 0.07994286715984344\n",
      "Epoch 1: train loss: 0.08464033156633377\n",
      "Epoch 1: train loss: 0.053109217435121536\n",
      "Epoch 1: train loss: 0.20535549521446228\n",
      "Epoch 1: train loss: 0.33237650990486145\n",
      "Epoch 1: train loss: 0.16360490024089813\n",
      "Epoch 1: train loss: 0.06399956345558167\n",
      "Epoch 1: train loss: 0.05637484788894653\n",
      "Epoch 1: train loss: 0.2627273201942444\n",
      "Epoch 1: train loss: 0.08188514411449432\n",
      "Epoch 1: train loss: 0.3221350610256195\n",
      "Epoch 1: train loss: 0.15607313811779022\n",
      "Epoch 1: train loss: 0.22171637415885925\n",
      "Epoch 1: train loss: 0.49833226203918457\n",
      "Epoch 1: train loss: 0.07240878790616989\n",
      "Epoch 1: train loss: 0.24336814880371094\n",
      "Epoch 1: train loss: 0.10025862604379654\n",
      "Epoch 1: train loss: 0.21112218499183655\n",
      "Epoch 1: train loss: 0.21231675148010254\n",
      "Epoch 1: train loss: 0.18934111297130585\n",
      "Epoch 1: train loss: 0.17221267521381378\n",
      "Epoch 1: train loss: 0.08677200973033905\n",
      "Epoch 1: train loss: 0.16526110470294952\n",
      "Epoch 1: train loss: 0.20354798436164856\n",
      "Epoch 1: train loss: 0.09519323706626892\n",
      "Epoch 1: train loss: 0.1606816053390503\n",
      "Epoch 1: train loss: 0.037135496735572815\n",
      "Epoch 1: train loss: 0.2057594656944275\n",
      "Epoch 1: train loss: 0.1672435998916626\n",
      "Epoch 1: train loss: 0.24990476667881012\n",
      "Epoch 1: train loss: 0.3115454316139221\n",
      "Epoch 1: train loss: 0.2621751129627228\n",
      "Epoch 1: train loss: 0.30440467596054077\n",
      "Epoch 1: train loss: 0.23301492631435394\n",
      "Epoch 1: train loss: 0.18177753686904907\n",
      "Epoch 1: train loss: 0.054063331335783005\n",
      "Epoch 1: train loss: 0.15980161726474762\n",
      "Epoch 1: train loss: 0.1931159645318985\n",
      "Epoch 1: train loss: 0.163881316781044\n",
      "Epoch 1: train loss: 0.05975978076457977\n",
      "Epoch 1: train loss: 0.16661961376667023\n",
      "Epoch 1: train loss: 0.41757407784461975\n",
      "Epoch 1: train loss: 0.07550915330648422\n",
      "Epoch 1: train loss: 0.15596966445446014\n",
      "Epoch 1: train loss: 0.32396188378334045\n",
      "Epoch 1: train loss: 0.32591956853866577\n",
      "Epoch 1: train loss: 0.16361956298351288\n",
      "Epoch 1: train loss: 0.23410186171531677\n",
      "Epoch 1: train loss: 0.47618037462234497\n",
      "Epoch 1: train loss: 0.16058309376239777\n",
      "Epoch 1: train loss: 0.09482774138450623\n",
      "Epoch 1: train loss: 0.2604109048843384\n",
      "Epoch 1: train loss: 0.2604561150074005\n",
      "Epoch 1: train loss: 0.08697399497032166\n",
      "Epoch 1: train loss: 0.22406543791294098\n",
      "Epoch 1: train loss: 0.11183527857065201\n",
      "Epoch 1: train loss: 0.1884339600801468\n",
      "Epoch 1: train loss: 0.12236862629652023\n",
      "Epoch 1: train loss: 0.14283092319965363\n",
      "Epoch 1: train loss: 0.19698068499565125\n",
      "Epoch 1: train loss: 0.45151087641716003\n",
      "Epoch 1: train loss: 0.2376306802034378\n",
      "Epoch 1: train loss: 0.16843625903129578\n",
      "Epoch 1: train loss: 0.20373594760894775\n",
      "Epoch 1: train loss: 0.2542917728424072\n",
      "Epoch 1: train loss: 0.23844020068645477\n",
      "Epoch 1: train loss: 0.21499177813529968\n",
      "Epoch 1: train loss: 0.14223924279212952\n",
      "Epoch 1: train loss: 0.2454870641231537\n",
      "Epoch 1: train loss: 0.07079581916332245\n",
      "Epoch 1: train loss: 0.3510154187679291\n",
      "Epoch 1: train loss: 0.17587754130363464\n",
      "Epoch 1: train loss: 0.2560952603816986\n",
      "Epoch 1: train loss: 0.06479641050100327\n",
      "Epoch 1: train loss: 0.08916916698217392\n",
      "Epoch 1: train loss: 0.3284094035625458\n",
      "Epoch 1: train loss: 0.15064257383346558\n",
      "Epoch 1: train loss: 0.1037626639008522\n",
      "Epoch 1: train loss: 0.14586138725280762\n",
      "Epoch 1: train loss: 0.31605958938598633\n",
      "Epoch 1: train loss: 0.11823752522468567\n",
      "Epoch 1: train loss: 0.23033030331134796\n",
      "Epoch 1: train loss: 0.19685770571231842\n",
      "Epoch 1: train loss: 0.17535072565078735\n",
      "Epoch 1: train loss: 0.2666691243648529\n",
      "Epoch 1: train loss: 0.10471125692129135\n",
      "Epoch 1: train loss: 0.3711965084075928\n",
      "Epoch 1: train loss: 0.16253651678562164\n",
      "Epoch 1: train loss: 0.14835511147975922\n",
      "Epoch 1: train loss: 0.09137459844350815\n",
      "Epoch 1: train loss: 0.12934380769729614\n",
      "Epoch 1: train loss: 0.27794069051742554\n",
      "Epoch 1: train loss: 0.05368643254041672\n",
      "Epoch 1: train loss: 0.3004470765590668\n",
      "Epoch 1: train loss: 0.16837812960147858\n",
      "Epoch 1: train loss: 0.23398999869823456\n",
      "Epoch 1: train loss: 0.10368373990058899\n",
      "Epoch 1: train loss: 0.1833794116973877\n",
      "Epoch 1: train loss: 0.23616398870944977\n",
      "Epoch 1: train loss: 0.4819702208042145\n",
      "Epoch 1: train loss: 0.2087765336036682\n",
      "Epoch 1: train loss: 0.16727100312709808\n",
      "Epoch 1: train loss: 0.0707627460360527\n",
      "Epoch 1: train loss: 0.13848872482776642\n",
      "Epoch 1: train loss: 0.08792465180158615\n",
      "Epoch 1: train loss: 0.2092571258544922\n",
      "Epoch 1: train loss: 0.30100640654563904\n",
      "Epoch 1: train loss: 0.3215346336364746\n",
      "Epoch 1: train loss: 0.1982342004776001\n",
      "Epoch 1: train loss: 0.36129751801490784\n",
      "Epoch 1: train loss: 0.3410934805870056\n",
      "Epoch 1: train loss: 0.10942717641592026\n",
      "Epoch 1: train loss: 0.1872721165418625\n",
      "Epoch 1: train loss: 0.2786904573440552\n",
      "Epoch 1: train loss: 0.26112744212150574\n",
      "Epoch 1: train loss: 0.3708811402320862\n",
      "Epoch 1: train loss: 0.21231772005558014\n",
      "Epoch 1: train loss: 0.23800763487815857\n",
      "Epoch 1: train loss: 0.3607941269874573\n",
      "Epoch 1: train loss: 0.1648949831724167\n",
      "Epoch 1: train loss: 0.4259432852268219\n",
      "Epoch 1: train loss: 0.10743319988250732\n",
      "Epoch 1: train loss: 0.37706583738327026\n",
      "Epoch 1: train loss: 0.1370147317647934\n",
      "Epoch 1: train loss: 0.09610137343406677\n",
      "Epoch 1: train loss: 0.0869266614317894\n",
      "Epoch 1: train loss: 0.10210231691598892\n",
      "Epoch 1: train loss: 0.11635229736566544\n",
      "Epoch 1: train loss: 0.21581438183784485\n",
      "Epoch 1: train loss: 0.410857230424881\n",
      "Epoch 1: train loss: 0.2432173192501068\n",
      "Epoch 1: train loss: 0.07466128468513489\n",
      "Epoch 1: train loss: 0.2907941937446594\n",
      "Epoch 1: train loss: 0.046485863626003265\n",
      "Epoch 1: train loss: 0.13997778296470642\n",
      "Epoch 1: train loss: 0.3258763253688812\n",
      "Epoch 1: train loss: 0.41956302523612976\n",
      "Epoch 1: train loss: 0.30692821741104126\n",
      "Epoch 1: train loss: 0.19171373546123505\n",
      "Epoch 1: train loss: 0.11900045722723007\n",
      "Epoch 1: train loss: 0.06184931844472885\n",
      "Epoch 1: train loss: 0.20037057995796204\n",
      "Epoch 1: train loss: 0.3002035915851593\n",
      "Epoch 1: train loss: 0.06506633013486862\n",
      "Epoch 1: train loss: 0.05260256305336952\n",
      "Epoch 1: train loss: 0.38961508870124817\n",
      "Epoch 1: train loss: 0.4715034067630768\n",
      "Epoch 1: train loss: 0.1746034175157547\n",
      "Epoch 1: train loss: 0.19976447522640228\n",
      "Epoch 1: train loss: 0.062388524413108826\n",
      "Epoch 1: train loss: 0.19407963752746582\n",
      "Epoch 1: train loss: 0.31290292739868164\n",
      "Epoch 1: train loss: 0.21362876892089844\n",
      "Epoch 1: train loss: 0.0905291810631752\n",
      "Epoch 1: train loss: 0.37313809990882874\n",
      "Epoch 1: train loss: 0.45401597023010254\n",
      "Epoch 1: train loss: 0.0702013224363327\n",
      "Epoch 1: train loss: 0.10671081393957138\n",
      "Epoch 1: train loss: 0.2748418152332306\n",
      "Epoch 1: train loss: 0.22817490994930267\n",
      "Epoch 1: train loss: 0.3199622631072998\n",
      "Epoch 1: train loss: 0.10444268584251404\n",
      "Epoch 1: train loss: 0.2728595435619354\n",
      "Epoch 1: train loss: 0.13006208837032318\n",
      "Epoch 1: train loss: 0.13174201548099518\n",
      "Epoch 1: train loss: 0.27249854803085327\n",
      "Epoch 1: train loss: 0.18992364406585693\n",
      "Epoch 1: train loss: 0.04940337687730789\n",
      "Epoch 1: train loss: 0.21960118412971497\n",
      "Epoch 1: train loss: 0.15529273450374603\n",
      "Epoch 1: train loss: 0.3804924190044403\n",
      "Epoch 1: train loss: 0.129272922873497\n",
      "Epoch 1: train loss: 0.1391264647245407\n",
      "Epoch 1: train loss: 0.4417894780635834\n",
      "Epoch 1: train loss: 0.2502276301383972\n",
      "Epoch 1: train loss: 0.23092493414878845\n",
      "Epoch 1: train loss: 0.17451971769332886\n",
      "Epoch 1: train loss: 0.19528868794441223\n",
      "Epoch 1: train loss: 0.13206979632377625\n",
      "Epoch 1: train loss: 0.2559112310409546\n",
      "Epoch 1: train loss: 0.24119660258293152\n",
      "Epoch 1: train loss: 0.1683293581008911\n",
      "Epoch 1: train loss: 0.16315950453281403\n",
      "Epoch 1: train loss: 0.2340305894613266\n",
      "Epoch 1: train loss: 0.3279866576194763\n",
      "Epoch 1: train loss: 0.09317474812269211\n",
      "Epoch 1: train loss: 0.25538402795791626\n",
      "Epoch 1: train loss: 0.1008317694067955\n",
      "Epoch 1: train loss: 0.08008890599012375\n",
      "Epoch 1: train loss: 0.08442353457212448\n",
      "Epoch 1: train loss: 0.05010269954800606\n",
      "Epoch 1: train loss: 0.4312364459037781\n",
      "Epoch 1: train loss: 0.27491554617881775\n",
      "Epoch 1: train loss: 0.28752511739730835\n",
      "Epoch 1: train loss: 0.28750813007354736\n",
      "Epoch 1: train loss: 0.14238867163658142\n",
      "Epoch 1: train loss: 0.06656120717525482\n",
      "Epoch 1: train loss: 0.2098754644393921\n",
      "Epoch 1: train loss: 0.3771508038043976\n",
      "Epoch 1: train loss: 0.16713117063045502\n",
      "Epoch 1: train loss: 0.27850577235221863\n",
      "Epoch 1: train loss: 0.12111234664916992\n",
      "Epoch 1: train loss: 0.2219340205192566\n",
      "Epoch 1: train loss: 0.11230584979057312\n",
      "Epoch 1: train loss: 0.1524621695280075\n",
      "Epoch 1: train loss: 0.09920139610767365\n",
      "Epoch 1: train loss: 0.09601010382175446\n",
      "Epoch 1: train loss: 0.08085628598928452\n",
      "Epoch 1: train loss: 0.2673645615577698\n",
      "Epoch 1: train loss: 0.09295567870140076\n",
      "Epoch 1: train loss: 0.030200645327568054\n",
      "Epoch 1: train loss: 0.044399574398994446\n",
      "Epoch 1: train loss: 0.35158076882362366\n",
      "Epoch 1: train loss: 0.29068899154663086\n",
      "Epoch 1: train loss: 0.27579423785209656\n",
      "Epoch 1: train loss: 0.34591439366340637\n",
      "Epoch 1: train loss: 0.17181681096553802\n",
      "Epoch 1: train loss: 0.2509107291698456\n",
      "Epoch 1: train loss: 0.04262837767601013\n",
      "Epoch 1: train loss: 0.2615702450275421\n",
      "Epoch 1: train loss: 0.16730128228664398\n",
      "Epoch 1: train loss: 0.2539092004299164\n",
      "Epoch 1: train loss: 0.2718466520309448\n",
      "Epoch 1: train loss: 0.07673045992851257\n",
      "Epoch 1: train loss: 0.04423205181956291\n",
      "Epoch 1: train loss: 0.09363271296024323\n",
      "Epoch 1: train loss: 0.1576862782239914\n",
      "Epoch 1: train loss: 0.10988704115152359\n",
      "Epoch 1: train loss: 0.3731400668621063\n",
      "Epoch 1: train loss: 0.27446261048316956\n",
      "Epoch 1: train loss: 0.3670318126678467\n",
      "Epoch 1: train loss: 0.2999829351902008\n",
      "Epoch 1: train loss: 0.11241332441568375\n",
      "Epoch 1: train loss: 0.17917653918266296\n",
      "Epoch 1: train loss: 0.11833082884550095\n",
      "Epoch 1: train loss: 0.19716155529022217\n",
      "Epoch 1: train loss: 0.32153958082199097\n",
      "Epoch 1: train loss: 0.0879155695438385\n",
      "Epoch 1: train loss: 0.30173739790916443\n",
      "Epoch 1: train loss: 0.08187900483608246\n",
      "Epoch 1: train loss: 0.18661516904830933\n",
      "Epoch 1: train loss: 0.1505737155675888\n",
      "Epoch 1: train loss: 0.2787227928638458\n",
      "Epoch 1: train loss: 0.18116119503974915\n",
      "Epoch 1: train loss: 0.24784350395202637\n",
      "Epoch 1: train loss: 0.2591727375984192\n",
      "Epoch 1: train loss: 0.20159997045993805\n",
      "Epoch 1: train loss: 0.1746206432580948\n",
      "Epoch 1: train loss: 0.10214617103338242\n",
      "Epoch 1: train loss: 0.20930495858192444\n",
      "Epoch 1: train loss: 0.16618876159191132\n",
      "Epoch 1: train loss: 0.054545897990465164\n",
      "Epoch 1: train loss: 0.14770911633968353\n",
      "Epoch 1: train loss: 0.26462316513061523\n",
      "Epoch 1: train loss: 0.25674140453338623\n",
      "Epoch 1: train loss: 0.12426751106977463\n",
      "Epoch 1: train loss: 0.059657983481884\n",
      "Epoch 1: train loss: 0.42257705330848694\n",
      "Epoch 1: train loss: 0.27053409814834595\n",
      "Epoch 1: train loss: 0.3084185719490051\n",
      "Epoch 1: train loss: 0.24969258904457092\n",
      "Epoch 1: train loss: 0.10436433553695679\n",
      "Epoch 1: train loss: 0.3643304705619812\n",
      "Epoch 1: train loss: 0.22004914283752441\n",
      "Epoch 1: train loss: 0.22470994293689728\n",
      "Epoch 1: train loss: 0.15884020924568176\n",
      "Epoch 1: train loss: 0.2586249113082886\n",
      "Epoch 1: train loss: 0.10165721923112869\n",
      "Epoch 1: train loss: 0.2625944912433624\n",
      "Epoch 1: train loss: 0.2215583324432373\n",
      "Epoch 1: train loss: 0.2569170594215393\n",
      "Epoch 1: train loss: 0.19975176453590393\n",
      "Epoch 1: train loss: 0.40845802426338196\n",
      "Epoch 1: train loss: 0.11328078806400299\n",
      "Epoch 1: train loss: 0.22539830207824707\n",
      "Epoch 1: train loss: 0.35498926043510437\n",
      "Epoch 1: train loss: 0.1635996699333191\n",
      "Epoch 1: train loss: 0.18981291353702545\n",
      "Epoch 1: train loss: 0.17857639491558075\n",
      "Epoch 1: train loss: 0.24990060925483704\n",
      "Epoch 1: train loss: 0.20940297842025757\n",
      "Epoch 1: train loss: 0.257468581199646\n",
      "Epoch 1: train loss: 0.11147056519985199\n",
      "Epoch 1: train loss: 0.3578164577484131\n",
      "Epoch 1: train loss: 0.21339862048625946\n",
      "Epoch 1: train loss: 0.2530069947242737\n",
      "Epoch 1: train loss: 0.18989728391170502\n",
      "Epoch 1: train loss: 0.26858553290367126\n",
      "Epoch 1: train loss: 0.3812246322631836\n",
      "Epoch 1: train loss: 0.19915054738521576\n",
      "Epoch 1: train loss: 0.06216207891702652\n",
      "Epoch 1: train loss: 0.3246650993824005\n",
      "Epoch 1: train loss: 0.21422147750854492\n",
      "Epoch 1: train loss: 0.247602179646492\n",
      "Epoch 1: train loss: 0.3966314196586609\n",
      "Epoch 1: train loss: 0.2513841986656189\n",
      "Epoch 1: train loss: 0.31127458810806274\n",
      "Epoch 1: train loss: 0.20335645973682404\n",
      "Epoch 1: train loss: 0.20842738449573517\n",
      "Epoch 1: train loss: 0.21627743542194366\n",
      "Epoch 1: train loss: 0.1237780824303627\n",
      "Epoch 1: train loss: 0.22414925694465637\n",
      "Epoch 1: train loss: 0.3450339734554291\n",
      "Epoch 1: train loss: 0.09028158336877823\n",
      "Epoch 1: train loss: 0.278476744890213\n",
      "Epoch 1: train loss: 0.12154441326856613\n",
      "Epoch 1: train loss: 0.24257980287075043\n",
      "Epoch 1: train loss: 0.1302545964717865\n",
      "Epoch 1: train loss: 0.0841282308101654\n",
      "Epoch 1: train loss: 0.23252448439598083\n",
      "Epoch 1: train loss: 0.04616944119334221\n",
      "Epoch 1: train loss: 0.18744127452373505\n",
      "Epoch 1: train loss: 0.15097272396087646\n",
      "Epoch 1: train loss: 0.12103139609098434\n",
      "Epoch 1: train loss: 0.020511841401457787\n",
      "Epoch 1: train loss: 0.11686467379331589\n",
      "Epoch 1: train loss: 0.04099806398153305\n",
      "Epoch 1: train loss: 0.4419359862804413\n",
      "Epoch 1: train loss: 0.7991699576377869\n",
      "Epoch 1: train loss: 0.08415248990058899\n",
      "Epoch 1: train loss: 0.26019346714019775\n",
      "Epoch 1: train loss: 0.30624720454216003\n",
      "Epoch 1: train loss: 0.04467432573437691\n",
      "Epoch 1: train loss: 0.10149765014648438\n",
      "Epoch 1: train loss: 0.1050826758146286\n",
      "Epoch 1: train loss: 0.12501585483551025\n",
      "Epoch 1: train loss: 0.15173865854740143\n",
      "Epoch 1: train loss: 0.2507013976573944\n",
      "Epoch 1: train loss: 0.1526394486427307\n",
      "Epoch 1: train loss: 0.19939109683036804\n",
      "Epoch 1: train loss: 0.28774166107177734\n",
      "Epoch 1: train loss: 0.08907842636108398\n",
      "Epoch 1: train loss: 0.14208579063415527\n",
      "Epoch 1: train loss: 0.2127993106842041\n",
      "Epoch 1: train loss: 0.06617061793804169\n",
      "Epoch 1: train loss: 0.07471820712089539\n",
      "Epoch 1: train loss: 0.1885647177696228\n",
      "Epoch 1: train loss: 0.06510839611291885\n",
      "Epoch 1: train loss: 0.3969166576862335\n",
      "Epoch 1: train loss: 0.18602769076824188\n",
      "Epoch 1: train loss: 0.4412762522697449\n",
      "Epoch 1: train loss: 0.15038977563381195\n",
      "Epoch 1: train loss: 0.1493094116449356\n",
      "Epoch 1: train loss: 0.21615305542945862\n",
      "Epoch 1: train loss: 0.33573684096336365\n",
      "Epoch 1: train loss: 0.29268699884414673\n",
      "Epoch 1: train loss: 0.20690084993839264\n",
      "Epoch 1: train loss: 0.3099026679992676\n",
      "Epoch 1: train loss: 0.17880070209503174\n",
      "Epoch 1: train loss: 0.06702015548944473\n",
      "Epoch 1: train loss: 0.14275972545146942\n",
      "Epoch 1: train loss: 0.10928895324468613\n",
      "Epoch 1: train loss: 0.12271856516599655\n",
      "Epoch 1: train loss: 0.15799760818481445\n",
      "Epoch 1: train loss: 0.08190231025218964\n",
      "Epoch 1: train loss: 0.3658771216869354\n",
      "Epoch 1: train loss: 0.23712028563022614\n",
      "Epoch 1: train loss: 0.16267237067222595\n",
      "Epoch 1: train loss: 0.08629851788282394\n",
      "Epoch 1: train loss: 0.06957726925611496\n",
      "Epoch 1: train loss: 0.1958618462085724\n",
      "Epoch 1: train loss: 0.16703835129737854\n",
      "Epoch 1: train loss: 0.23437772691249847\n",
      "Epoch 1: train loss: 0.26125138998031616\n",
      "Epoch 1: train loss: 0.06387241184711456\n",
      "Epoch 1: train loss: 0.4489946961402893\n",
      "Epoch 1: train loss: 0.052680373191833496\n",
      "Epoch 1: train loss: 0.16048775613307953\n",
      "Epoch 1: train loss: 0.14183923602104187\n",
      "Epoch 1: train loss: 0.41487520933151245\n",
      "Epoch 1: train loss: 0.171981081366539\n",
      "Epoch 1: train loss: 0.18667596578598022\n",
      "Epoch 1: train loss: 0.17189691960811615\n",
      "Epoch 1: train loss: 0.0757807195186615\n",
      "Epoch 1: train loss: 0.14422067999839783\n",
      "Epoch 1: train loss: 0.2522446811199188\n",
      "Epoch 1: train loss: 0.09853158891201019\n",
      "Epoch 1: train loss: 0.20690396428108215\n",
      "Epoch 1: train loss: 0.08794251084327698\n",
      "Epoch 1: train loss: 0.29657644033432007\n",
      "Epoch 1: train loss: 0.2517009675502777\n",
      "Epoch 1: train loss: 0.23303520679473877\n",
      "Epoch 1: train loss: 0.40106889605522156\n",
      "Epoch 1: train loss: 0.23565718531608582\n",
      "Epoch 1: train loss: 0.17380182445049286\n",
      "Epoch 1: train loss: 0.26515066623687744\n",
      "Epoch 1: train loss: 0.0995473861694336\n",
      "Epoch 1: train loss: 0.09375903010368347\n",
      "Epoch 1: train loss: 0.2597120404243469\n",
      "Epoch 1: train loss: 0.13562385737895966\n",
      "Epoch 1: train loss: 0.22026444971561432\n",
      "Epoch 1: train loss: 0.06137213110923767\n",
      "Epoch 1: train loss: 0.3463243842124939\n",
      "Epoch 1: train loss: 0.20375312864780426\n",
      "Epoch 1: train loss: 0.19800683856010437\n",
      "Epoch 1: train loss: 0.18471701443195343\n",
      "Epoch 1: train loss: 0.14403730630874634\n",
      "Epoch 1: train loss: 0.23622483015060425\n",
      "Epoch 1: train loss: 0.206039696931839\n",
      "Epoch 1: train loss: 0.13870221376419067\n",
      "Epoch 1: train loss: 0.23839999735355377\n",
      "Epoch 1: train loss: 0.08246970176696777\n",
      "Epoch 1: train loss: 0.2883899509906769\n",
      "Epoch 1: train loss: 0.470048725605011\n",
      "Epoch 1: train loss: 0.40818822383880615\n",
      "Epoch 1: train loss: 0.21846961975097656\n",
      "Epoch 1: train loss: 0.26793792843818665\n",
      "Epoch 1: train loss: 0.20245513319969177\n",
      "Epoch 1: train loss: 0.11016280949115753\n",
      "Epoch 1: train loss: 0.15046577155590057\n",
      "Epoch 1: train loss: 0.19484902918338776\n",
      "Epoch 1: train loss: 0.07477658241987228\n",
      "Epoch 1: train loss: 0.17562171816825867\n",
      "Epoch 1: train loss: 0.2776440680027008\n",
      "Epoch 1: train loss: 0.5571174621582031\n",
      "Epoch 1: train loss: 0.07016907632350922\n",
      "Epoch 1: train loss: 0.28928324580192566\n",
      "Epoch 1: train loss: 0.3710683584213257\n",
      "Epoch 1: train loss: 0.32119622826576233\n",
      "Epoch 1: train loss: 0.5253903865814209\n",
      "Epoch 1: train loss: 0.2904456853866577\n",
      "Epoch 1: train loss: 0.22364471852779388\n",
      "Epoch 1: train loss: 0.1222045049071312\n",
      "Epoch 1: train loss: 0.17676880955696106\n",
      "Epoch 1: train loss: 0.27161842584609985\n",
      "Epoch 1: train loss: 0.19264334440231323\n",
      "Epoch 1: train loss: 0.1988670527935028\n",
      "Epoch 1: train loss: 0.09032653272151947\n",
      "Epoch 1: train loss: 0.24867285788059235\n",
      "Epoch 1: train loss: 0.2537979781627655\n",
      "Epoch 1: train loss: 0.22735701501369476\n",
      "Epoch 1: train loss: 0.10626508295536041\n",
      "Epoch 1: train loss: 0.22206273674964905\n",
      "Epoch 1: train loss: 0.18996647000312805\n",
      "Epoch 1: train loss: 0.18608969449996948\n",
      "Epoch 1: train loss: 0.30953478813171387\n",
      "Epoch 1: train loss: 0.2877480387687683\n",
      "Epoch 1: train loss: 0.11976484209299088\n",
      "Epoch 1: train loss: 0.23278887569904327\n",
      "Epoch 1: train loss: 0.25589457154273987\n",
      "Epoch 1: train loss: 0.323686420917511\n",
      "Epoch 1: train loss: 0.3852085471153259\n",
      "Epoch 1: train loss: 0.21253487467765808\n",
      "Epoch 1: train loss: 0.28508955240249634\n",
      "Epoch 1: train loss: 0.17780451476573944\n",
      "Epoch 1: train loss: 0.22292642295360565\n",
      "Epoch 1: train loss: 0.1455485224723816\n",
      "Epoch 1: train loss: 0.08747808635234833\n",
      "Epoch 1: train loss: 0.093805231153965\n",
      "Epoch 1: train loss: 0.22574341297149658\n",
      "Epoch 1: train loss: 0.21581441164016724\n",
      "Epoch 1: train loss: 0.37182626128196716\n",
      "Epoch 1: train loss: 0.15485404431819916\n",
      "Epoch 1: train loss: 0.30086249113082886\n",
      "Epoch 1: train loss: 0.07905331254005432\n",
      "Epoch 1: train loss: 0.30174520611763\n",
      "Epoch 1: train loss: 0.35654178261756897\n",
      "Epoch 1: train loss: 0.42248770594596863\n",
      "Epoch 1: train loss: 0.09278599917888641\n",
      "Epoch 1: train loss: 0.09132164716720581\n",
      "Epoch 1: train loss: 0.13293980062007904\n",
      "Epoch 1: train loss: 0.15013937652111053\n",
      "Epoch 1: train loss: 0.2620239555835724\n",
      "Epoch 1: train loss: 0.20203867554664612\n",
      "Epoch 1: train loss: 0.06778199970722198\n",
      "Epoch 1: train loss: 0.14031420648097992\n",
      "Epoch 1: train loss: 0.40005144476890564\n",
      "Epoch 1: train loss: 0.07586539536714554\n",
      "Epoch 1: train loss: 0.2360847145318985\n",
      "Epoch 1: train loss: 0.19923624396324158\n",
      "Epoch 1: train loss: 0.3751400411128998\n",
      "Epoch 1: train loss: 0.29083770513534546\n",
      "Epoch 1: train loss: 0.06987547874450684\n",
      "Epoch 1: train loss: 0.17172755300998688\n",
      "Epoch 1: train loss: 0.1303938329219818\n",
      "Epoch 1: train loss: 0.313751757144928\n",
      "Epoch 1: train loss: 0.11332827806472778\n",
      "Epoch 1: train loss: 0.17622193694114685\n",
      "Epoch 1: train loss: 0.08750142902135849\n",
      "Epoch 1: train loss: 0.23327310383319855\n",
      "Epoch 1: train loss: 0.20292708277702332\n",
      "Epoch 1: train loss: 0.19779334962368011\n",
      "Epoch 1: train loss: 0.1062181293964386\n",
      "Epoch 1: train loss: 0.03699253499507904\n",
      "Epoch 1: train loss: 0.4746766686439514\n",
      "Epoch 1: train loss: 0.22248056530952454\n",
      "Epoch 1: train loss: 0.34582042694091797\n",
      "Epoch 1: train loss: 0.13777312636375427\n",
      "Epoch 1: train loss: 0.41054293513298035\n",
      "Epoch 1: train loss: 0.201710507273674\n",
      "Epoch 1: train loss: 0.1992047280073166\n",
      "Epoch 1: train loss: 0.06298865377902985\n",
      "Epoch 1: train loss: 0.1963677704334259\n",
      "Epoch 1: train loss: 0.21793679893016815\n",
      "Epoch 1: train loss: 0.2671648859977722\n",
      "Epoch 1: train loss: 0.2174096703529358\n",
      "Epoch 1: train loss: 0.2822572886943817\n",
      "Epoch 1: train loss: 0.21086440980434418\n",
      "Epoch 1: train loss: 0.11420319229364395\n",
      "Epoch 1: train loss: 0.2500731647014618\n",
      "Epoch 1: train loss: 0.39139699935913086\n",
      "Epoch 1: train loss: 0.22961091995239258\n",
      "Epoch 1: train loss: 0.09683944284915924\n",
      "Epoch 1: train loss: 0.2239440232515335\n",
      "Epoch 1: train loss: 0.16617447137832642\n",
      "Epoch 1: train loss: 0.3096449673175812\n",
      "Epoch 1: train loss: 0.07830353826284409\n",
      "Epoch 1: train loss: 0.3176811635494232\n",
      "Epoch 1: train loss: 0.24442867934703827\n",
      "Epoch 1: train loss: 0.17990009486675262\n",
      "Epoch 1: train loss: 0.3541906774044037\n",
      "Epoch 1: train loss: 0.20540106296539307\n",
      "Epoch 1: train loss: 0.3506440818309784\n",
      "Epoch 1: train loss: 0.14517931640148163\n",
      "Epoch 1: train loss: 0.14015495777130127\n",
      "Epoch 1: train loss: 0.20477913320064545\n",
      "Epoch 1: train loss: 0.24410240352153778\n",
      "Epoch 1: train loss: 0.14664287865161896\n",
      "Epoch 1: train loss: 0.0751543864607811\n",
      "Epoch 1: train loss: 0.22798669338226318\n",
      "Epoch 1: train loss: 0.3720780313014984\n",
      "Epoch 1: train loss: 0.5367647409439087\n",
      "Epoch 1: train loss: 0.1702733039855957\n",
      "Epoch 1: train loss: 0.11493684351444244\n",
      "Epoch 1: train loss: 0.1941012144088745\n",
      "Epoch 1: train loss: 0.1109742596745491\n",
      "Epoch 1: train loss: 0.10710040479898453\n",
      "Epoch 1: train loss: 0.15056174993515015\n",
      "Epoch 1: train loss: 0.3003479242324829\n",
      "Epoch 1: train loss: 0.12224390357732773\n",
      "Epoch 1: train loss: 0.12932772934436798\n",
      "Epoch 1: train loss: 0.26595157384872437\n",
      "Epoch 1: train loss: 0.08597487211227417\n",
      "Epoch 1: train loss: 0.03185198828577995\n",
      "Epoch 1: train loss: 0.1406036913394928\n",
      "Epoch 1: train loss: 0.08701451122760773\n",
      "Epoch 1: train loss: 0.1743496209383011\n",
      "Epoch 1: train loss: 0.026221921667456627\n",
      "Epoch 1: train loss: 0.3091466724872589\n",
      "Epoch 1: train loss: 0.2322208285331726\n",
      "Epoch 1: train loss: 0.09051571786403656\n",
      "Epoch 1: train loss: 0.02297486551105976\n",
      "Epoch 1: train loss: 0.3951391875743866\n",
      "Epoch 1: train loss: 0.2562025189399719\n",
      "Epoch 1: train loss: 0.18579146265983582\n",
      "Epoch 1: train loss: 0.037010736763477325\n",
      "Epoch 1: train loss: 0.263060599565506\n",
      "Epoch 1: train loss: 0.3334313631057739\n",
      "Epoch 1: train loss: 0.1289440542459488\n",
      "Epoch 1: train loss: 0.07146011292934418\n",
      "Epoch 1: train loss: 0.06727968156337738\n",
      "Epoch 1: train loss: 0.15359936654567719\n",
      "Epoch 1: train loss: 0.08220440149307251\n",
      "Epoch 1: train loss: 0.12850455939769745\n",
      "Epoch 1: train loss: 0.21940173208713531\n",
      "Epoch 1: train loss: 0.17384910583496094\n",
      "Epoch 1: train loss: 0.14447635412216187\n",
      "Epoch 1: train loss: 0.22093619406223297\n",
      "Epoch 1: train loss: 0.1819741278886795\n",
      "Epoch 1: train loss: 0.20141898095607758\n",
      "Epoch 1: train loss: 0.19343283772468567\n",
      "Epoch 1: train loss: 0.14772813022136688\n",
      "Epoch 1: train loss: 0.14450155198574066\n",
      "Epoch 1: train loss: 0.06405780464410782\n",
      "Epoch 1: train loss: 0.12586912512779236\n",
      "Epoch 1: train loss: 0.23165418207645416\n",
      "Epoch 1: train loss: 0.11713943630456924\n",
      "Epoch 1: train loss: 0.08570002019405365\n",
      "Epoch 1: train loss: 0.2126646637916565\n",
      "Epoch 1: train loss: 0.18749745190143585\n",
      "Epoch 1: train loss: 0.6996229887008667\n",
      "Epoch 1: train loss: 0.3375857472419739\n",
      "Epoch 1: train loss: 0.22044707834720612\n",
      "Epoch 1: train loss: 0.13379830121994019\n",
      "Epoch 1: train loss: 0.38566598296165466\n",
      "Epoch 1: train loss: 0.1229059249162674\n",
      "Epoch 1: train loss: 0.39577361941337585\n",
      "Epoch 1: train loss: 0.1569599062204361\n",
      "Epoch 1: train loss: 0.17551857233047485\n",
      "Epoch 1: train loss: 0.18464164435863495\n",
      "Epoch 1: train loss: 0.2780635952949524\n",
      "Epoch 1: train loss: 0.21246108412742615\n",
      "Epoch 1: train loss: 0.28427207469940186\n",
      "Epoch 1: train loss: 0.1867021769285202\n",
      "Epoch 1: train loss: 0.3609434962272644\n",
      "Epoch 1: train loss: 0.22630470991134644\n",
      "Epoch 1: train loss: 0.15782280266284943\n",
      "Epoch 1: train loss: 0.31891340017318726\n",
      "Epoch 1: train loss: 0.0860450267791748\n",
      "Epoch 1: train loss: 0.16012726724147797\n",
      "Epoch 1: train loss: 0.26237204670906067\n",
      "Epoch 1: train loss: 0.06480032950639725\n",
      "Epoch 1: train loss: 0.23420551419258118\n",
      "Epoch 1: train loss: 0.08273341506719589\n",
      "Epoch 1: train loss: 0.1584947407245636\n",
      "Epoch 1: train loss: 0.16459961235523224\n",
      "Epoch 1: train loss: 0.05930960550904274\n",
      "Epoch 1: train loss: 0.03148765116930008\n",
      "Epoch 1: train loss: 0.179033562541008\n",
      "Epoch 1: train loss: 0.09497526288032532\n",
      "Epoch 1: train loss: 0.31778770685195923\n",
      "Epoch 1: train loss: 0.2783336341381073\n",
      "Epoch 1: train loss: 0.11369835585355759\n",
      "Epoch 1: train loss: 0.21996131539344788\n",
      "Epoch 1: train loss: 0.1791919320821762\n",
      "Epoch 1: train loss: 0.21244411170482635\n",
      "Epoch 1: train loss: 0.07889563590288162\n",
      "Epoch 1: train loss: 0.17493903636932373\n",
      "Epoch 1: train loss: 0.16658127307891846\n",
      "Epoch 1: train loss: 0.16865774989128113\n",
      "Epoch 1: train loss: 0.10841017216444016\n",
      "Epoch 1: train loss: 0.12587614357471466\n",
      "Epoch 1: train loss: 0.44566062092781067\n",
      "Epoch 1: train loss: 0.18125300109386444\n",
      "Epoch 1: train loss: 0.25769326090812683\n",
      "Epoch 1: train loss: 0.2050212025642395\n",
      "Epoch 1: train loss: 0.12293383479118347\n",
      "Epoch 1: train loss: 0.14484675228595734\n",
      "Epoch 1: train loss: 0.18066741526126862\n",
      "Epoch 1: train loss: 0.10108279436826706\n",
      "Epoch 1: train loss: 0.2767932415008545\n",
      "Epoch 1: train loss: 0.13359829783439636\n",
      "Epoch 1: train loss: 0.10328693687915802\n",
      "Epoch 1: train loss: 0.08492419123649597\n",
      "Epoch 1: train loss: 0.24169233441352844\n",
      "Epoch 1: train loss: 0.17948001623153687\n",
      "Epoch 1: train loss: 0.1927955001592636\n",
      "Epoch 1: train loss: 0.2557128965854645\n",
      "Epoch 1: train loss: 0.2890098989009857\n",
      "Epoch 1: train loss: 0.09181568026542664\n",
      "Epoch 1: train loss: 0.04809573292732239\n",
      "Epoch 1: train loss: 0.044368404895067215\n",
      "Epoch 1: train loss: 0.2784383296966553\n",
      "Epoch 1: train loss: 0.2595899999141693\n",
      "Epoch 1: train loss: 0.07843880355358124\n",
      "Epoch 1: train loss: 0.17852161824703217\n",
      "Epoch 1: train loss: 0.43911582231521606\n",
      "Epoch 1: train loss: 0.46305328607559204\n",
      "Epoch 1: train loss: 0.14185254275798798\n",
      "Epoch 1: train loss: 0.12751783430576324\n",
      "Epoch 1: train loss: 0.21251733601093292\n",
      "Epoch 1: train loss: 0.12275209277868271\n",
      "Epoch 1: train loss: 0.3772556483745575\n",
      "Epoch 1: train loss: 0.13549862802028656\n",
      "Epoch 1: train loss: 0.10197541862726212\n",
      "Epoch 1: train loss: 0.21316900849342346\n",
      "Epoch 1: train loss: 0.10248462110757828\n",
      "Epoch 1: train loss: 0.0619770847260952\n",
      "Epoch 1: train loss: 0.2461545467376709\n",
      "Epoch 1: train loss: 0.25379234552383423\n",
      "Epoch 1: train loss: 0.0736737921833992\n",
      "Epoch 1: train loss: 0.11278539150953293\n",
      "Epoch 1: train loss: 0.15022532641887665\n",
      "Epoch 1: train loss: 0.03851377218961716\n",
      "Epoch 1: train loss: 0.08115687221288681\n",
      "Epoch 1: train loss: 0.06278589367866516\n",
      "Epoch 1: train loss: 0.0973530188202858\n",
      "Epoch 1: train loss: 0.25478002429008484\n",
      "Epoch 1: train loss: 0.21280264854431152\n",
      "Epoch 1: train loss: 0.2935214936733246\n",
      "Epoch 1: train loss: 0.19423773884773254\n",
      "Epoch 1: train loss: 0.5974270105361938\n",
      "Epoch 1: train loss: 0.029910294339060783\n",
      "Epoch 1: train loss: 0.31703922152519226\n",
      "Epoch 1: train loss: 0.14842547476291656\n",
      "Epoch 1: train loss: 0.24286103248596191\n",
      "Epoch 1: train loss: 0.4132669270038605\n",
      "Epoch 1: train loss: 0.11750786006450653\n",
      "Epoch 1: train loss: 0.30414992570877075\n",
      "Epoch 1: train loss: 0.09621059894561768\n",
      "Epoch 1: train loss: 0.16026566922664642\n",
      "Epoch 1: train loss: 0.2750045359134674\n",
      "Epoch 1: train loss: 0.22564496099948883\n",
      "Epoch 1: train loss: 0.18993860483169556\n",
      "Epoch 1: train loss: 0.41422268748283386\n",
      "Epoch 1: train loss: 0.18560664355754852\n",
      "Epoch 1: train loss: 0.11627223342657089\n",
      "Epoch 1: train loss: 0.2706984281539917\n",
      "Epoch 1: train loss: 0.1407245248556137\n",
      "Epoch 1: train loss: 0.19831237196922302\n",
      "Epoch 1: train loss: 0.22912350296974182\n",
      "Epoch 1: train loss: 0.18887503445148468\n",
      "Epoch 1: train loss: 0.22149688005447388\n",
      "Epoch 1: train loss: 0.15193282067775726\n",
      "Epoch 1: train loss: 0.06742314994335175\n",
      "Epoch 1: train loss: 0.15364274382591248\n",
      "Epoch 1: train loss: 0.048793498426675797\n",
      "Epoch 1: train loss: 0.2899247407913208\n",
      "Epoch 1: train loss: 0.1877410113811493\n",
      "Epoch 1: train loss: 0.6691728830337524\n",
      "Epoch 1: train loss: 0.021409280598163605\n",
      "Epoch 1: train loss: 0.2299482822418213\n",
      "Epoch 1: train loss: 0.23179544508457184\n",
      "Epoch 1: train loss: 0.13551531732082367\n",
      "Epoch 1: train loss: 0.37924376130104065\n",
      "Epoch 1: train loss: 0.25763368606567383\n",
      "Epoch 1: train loss: 0.18658114969730377\n",
      "Epoch 1: train loss: 0.2001773715019226\n",
      "Epoch 1: train loss: 0.28114965558052063\n",
      "Epoch 1: train loss: 0.19632311165332794\n",
      "Epoch 1: train loss: 0.17890913784503937\n",
      "Epoch 1: train loss: 0.2267293930053711\n",
      "Epoch 1: train loss: 0.2232866883277893\n",
      "Epoch 1: train loss: 0.12681208550930023\n",
      "Epoch 1: train loss: 0.16530101001262665\n",
      "Epoch 1: train loss: 0.266061007976532\n",
      "Epoch 1: train loss: 0.1348154991865158\n",
      "Epoch 1: train loss: 0.21185782551765442\n",
      "Epoch 1: train loss: 0.26655352115631104\n",
      "Epoch 1: train loss: 0.35099101066589355\n",
      "Epoch 1: train loss: 0.38110607862472534\n",
      "Epoch 1: train loss: 0.14090608060359955\n",
      "Epoch 1: train loss: 0.2725893557071686\n",
      "Epoch 1: train loss: 0.2578393518924713\n",
      "Epoch 1: train loss: 0.38705974817276\n",
      "Epoch 1: train loss: 0.23640106618404388\n",
      "Epoch 1: train loss: 0.5100629925727844\n",
      "Epoch 1: train loss: 0.2085345834493637\n",
      "Epoch 1: train loss: 0.23480767011642456\n",
      "Epoch 1: train loss: 0.3420122265815735\n",
      "Epoch 1: train loss: 0.32434624433517456\n",
      "Epoch 1: train loss: 0.2329847365617752\n",
      "Epoch 1: train loss: 0.1526383012533188\n",
      "Epoch 1: train loss: 0.11413879692554474\n",
      "Epoch 1: train loss: 0.21644458174705505\n",
      "Epoch 1: train loss: 0.2229910045862198\n",
      "Epoch 1: train loss: 0.19287484884262085\n",
      "Epoch 1: train loss: 0.42146849632263184\n",
      "Epoch 1: train loss: 0.2378285676240921\n",
      "Epoch 1: train loss: 0.17443887889385223\n",
      "Epoch 1: train loss: 0.2863676846027374\n",
      "Epoch 1: train loss: 0.31936004757881165\n",
      "Epoch 1: train loss: 0.13433793187141418\n",
      "Epoch 1: train loss: 0.13651227951049805\n",
      "Epoch 1: train loss: 0.17545907199382782\n",
      "Epoch 1: train loss: 0.36409255862236023\n",
      "Epoch 1: train loss: 0.0517045259475708\n",
      "Epoch 1: train loss: 0.439678430557251\n",
      "Epoch 1: train loss: 0.08273656666278839\n",
      "Epoch 1: train loss: 0.12817920744419098\n",
      "Epoch 1: train loss: 0.056875068694353104\n",
      "Epoch 1: train loss: 0.1925087422132492\n",
      "Epoch 1: train loss: 0.2517125606536865\n",
      "Epoch 1: train loss: 0.20053553581237793\n",
      "Epoch 1: train loss: 0.3622911870479584\n",
      "Epoch 1: train loss: 0.11526619642972946\n",
      "Epoch 1: train loss: 0.261154443025589\n",
      "Epoch 1: train loss: 0.48462584614753723\n",
      "Epoch 1: train loss: 0.13934724032878876\n",
      "Epoch 1: train loss: 0.353365033864975\n",
      "Epoch 1: train loss: 0.388429194688797\n",
      "Epoch 1: train loss: 0.37524983286857605\n",
      "Epoch 1: train loss: 0.27889588475227356\n",
      "Epoch 1: train loss: 0.19230274856090546\n",
      "Epoch 1: train loss: 0.3178722560405731\n",
      "Epoch 1: train loss: 0.09882943332195282\n",
      "Epoch 1: train loss: 0.3961070477962494\n",
      "Epoch 1: train loss: 0.1718430370092392\n",
      "Epoch 1: train loss: 0.3010331988334656\n",
      "Epoch 1: train loss: 0.2611079514026642\n",
      "Epoch 1: train loss: 0.2529335916042328\n",
      "Epoch 1: train loss: 0.1472116857767105\n",
      "Epoch 1: train loss: 0.21920166909694672\n",
      "Epoch 1: train loss: 0.09867119044065475\n",
      "Epoch 1: train loss: 0.22518028318881989\n",
      "Epoch 1: train loss: 0.24759453535079956\n",
      "Epoch 1: train loss: 0.08187943696975708\n",
      "Epoch 1: train loss: 0.4130750894546509\n",
      "Epoch 1: train loss: 0.23610010743141174\n",
      "Epoch 1: train loss: 0.11129207909107208\n",
      "Epoch 1: train loss: 0.2131410539150238\n",
      "Epoch 1: train loss: 0.09419164806604385\n",
      "Epoch 1: train loss: 0.3579237163066864\n",
      "Epoch 1: train loss: 0.3009627163410187\n",
      "Epoch 1: train loss: 0.3539957106113434\n",
      "Epoch 1: train loss: 0.19864974915981293\n",
      "Epoch 1: train loss: 0.13467592000961304\n",
      "Epoch 1: train loss: 0.18240860104560852\n",
      "Epoch 1: train loss: 0.33938896656036377\n",
      "Epoch 1: train loss: 0.47327882051467896\n",
      "Epoch 1: train loss: 0.13121356070041656\n",
      "Epoch 1: train loss: 0.30384430289268494\n",
      "Epoch 1: train loss: 0.18094202876091003\n",
      "Epoch 1: train loss: 0.35321924090385437\n",
      "Epoch 1: train loss: 0.22648903727531433\n",
      "Epoch 1: train loss: 0.1313142627477646\n",
      "Epoch 1: train loss: 0.1373545527458191\n",
      "Epoch 1: train loss: 0.2886858582496643\n",
      "Epoch 1: train loss: 0.05838048830628395\n",
      "Epoch 1: train loss: 0.13332821428775787\n",
      "Epoch 1: train loss: 0.13212421536445618\n",
      "Epoch 1: train loss: 0.16371601819992065\n",
      "Epoch 1: train loss: 0.12946578860282898\n",
      "Epoch 1: train loss: 0.19608402252197266\n",
      "Epoch 1: train loss: 0.2424086630344391\n",
      "Epoch 1: train loss: 0.13961826264858246\n",
      "Epoch 1: train loss: 0.17568063735961914\n",
      "Epoch 1: train loss: 0.3911445736885071\n",
      "Epoch 1: train loss: 0.0709071084856987\n",
      "Epoch 1: train loss: 0.15419308841228485\n",
      "Epoch 1: train loss: 0.2570987939834595\n",
      "Epoch 1: train loss: 0.1975015103816986\n",
      "Epoch 1: train loss: 0.26995059847831726\n",
      "Epoch 1: train loss: 0.08098134398460388\n",
      "Epoch 1: train loss: 0.12212496995925903\n",
      "Epoch 1: train loss: 0.2605133652687073\n",
      "Epoch 1: train loss: 0.2538214325904846\n",
      "Epoch 1: train loss: 0.18486648797988892\n",
      "Epoch 1: train loss: 0.25076863169670105\n",
      "Epoch 1: train loss: 0.15784959495067596\n",
      "Epoch 1: train loss: 0.15263314545154572\n",
      "Epoch 1: train loss: 0.08939322084188461\n",
      "Epoch 1: train loss: 0.12265466898679733\n",
      "Epoch 1: train loss: 0.2664523124694824\n",
      "Epoch 1: train loss: 0.1905079334974289\n",
      "Epoch 1: train loss: 0.23439373075962067\n",
      "Epoch 1: train loss: 0.20664848387241364\n",
      "Epoch 1: train loss: 0.08085759729146957\n",
      "Epoch 1: train loss: 0.3816600739955902\n",
      "Epoch 1: train loss: 0.13832415640354156\n",
      "Epoch 1: train loss: 0.10858140885829926\n",
      "Epoch 1: train loss: 0.2532874345779419\n",
      "Epoch 1: train loss: 0.2474788874387741\n",
      "Epoch 1: train loss: 0.08361387252807617\n",
      "Epoch 1: train loss: 0.1896834373474121\n",
      "Epoch 1: train loss: 0.12029422074556351\n",
      "Epoch 1: train loss: 0.16459043323993683\n",
      "Epoch 1: train loss: 0.035138726234436035\n",
      "Epoch 1: train loss: 0.05143147334456444\n",
      "Epoch 1: train loss: 0.1867709457874298\n",
      "Epoch 1: train loss: 0.44904154539108276\n",
      "Epoch 1: train loss: 0.14198268949985504\n",
      "Epoch 1: train loss: 0.25126028060913086\n",
      "Epoch 1: train loss: 0.21684826910495758\n",
      "Epoch 1: train loss: 0.17529858648777008\n",
      "Epoch 1: train loss: 0.1529274433851242\n",
      "Epoch 1: train loss: 0.12755973637104034\n",
      "Epoch 1: train loss: 0.2663935720920563\n",
      "Epoch 1: train loss: 0.1454407423734665\n",
      "Epoch 1: train loss: 0.5800005197525024\n",
      "Epoch 1: train loss: 0.1440264731645584\n",
      "Epoch 1: train loss: 0.3783009946346283\n",
      "Epoch 1: train loss: 0.13183286786079407\n",
      "Epoch 1: train loss: 0.1382320076227188\n",
      "Epoch 1: train loss: 0.22207123041152954\n",
      "Epoch 1: train loss: 0.21893702447414398\n",
      "Epoch 1: train loss: 0.43251243233680725\n",
      "Epoch 1: train loss: 0.29723453521728516\n",
      "Epoch 1: train loss: 0.08699847012758255\n",
      "Epoch 1: train loss: 0.20252640545368195\n",
      "Epoch 1: train loss: 0.29911935329437256\n",
      "Epoch 1: train loss: 0.17270217835903168\n",
      "Epoch 1: train loss: 0.2821689546108246\n",
      "Epoch 1: train loss: 0.3323909342288971\n",
      "Epoch 1: train loss: 0.1911720633506775\n",
      "Epoch 1: train loss: 0.06626120954751968\n",
      "Epoch 1: train loss: 0.10783521831035614\n",
      "Epoch 1: train loss: 0.19239160418510437\n",
      "Epoch 1: train loss: 0.3395024836063385\n",
      "Epoch 1: train loss: 0.06704817712306976\n",
      "Epoch 1: train loss: 0.2713376581668854\n",
      "Epoch 1: train loss: 0.2726943790912628\n",
      "Epoch 1: train loss: 0.05271782726049423\n",
      "Epoch 1: train loss: 0.1857893019914627\n",
      "Epoch 1: train loss: 0.16828064620494843\n",
      "Epoch 1: train loss: 0.2275194674730301\n",
      "Epoch 1: train loss: 0.15291732549667358\n",
      "Epoch 1: train loss: 0.25465160608291626\n",
      "Epoch 1: train loss: 0.14958693087100983\n",
      "Epoch 1: train loss: 0.2253938466310501\n",
      "Epoch 1: train loss: 0.3105672597885132\n",
      "Epoch 1: train loss: 0.2717798054218292\n",
      "Epoch 1: train loss: 0.1361989974975586\n",
      "Epoch 1: train loss: 0.05277032405138016\n",
      "Epoch 1: train loss: 0.07268335670232773\n",
      "Epoch 1: train loss: 0.32186391949653625\n",
      "Epoch 1: train loss: 0.38752713799476624\n",
      "Epoch 1: train loss: 0.13469833135604858\n",
      "Epoch 1: train loss: 0.06719420850276947\n",
      "Epoch 1: train loss: 0.14285525679588318\n",
      "Epoch 1: train loss: 0.19955633580684662\n",
      "Epoch 1: train loss: 0.22183780372142792\n",
      "Epoch 1: train loss: 0.1962723284959793\n",
      "Epoch 1: train loss: 0.3603304624557495\n",
      "Epoch 1: train loss: 0.3090982139110565\n",
      "Epoch 1: train loss: 0.36763209104537964\n",
      "Epoch 1: train loss: 0.24806636571884155\n",
      "Epoch 1: train loss: 0.24791844189167023\n",
      "Epoch 1: train loss: 0.29139596223831177\n",
      "Epoch 1: train loss: 0.20060135424137115\n",
      "Epoch 1: train loss: 0.11769868433475494\n",
      "Epoch 1: train loss: 0.19554269313812256\n",
      "Epoch 1: train loss: 0.5111938118934631\n",
      "Epoch 1: train loss: 0.1286786049604416\n",
      "Epoch 1: train loss: 0.1414300501346588\n",
      "Epoch 1: train loss: 0.39691925048828125\n",
      "Epoch 1: train loss: 0.06897783279418945\n",
      "Epoch 1: train loss: 0.31995758414268494\n",
      "Epoch 1: train loss: 0.10808300226926804\n",
      "Epoch 1: train loss: 0.16353406012058258\n",
      "Epoch 1: train loss: 0.22735595703125\n",
      "Epoch 1: train loss: 0.30342280864715576\n",
      "Epoch 1: train loss: 0.0959663987159729\n",
      "Epoch 1: train loss: 0.3683270812034607\n",
      "Epoch 1: train loss: 0.41812071204185486\n",
      "Epoch 1: train loss: 0.1943347454071045\n",
      "Epoch 1: train loss: 0.054919544607400894\n",
      "Epoch 1: train loss: 0.3605455458164215\n",
      "Epoch 1: train loss: 0.20255863666534424\n",
      "Epoch 1: train loss: 0.1889623999595642\n",
      "Epoch 1: train loss: 0.16681309044361115\n",
      "Epoch 1: train loss: 0.2455088496208191\n",
      "Epoch 1: train loss: 0.3258759081363678\n",
      "Epoch 1: train loss: 0.14527276158332825\n",
      "Epoch 1: train loss: 0.1778363138437271\n",
      "Epoch 1: train loss: 0.3117234706878662\n",
      "Epoch 1: train loss: 0.44781920313835144\n",
      "Epoch 1: train loss: 0.12583161890506744\n",
      "Epoch 1: train loss: 0.23137076199054718\n",
      "Epoch 1: train loss: 0.0953470766544342\n",
      "Epoch 1: train loss: 0.15597793459892273\n",
      "Epoch 1: train loss: 0.354647696018219\n",
      "Epoch 1: train loss: 0.1567821055650711\n",
      "Epoch 1: train loss: 0.2411920726299286\n",
      "Epoch 1: train loss: 0.3247755467891693\n",
      "Epoch 1: train loss: 0.2581290006637573\n",
      "Epoch 1: train loss: 0.23908035457134247\n",
      "Epoch 1: train loss: 0.3340117633342743\n",
      "Epoch 1: train loss: 0.26677849888801575\n",
      "Epoch 1: train loss: 0.2533978819847107\n",
      "Epoch 1: train loss: 0.08782350271940231\n",
      "Epoch 1: train loss: 0.18102815747261047\n",
      "Epoch 1: train loss: 0.11356103420257568\n",
      "Epoch 1: train loss: 0.15533293783664703\n",
      "Epoch 1: train loss: 0.1653878539800644\n",
      "Epoch 1: train loss: 0.15573228895664215\n",
      "Epoch 1: train loss: 0.1116371899843216\n",
      "Epoch 1: train loss: 0.1844569742679596\n",
      "Epoch 1: train loss: 0.25121182203292847\n",
      "Epoch 1: train loss: 0.054468121379613876\n",
      "Epoch 1: train loss: 0.18907174468040466\n",
      "Epoch 1: train loss: 0.23067939281463623\n",
      "Epoch 1: train loss: 0.013505067676305771\n",
      "Epoch 2: train loss: 0.15671291947364807\n",
      "Epoch 2: train loss: 0.1740928292274475\n",
      "Epoch 2: train loss: 0.23795296251773834\n",
      "Epoch 2: train loss: 0.28524062037467957\n",
      "Epoch 2: train loss: 0.2480853945016861\n",
      "Epoch 2: train loss: 0.22918261587619781\n",
      "Epoch 2: train loss: 0.09385315328836441\n",
      "Epoch 2: train loss: 0.18440693616867065\n",
      "Epoch 2: train loss: 0.18343722820281982\n",
      "Epoch 2: train loss: 0.13595910370349884\n",
      "Epoch 2: train loss: 0.038011014461517334\n",
      "Epoch 2: train loss: 0.3210180401802063\n",
      "Epoch 2: train loss: 0.2830166220664978\n",
      "Epoch 2: train loss: 0.28247547149658203\n",
      "Epoch 2: train loss: 0.22008965909481049\n",
      "Epoch 2: train loss: 0.23043344914913177\n",
      "Epoch 2: train loss: 0.23775672912597656\n",
      "Epoch 2: train loss: 0.3531472980976105\n",
      "Epoch 2: train loss: 0.12038812786340714\n",
      "Epoch 2: train loss: 0.13623182475566864\n",
      "Epoch 2: train loss: 0.07008407264947891\n",
      "Epoch 2: train loss: 0.16629789769649506\n",
      "Epoch 2: train loss: 0.17566992342472076\n",
      "Epoch 2: train loss: 0.28613799810409546\n",
      "Epoch 2: train loss: 0.3215526342391968\n",
      "Epoch 2: train loss: 0.17243371903896332\n",
      "Epoch 2: train loss: 0.3576277196407318\n",
      "Epoch 2: train loss: 0.26354268193244934\n",
      "Epoch 2: train loss: 0.23323114216327667\n",
      "Epoch 2: train loss: 0.259526789188385\n",
      "Epoch 2: train loss: 0.3403773009777069\n",
      "Epoch 2: train loss: 0.08660370111465454\n",
      "Epoch 2: train loss: 0.3532507121562958\n",
      "Epoch 2: train loss: 0.18918277323246002\n",
      "Epoch 2: train loss: 0.2540431022644043\n",
      "Epoch 2: train loss: 0.15252669155597687\n",
      "Epoch 2: train loss: 0.1268521398305893\n",
      "Epoch 2: train loss: 0.05735200643539429\n",
      "Epoch 2: train loss: 0.23724617063999176\n",
      "Epoch 2: train loss: 0.2681282162666321\n",
      "Epoch 2: train loss: 0.6474972367286682\n",
      "Epoch 2: train loss: 0.4381399154663086\n",
      "Epoch 2: train loss: 0.14202779531478882\n",
      "Epoch 2: train loss: 0.13799171149730682\n",
      "Epoch 2: train loss: 0.21410076320171356\n",
      "Epoch 2: train loss: 0.2012675255537033\n",
      "Epoch 2: train loss: 0.20339733362197876\n",
      "Epoch 2: train loss: 0.20829932391643524\n",
      "Epoch 2: train loss: 0.3885856568813324\n",
      "Epoch 2: train loss: 0.10998644679784775\n",
      "Epoch 2: train loss: 0.18821701407432556\n",
      "Epoch 2: train loss: 0.43389227986335754\n",
      "Epoch 2: train loss: 0.1513114720582962\n",
      "Epoch 2: train loss: 0.28396910429000854\n",
      "Epoch 2: train loss: 0.30481138825416565\n",
      "Epoch 2: train loss: 0.1815575361251831\n",
      "Epoch 2: train loss: 0.28672516345977783\n",
      "Epoch 2: train loss: 0.2761337161064148\n",
      "Epoch 2: train loss: 0.3233993351459503\n",
      "Epoch 2: train loss: 0.14917521178722382\n",
      "Epoch 2: train loss: 0.06263528019189835\n",
      "Epoch 2: train loss: 0.24978795647621155\n",
      "Epoch 2: train loss: 0.061031606048345566\n",
      "Epoch 2: train loss: 0.09508448839187622\n",
      "Epoch 2: train loss: 0.268348753452301\n",
      "Epoch 2: train loss: 0.35730892419815063\n",
      "Epoch 2: train loss: 0.1930423378944397\n",
      "Epoch 2: train loss: 0.1499793976545334\n",
      "Epoch 2: train loss: 0.18497207760810852\n",
      "Epoch 2: train loss: 0.15794485807418823\n",
      "Epoch 2: train loss: 0.21650679409503937\n",
      "Epoch 2: train loss: 0.040487777441740036\n",
      "Epoch 2: train loss: 0.07112567126750946\n",
      "Epoch 2: train loss: 0.18854035437107086\n",
      "Epoch 2: train loss: 0.28338155150413513\n",
      "Epoch 2: train loss: 0.25763675570487976\n",
      "Epoch 2: train loss: 0.2642456293106079\n",
      "Epoch 2: train loss: 0.09426530450582504\n",
      "Epoch 2: train loss: 0.33199989795684814\n",
      "Epoch 2: train loss: 0.31809234619140625\n",
      "Epoch 2: train loss: 0.23506635427474976\n",
      "Epoch 2: train loss: 0.10020239651203156\n",
      "Epoch 2: train loss: 0.06099396198987961\n",
      "Epoch 2: train loss: 0.2751213610172272\n",
      "Epoch 2: train loss: 0.18968041241168976\n",
      "Epoch 2: train loss: 0.09485071897506714\n",
      "Epoch 2: train loss: 0.12362374365329742\n",
      "Epoch 2: train loss: 0.42112189531326294\n",
      "Epoch 2: train loss: 0.1840112954378128\n",
      "Epoch 2: train loss: 0.20450252294540405\n",
      "Epoch 2: train loss: 0.15323126316070557\n",
      "Epoch 2: train loss: 0.1898885816335678\n",
      "Epoch 2: train loss: 0.2739402949810028\n",
      "Epoch 2: train loss: 0.23798373341560364\n",
      "Epoch 2: train loss: 0.060048822313547134\n",
      "Epoch 2: train loss: 0.21190601587295532\n",
      "Epoch 2: train loss: 0.09418448060750961\n",
      "Epoch 2: train loss: 0.18599341809749603\n",
      "Epoch 2: train loss: 0.145349383354187\n",
      "Epoch 2: train loss: 0.22946126759052277\n",
      "Epoch 2: train loss: 0.24328874051570892\n",
      "Epoch 2: train loss: 0.2219935953617096\n",
      "Epoch 2: train loss: 0.040245573967695236\n",
      "Epoch 2: train loss: 0.07655104994773865\n",
      "Epoch 2: train loss: 0.13777562975883484\n",
      "Epoch 2: train loss: 0.14804337918758392\n",
      "Epoch 2: train loss: 0.19817142188549042\n",
      "Epoch 2: train loss: 0.06957066059112549\n",
      "Epoch 2: train loss: 0.06470432132482529\n",
      "Epoch 2: train loss: 0.12483365088701248\n",
      "Epoch 2: train loss: 0.18596923351287842\n",
      "Epoch 2: train loss: 0.20174263417720795\n",
      "Epoch 2: train loss: 0.05093013495206833\n",
      "Epoch 2: train loss: 0.2643741965293884\n",
      "Epoch 2: train loss: 0.2975388765335083\n",
      "Epoch 2: train loss: 0.10645222663879395\n",
      "Epoch 2: train loss: 0.2202010601758957\n",
      "Epoch 2: train loss: 0.36815035343170166\n",
      "Epoch 2: train loss: 0.21777702867984772\n",
      "Epoch 2: train loss: 0.16350051760673523\n",
      "Epoch 2: train loss: 0.3209378719329834\n",
      "Epoch 2: train loss: 0.28397801518440247\n",
      "Epoch 2: train loss: 0.19961820542812347\n",
      "Epoch 2: train loss: 0.10428673774003983\n",
      "Epoch 2: train loss: 0.18952924013137817\n",
      "Epoch 2: train loss: 0.11052081733942032\n",
      "Epoch 2: train loss: 0.2539447247982025\n",
      "Epoch 2: train loss: 0.1436905860900879\n",
      "Epoch 2: train loss: 0.16839832067489624\n",
      "Epoch 2: train loss: 0.07141140103340149\n",
      "Epoch 2: train loss: 0.18671824038028717\n",
      "Epoch 2: train loss: 0.3129502534866333\n",
      "Epoch 2: train loss: 0.05798698589205742\n",
      "Epoch 2: train loss: 0.06913942843675613\n",
      "Epoch 2: train loss: 0.1366303563117981\n",
      "Epoch 2: train loss: 0.1341414898633957\n",
      "Epoch 2: train loss: 0.2046140432357788\n",
      "Epoch 2: train loss: 0.4439099133014679\n",
      "Epoch 2: train loss: 0.04099983721971512\n",
      "Epoch 2: train loss: 0.20533178746700287\n",
      "Epoch 2: train loss: 0.2283107191324234\n",
      "Epoch 2: train loss: 0.06348937004804611\n",
      "Epoch 2: train loss: 0.17891520261764526\n",
      "Epoch 2: train loss: 0.18380212783813477\n",
      "Epoch 2: train loss: 0.0629577785730362\n",
      "Epoch 2: train loss: 0.40670958161354065\n",
      "Epoch 2: train loss: 0.11733927577733994\n",
      "Epoch 2: train loss: 0.43071267008781433\n",
      "Epoch 2: train loss: 0.19153881072998047\n",
      "Epoch 2: train loss: 0.11869017779827118\n",
      "Epoch 2: train loss: 0.06477189809083939\n",
      "Epoch 2: train loss: 0.12628766894340515\n",
      "Epoch 2: train loss: 0.21774940192699432\n",
      "Epoch 2: train loss: 0.28985509276390076\n",
      "Epoch 2: train loss: 0.15092132985591888\n",
      "Epoch 2: train loss: 0.27625131607055664\n",
      "Epoch 2: train loss: 0.31020089983940125\n",
      "Epoch 2: train loss: 0.16482365131378174\n",
      "Epoch 2: train loss: 0.144991934299469\n",
      "Epoch 2: train loss: 0.18312449753284454\n",
      "Epoch 2: train loss: 0.12233451753854752\n",
      "Epoch 2: train loss: 0.13576547801494598\n",
      "Epoch 2: train loss: 0.06705347448587418\n",
      "Epoch 2: train loss: 0.2961125671863556\n",
      "Epoch 2: train loss: 0.046582531183958054\n",
      "Epoch 2: train loss: 0.0632566511631012\n",
      "Epoch 2: train loss: 0.47328945994377136\n",
      "Epoch 2: train loss: 0.23321619629859924\n",
      "Epoch 2: train loss: 0.35090309381484985\n",
      "Epoch 2: train loss: 0.4643203616142273\n",
      "Epoch 2: train loss: 0.11987224221229553\n",
      "Epoch 2: train loss: 0.17019972205162048\n",
      "Epoch 2: train loss: 0.1546088457107544\n",
      "Epoch 2: train loss: 0.22352288663387299\n",
      "Epoch 2: train loss: 0.22807326912879944\n",
      "Epoch 2: train loss: 0.23177537322044373\n",
      "Epoch 2: train loss: 0.18750908970832825\n",
      "Epoch 2: train loss: 0.16439230740070343\n",
      "Epoch 2: train loss: 0.22508026659488678\n",
      "Epoch 2: train loss: 0.09979084879159927\n",
      "Epoch 2: train loss: 0.1702587902545929\n",
      "Epoch 2: train loss: 0.3942413032054901\n",
      "Epoch 2: train loss: 0.16955997049808502\n",
      "Epoch 2: train loss: 0.3757527470588684\n",
      "Epoch 2: train loss: 0.27521568536758423\n",
      "Epoch 2: train loss: 0.05295293778181076\n",
      "Epoch 2: train loss: 0.3181316554546356\n",
      "Epoch 2: train loss: 0.08951452374458313\n",
      "Epoch 2: train loss: 0.26667702198028564\n",
      "Epoch 2: train loss: 0.20023539662361145\n",
      "Epoch 2: train loss: 0.08780618757009506\n",
      "Epoch 2: train loss: 0.06133224815130234\n",
      "Epoch 2: train loss: 0.3307238817214966\n",
      "Epoch 2: train loss: 0.1517457664012909\n",
      "Epoch 2: train loss: 0.19615207612514496\n",
      "Epoch 2: train loss: 0.12981435656547546\n",
      "Epoch 2: train loss: 0.1883026659488678\n",
      "Epoch 2: train loss: 0.621992290019989\n",
      "Epoch 2: train loss: 0.15552261471748352\n",
      "Epoch 2: train loss: 0.07210766524076462\n",
      "Epoch 2: train loss: 0.10424134135246277\n",
      "Epoch 2: train loss: 0.0927499532699585\n",
      "Epoch 2: train loss: 0.1790539026260376\n",
      "Epoch 2: train loss: 0.106848806142807\n",
      "Epoch 2: train loss: 0.16004624962806702\n",
      "Epoch 2: train loss: 0.1486252248287201\n",
      "Epoch 2: train loss: 0.5510965585708618\n",
      "Epoch 2: train loss: 0.1758071333169937\n",
      "Epoch 2: train loss: 0.28372424840927124\n",
      "Epoch 2: train loss: 0.27756497263908386\n",
      "Epoch 2: train loss: 0.43568992614746094\n",
      "Epoch 2: train loss: 0.10463907569646835\n",
      "Epoch 2: train loss: 0.3745172917842865\n",
      "Epoch 2: train loss: 0.2576565444469452\n",
      "Epoch 2: train loss: 0.20497922599315643\n",
      "Epoch 2: train loss: 0.2052273452281952\n",
      "Epoch 2: train loss: 0.36523717641830444\n",
      "Epoch 2: train loss: 0.19231194257736206\n",
      "Epoch 2: train loss: 0.18190589547157288\n",
      "Epoch 2: train loss: 0.19079044461250305\n",
      "Epoch 2: train loss: 0.16226667165756226\n",
      "Epoch 2: train loss: 0.15112212300300598\n",
      "Epoch 2: train loss: 0.26435714960098267\n",
      "Epoch 2: train loss: 0.14163127541542053\n",
      "Epoch 2: train loss: 0.08953803032636642\n",
      "Epoch 2: train loss: 0.46389836072921753\n",
      "Epoch 2: train loss: 0.17692629992961884\n",
      "Epoch 2: train loss: 0.1287935972213745\n",
      "Epoch 2: train loss: 0.17170262336730957\n",
      "Epoch 2: train loss: 0.18432915210723877\n",
      "Epoch 2: train loss: 0.2658728063106537\n",
      "Epoch 2: train loss: 0.07271430641412735\n",
      "Epoch 2: train loss: 0.14379708468914032\n",
      "Epoch 2: train loss: 0.08872909843921661\n",
      "Epoch 2: train loss: 0.2888622283935547\n",
      "Epoch 2: train loss: 0.1717851758003235\n",
      "Epoch 2: train loss: 0.08038175851106644\n",
      "Epoch 2: train loss: 0.15245883166790009\n",
      "Epoch 2: train loss: 0.101936474442482\n",
      "Epoch 2: train loss: 0.06170176714658737\n",
      "Epoch 2: train loss: 0.30874550342559814\n",
      "Epoch 2: train loss: 0.34440159797668457\n",
      "Epoch 2: train loss: 0.17760531604290009\n",
      "Epoch 2: train loss: 0.03870999440550804\n",
      "Epoch 2: train loss: 0.08834237605333328\n",
      "Epoch 2: train loss: 0.03412456810474396\n",
      "Epoch 2: train loss: 0.11468739807605743\n",
      "Epoch 2: train loss: 0.1203361228108406\n",
      "Epoch 2: train loss: 0.37597453594207764\n",
      "Epoch 2: train loss: 0.24007557332515717\n",
      "Epoch 2: train loss: 0.22942817211151123\n",
      "Epoch 2: train loss: 0.13102512061595917\n",
      "Epoch 2: train loss: 0.17386645078659058\n",
      "Epoch 2: train loss: 0.2975529432296753\n",
      "Epoch 2: train loss: 0.2481909543275833\n",
      "Epoch 2: train loss: 0.25358742475509644\n",
      "Epoch 2: train loss: 0.10905950516462326\n",
      "Epoch 2: train loss: 0.19732022285461426\n",
      "Epoch 2: train loss: 0.06126461923122406\n",
      "Epoch 2: train loss: 0.10839861631393433\n",
      "Epoch 2: train loss: 0.18532240390777588\n",
      "Epoch 2: train loss: 0.15991641581058502\n",
      "Epoch 2: train loss: 0.0858427882194519\n",
      "Epoch 2: train loss: 0.17746992409229279\n",
      "Epoch 2: train loss: 0.2466927319765091\n",
      "Epoch 2: train loss: 0.173110231757164\n",
      "Epoch 2: train loss: 0.1368439942598343\n",
      "Epoch 2: train loss: 0.2896149456501007\n",
      "Epoch 2: train loss: 0.14673204720020294\n",
      "Epoch 2: train loss: 0.08068609982728958\n",
      "Epoch 2: train loss: 0.11781519651412964\n",
      "Epoch 2: train loss: 0.14097432792186737\n",
      "Epoch 2: train loss: 0.10546162724494934\n",
      "Epoch 2: train loss: 0.29337599873542786\n",
      "Epoch 2: train loss: 0.06688523292541504\n",
      "Epoch 2: train loss: 0.36344829201698303\n",
      "Epoch 2: train loss: 0.17432525753974915\n",
      "Epoch 2: train loss: 0.027080003172159195\n",
      "Epoch 2: train loss: 0.09085246920585632\n",
      "Epoch 2: train loss: 0.17007268965244293\n",
      "Epoch 2: train loss: 0.1201656386256218\n",
      "Epoch 2: train loss: 0.26604756712913513\n",
      "Epoch 2: train loss: 0.40267062187194824\n",
      "Epoch 2: train loss: 0.14851528406143188\n",
      "Epoch 2: train loss: 0.16099898517131805\n",
      "Epoch 2: train loss: 0.17118629813194275\n",
      "Epoch 2: train loss: 0.1774379014968872\n",
      "Epoch 2: train loss: 0.17165766656398773\n",
      "Epoch 2: train loss: 0.152165025472641\n",
      "Epoch 2: train loss: 0.2610301375389099\n",
      "Epoch 2: train loss: 0.3081984221935272\n",
      "Epoch 2: train loss: 0.2661088705062866\n",
      "Epoch 2: train loss: 0.13426803052425385\n",
      "Epoch 2: train loss: 0.1206747442483902\n",
      "Epoch 2: train loss: 0.09150862693786621\n",
      "Epoch 2: train loss: 0.4383516311645508\n",
      "Epoch 2: train loss: 0.1684207320213318\n",
      "Epoch 2: train loss: 0.05473274365067482\n",
      "Epoch 2: train loss: 0.24717450141906738\n",
      "Epoch 2: train loss: 0.10027286410331726\n",
      "Epoch 2: train loss: 0.34367382526397705\n",
      "Epoch 2: train loss: 0.14343255758285522\n",
      "Epoch 2: train loss: 0.13385049998760223\n",
      "Epoch 2: train loss: 0.21583524346351624\n",
      "Epoch 2: train loss: 0.07968790084123611\n",
      "Epoch 2: train loss: 0.48607194423675537\n",
      "Epoch 2: train loss: 0.2380366325378418\n",
      "Epoch 2: train loss: 0.17967645823955536\n",
      "Epoch 2: train loss: 0.25011885166168213\n",
      "Epoch 2: train loss: 0.17804554104804993\n",
      "Epoch 2: train loss: 0.15172146260738373\n",
      "Epoch 2: train loss: 0.18469718098640442\n",
      "Epoch 2: train loss: 0.12714500725269318\n",
      "Epoch 2: train loss: 0.14971360564231873\n",
      "Epoch 2: train loss: 0.18977712094783783\n",
      "Epoch 2: train loss: 0.29154667258262634\n",
      "Epoch 2: train loss: 0.2573116421699524\n",
      "Epoch 2: train loss: 0.189314603805542\n",
      "Epoch 2: train loss: 0.06321538239717484\n",
      "Epoch 2: train loss: 0.4730495512485504\n",
      "Epoch 2: train loss: 0.22056199610233307\n",
      "Epoch 2: train loss: 0.21872210502624512\n",
      "Epoch 2: train loss: 0.1398630440235138\n",
      "Epoch 2: train loss: 0.10294224321842194\n",
      "Epoch 2: train loss: 0.17039275169372559\n",
      "Epoch 2: train loss: 0.05856320634484291\n",
      "Epoch 2: train loss: 0.10704625397920609\n",
      "Epoch 2: train loss: 0.06708528846502304\n",
      "Epoch 2: train loss: 0.3523975610733032\n",
      "Epoch 2: train loss: 0.06261937320232391\n",
      "Epoch 2: train loss: 0.35635703802108765\n",
      "Epoch 2: train loss: 0.3245927095413208\n",
      "Epoch 2: train loss: 0.21346470713615417\n",
      "Epoch 2: train loss: 0.3575095534324646\n",
      "Epoch 2: train loss: 0.07265958189964294\n",
      "Epoch 2: train loss: 0.2370142787694931\n",
      "Epoch 2: train loss: 0.27634650468826294\n",
      "Epoch 2: train loss: 0.20206968486309052\n",
      "Epoch 2: train loss: 0.23595955967903137\n",
      "Epoch 2: train loss: 0.11562646925449371\n",
      "Epoch 2: train loss: 0.13129600882530212\n",
      "Epoch 2: train loss: 0.09572136402130127\n",
      "Epoch 2: train loss: 0.2328542321920395\n",
      "Epoch 2: train loss: 0.05124128982424736\n",
      "Epoch 2: train loss: 0.45294424891471863\n",
      "Epoch 2: train loss: 0.21742059290409088\n",
      "Epoch 2: train loss: 0.1192130297422409\n",
      "Epoch 2: train loss: 0.2721558213233948\n",
      "Epoch 2: train loss: 0.09319222718477249\n",
      "Epoch 2: train loss: 0.06372064352035522\n",
      "Epoch 2: train loss: 0.08751414716243744\n",
      "Epoch 2: train loss: 0.18617959320545197\n",
      "Epoch 2: train loss: 0.20881612598896027\n",
      "Epoch 2: train loss: 0.18603597581386566\n",
      "Epoch 2: train loss: 0.12403826415538788\n",
      "Epoch 2: train loss: 0.26905032992362976\n",
      "Epoch 2: train loss: 0.07852332293987274\n",
      "Epoch 2: train loss: 0.2094872146844864\n",
      "Epoch 2: train loss: 0.07160040736198425\n",
      "Epoch 2: train loss: 0.09797699004411697\n",
      "Epoch 2: train loss: 0.0782136395573616\n",
      "Epoch 2: train loss: 0.28853440284729004\n",
      "Epoch 2: train loss: 0.019972803071141243\n",
      "Epoch 2: train loss: 0.17118169367313385\n",
      "Epoch 2: train loss: 0.06807553768157959\n",
      "Epoch 2: train loss: 0.3194977343082428\n",
      "Epoch 2: train loss: 0.23355166614055634\n",
      "Epoch 2: train loss: 0.43572545051574707\n",
      "Epoch 2: train loss: 0.13553503155708313\n",
      "Epoch 2: train loss: 0.43328857421875\n",
      "Epoch 2: train loss: 0.1117153987288475\n",
      "Epoch 2: train loss: 0.25168919563293457\n",
      "Epoch 2: train loss: 0.22668208181858063\n",
      "Epoch 2: train loss: 0.1524813026189804\n",
      "Epoch 2: train loss: 0.1283847987651825\n",
      "Epoch 2: train loss: 0.0823005884885788\n",
      "Epoch 2: train loss: 0.2432972490787506\n",
      "Epoch 2: train loss: 0.45215949416160583\n",
      "Epoch 2: train loss: 0.19906163215637207\n",
      "Epoch 2: train loss: 0.12555988132953644\n",
      "Epoch 2: train loss: 0.21807339787483215\n",
      "Epoch 2: train loss: 0.21507635712623596\n",
      "Epoch 2: train loss: 0.21524418890476227\n",
      "Epoch 2: train loss: 0.2764899432659149\n",
      "Epoch 2: train loss: 0.2668454647064209\n",
      "Epoch 2: train loss: 0.3078194260597229\n",
      "Epoch 2: train loss: 0.30602288246154785\n",
      "Epoch 2: train loss: 0.27145928144454956\n",
      "Epoch 2: train loss: 0.16665486991405487\n",
      "Epoch 2: train loss: 0.383086621761322\n",
      "Epoch 2: train loss: 0.14086328446865082\n",
      "Epoch 2: train loss: 0.17379264533519745\n",
      "Epoch 2: train loss: 0.20879915356636047\n",
      "Epoch 2: train loss: 0.1833081841468811\n",
      "Epoch 2: train loss: 0.17765970528125763\n",
      "Epoch 2: train loss: 0.267267107963562\n",
      "Epoch 2: train loss: 0.4020079970359802\n",
      "Epoch 2: train loss: 0.2811606824398041\n",
      "Epoch 2: train loss: 0.10323925316333771\n",
      "Epoch 2: train loss: 0.46990782022476196\n",
      "Epoch 2: train loss: 0.1572171002626419\n",
      "Epoch 2: train loss: 0.11760058999061584\n",
      "Epoch 2: train loss: 0.1573423594236374\n",
      "Epoch 2: train loss: 0.1321905255317688\n",
      "Epoch 2: train loss: 0.1942887008190155\n",
      "Epoch 2: train loss: 0.0905284434556961\n",
      "Epoch 2: train loss: 0.08370323479175568\n",
      "Epoch 2: train loss: 0.20344969630241394\n",
      "Epoch 2: train loss: 0.07698746770620346\n",
      "Epoch 2: train loss: 0.25216928124427795\n",
      "Epoch 2: train loss: 0.32931652665138245\n",
      "Epoch 2: train loss: 0.18894551694393158\n",
      "Epoch 2: train loss: 0.20548371970653534\n",
      "Epoch 2: train loss: 0.49013257026672363\n",
      "Epoch 2: train loss: 0.270608127117157\n",
      "Epoch 2: train loss: 0.5137189030647278\n",
      "Epoch 2: train loss: 0.38409414887428284\n",
      "Epoch 2: train loss: 0.28135865926742554\n",
      "Epoch 2: train loss: 0.16041851043701172\n",
      "Epoch 2: train loss: 0.17238743603229523\n",
      "Epoch 2: train loss: 0.2196345031261444\n",
      "Epoch 2: train loss: 0.13673901557922363\n",
      "Epoch 2: train loss: 0.13124750554561615\n",
      "Epoch 2: train loss: 0.1308976262807846\n",
      "Epoch 2: train loss: 0.3204713761806488\n",
      "Epoch 2: train loss: 0.19104093313217163\n",
      "Epoch 2: train loss: 0.10124344378709793\n",
      "Epoch 2: train loss: 0.3374013602733612\n",
      "Epoch 2: train loss: 0.12341681122779846\n",
      "Epoch 2: train loss: 0.17219874262809753\n",
      "Epoch 2: train loss: 0.07554243505001068\n",
      "Epoch 2: train loss: 0.11785310506820679\n",
      "Epoch 2: train loss: 0.3430000841617584\n",
      "Epoch 2: train loss: 0.2694810628890991\n",
      "Epoch 2: train loss: 0.08594275265932083\n",
      "Epoch 2: train loss: 0.42092588543891907\n",
      "Epoch 2: train loss: 0.18877382576465607\n",
      "Epoch 2: train loss: 0.04245288670063019\n",
      "Epoch 2: train loss: 0.21125294268131256\n",
      "Epoch 2: train loss: 0.2562858760356903\n",
      "Epoch 2: train loss: 0.2124483436346054\n",
      "Epoch 2: train loss: 0.294353187084198\n",
      "Epoch 2: train loss: 0.09815072268247604\n",
      "Epoch 2: train loss: 0.19569064676761627\n",
      "Epoch 2: train loss: 0.22249671816825867\n",
      "Epoch 2: train loss: 0.2977834939956665\n",
      "Epoch 2: train loss: 0.1924208253622055\n",
      "Epoch 2: train loss: 0.05466384440660477\n",
      "Epoch 2: train loss: 0.26529261469841003\n",
      "Epoch 2: train loss: 0.28791823983192444\n",
      "Epoch 2: train loss: 0.1773570477962494\n",
      "Epoch 2: train loss: 0.12221310287714005\n",
      "Epoch 2: train loss: 0.1436678022146225\n",
      "Epoch 2: train loss: 0.06411602348089218\n",
      "Epoch 2: train loss: 0.11209780722856522\n",
      "Epoch 2: train loss: 0.28264617919921875\n",
      "Epoch 2: train loss: 0.18707406520843506\n",
      "Epoch 2: train loss: 0.2580200731754303\n",
      "Epoch 2: train loss: 0.17593790590763092\n",
      "Epoch 2: train loss: 0.291838675737381\n",
      "Epoch 2: train loss: 0.2738347351551056\n",
      "Epoch 2: train loss: 0.18264219164848328\n",
      "Epoch 2: train loss: 0.1900120973587036\n",
      "Epoch 2: train loss: 0.3754548728466034\n",
      "Epoch 2: train loss: 0.21171893179416656\n",
      "Epoch 2: train loss: 0.11428378522396088\n",
      "Epoch 2: train loss: 0.19889773428440094\n",
      "Epoch 2: train loss: 0.08378032594919205\n",
      "Epoch 2: train loss: 0.36910876631736755\n",
      "Epoch 2: train loss: 0.24039092659950256\n",
      "Epoch 2: train loss: 0.26261961460113525\n",
      "Epoch 2: train loss: 0.23813699185848236\n",
      "Epoch 2: train loss: 0.08561687916517258\n",
      "Epoch 2: train loss: 0.20823447406291962\n",
      "Epoch 2: train loss: 0.04997790977358818\n",
      "Epoch 2: train loss: 0.37000688910484314\n",
      "Epoch 2: train loss: 0.41498762369155884\n",
      "Epoch 2: train loss: 0.24831059575080872\n",
      "Epoch 2: train loss: 0.23769719898700714\n",
      "Epoch 2: train loss: 0.14650720357894897\n",
      "Epoch 2: train loss: 0.2157912254333496\n",
      "Epoch 2: train loss: 0.1667395979166031\n",
      "Epoch 2: train loss: 0.19499164819717407\n",
      "Epoch 2: train loss: 0.10001043230295181\n",
      "Epoch 2: train loss: 0.39627355337142944\n",
      "Epoch 2: train loss: 0.22969520092010498\n",
      "Epoch 2: train loss: 0.08471029251813889\n",
      "Epoch 2: train loss: 0.10776040703058243\n",
      "Epoch 2: train loss: 0.26375117897987366\n",
      "Epoch 2: train loss: 0.1795935183763504\n",
      "Epoch 2: train loss: 0.26695770025253296\n",
      "Epoch 2: train loss: 0.18524762988090515\n",
      "Epoch 2: train loss: 0.41851329803466797\n",
      "Epoch 2: train loss: 0.311705082654953\n",
      "Epoch 2: train loss: 0.18467088043689728\n",
      "Epoch 2: train loss: 0.1279481053352356\n",
      "Epoch 2: train loss: 0.31013306975364685\n",
      "Epoch 2: train loss: 0.1280067265033722\n",
      "Epoch 2: train loss: 0.30365705490112305\n",
      "Epoch 2: train loss: 0.1344556212425232\n",
      "Epoch 2: train loss: 0.2655826210975647\n",
      "Epoch 2: train loss: 0.16689898073673248\n",
      "Epoch 2: train loss: 0.11269935965538025\n",
      "Epoch 2: train loss: 0.33667272329330444\n",
      "Epoch 2: train loss: 0.5000315308570862\n",
      "Epoch 2: train loss: 0.11128678917884827\n",
      "Epoch 2: train loss: 0.1475130319595337\n",
      "Epoch 2: train loss: 0.12488691508769989\n",
      "Epoch 2: train loss: 0.2913329601287842\n",
      "Epoch 2: train loss: 0.4060225486755371\n",
      "Epoch 2: train loss: 0.2535744309425354\n",
      "Epoch 2: train loss: 0.13447615504264832\n",
      "Epoch 2: train loss: 0.05791378393769264\n",
      "Epoch 2: train loss: 0.22773630917072296\n",
      "Epoch 2: train loss: 0.18717904388904572\n",
      "Epoch 2: train loss: 0.4662168323993683\n",
      "Epoch 2: train loss: 0.2283836305141449\n",
      "Epoch 2: train loss: 0.20552986860275269\n",
      "Epoch 2: train loss: 0.35330742597579956\n",
      "Epoch 2: train loss: 0.1794208437204361\n",
      "Epoch 2: train loss: 0.18083122372627258\n",
      "Epoch 2: train loss: 0.17241066694259644\n",
      "Epoch 2: train loss: 0.2166823148727417\n",
      "Epoch 2: train loss: 0.23642411828041077\n",
      "Epoch 2: train loss: 0.07721782475709915\n",
      "Epoch 2: train loss: 0.18174788355827332\n",
      "Epoch 2: train loss: 0.03200164809823036\n",
      "Epoch 2: train loss: 0.032903991639614105\n",
      "Epoch 2: train loss: 0.26098063588142395\n",
      "Epoch 2: train loss: 0.34734001755714417\n",
      "Epoch 2: train loss: 0.3001570403575897\n",
      "Epoch 2: train loss: 0.2597350776195526\n",
      "Epoch 2: train loss: 0.2377898395061493\n",
      "Epoch 2: train loss: 0.03792448341846466\n",
      "Epoch 2: train loss: 0.07412530481815338\n",
      "Epoch 2: train loss: 0.12909623980522156\n",
      "Epoch 2: train loss: 0.2441418170928955\n",
      "Epoch 2: train loss: 0.3987833559513092\n",
      "Epoch 2: train loss: 0.03551502898335457\n",
      "Epoch 2: train loss: 0.1004657968878746\n",
      "Epoch 2: train loss: 0.062181923538446426\n",
      "Epoch 2: train loss: 0.07322810590267181\n",
      "Epoch 2: train loss: 0.18798312544822693\n",
      "Epoch 2: train loss: 0.19105082750320435\n",
      "Epoch 2: train loss: 0.05504302680492401\n",
      "Epoch 2: train loss: 0.1573559194803238\n",
      "Epoch 2: train loss: 0.19638901948928833\n",
      "Epoch 2: train loss: 0.14836116135120392\n",
      "Epoch 2: train loss: 0.09704484045505524\n",
      "Epoch 2: train loss: 0.021511275321245193\n",
      "Epoch 2: train loss: 0.03829880431294441\n",
      "Epoch 2: train loss: 0.07678672671318054\n",
      "Epoch 2: train loss: 0.4782024919986725\n",
      "Epoch 2: train loss: 0.11948242783546448\n",
      "Epoch 2: train loss: 0.04665089398622513\n",
      "Epoch 2: train loss: 0.1424078494310379\n",
      "Epoch 2: train loss: 0.23934392631053925\n",
      "Epoch 2: train loss: 0.1876145899295807\n",
      "Epoch 2: train loss: 0.26117584109306335\n",
      "Epoch 2: train loss: 0.17568710446357727\n",
      "Epoch 2: train loss: 0.2402222454547882\n",
      "Epoch 2: train loss: 0.21775394678115845\n",
      "Epoch 2: train loss: 0.46553996205329895\n",
      "Epoch 2: train loss: 0.31685274839401245\n",
      "Epoch 2: train loss: 0.08210138976573944\n",
      "Epoch 2: train loss: 0.23247070610523224\n",
      "Epoch 2: train loss: 0.15372765064239502\n",
      "Epoch 2: train loss: 0.21523071825504303\n",
      "Epoch 2: train loss: 0.26945924758911133\n",
      "Epoch 2: train loss: 0.10466300696134567\n",
      "Epoch 2: train loss: 0.16320224106311798\n",
      "Epoch 2: train loss: 0.08812039345502853\n",
      "Epoch 2: train loss: 0.041716381907463074\n",
      "Epoch 2: train loss: 0.27624446153640747\n",
      "Epoch 2: train loss: 0.1533259153366089\n",
      "Epoch 2: train loss: 0.26742368936538696\n",
      "Epoch 2: train loss: 0.12250009179115295\n",
      "Epoch 2: train loss: 0.058659523725509644\n",
      "Epoch 2: train loss: 0.24005715548992157\n",
      "Epoch 2: train loss: 0.35058528184890747\n",
      "Epoch 2: train loss: 0.08420849591493607\n",
      "Epoch 2: train loss: 0.03240754455327988\n",
      "Epoch 2: train loss: 0.17230264842510223\n",
      "Epoch 2: train loss: 0.041349492967128754\n",
      "Epoch 2: train loss: 0.1064089685678482\n",
      "Epoch 2: train loss: 0.15460431575775146\n",
      "Epoch 2: train loss: 0.4916219413280487\n",
      "Epoch 2: train loss: 0.15414409339427948\n",
      "Epoch 2: train loss: 0.17216333746910095\n",
      "Epoch 2: train loss: 0.0417933389544487\n",
      "Epoch 2: train loss: 0.04283449798822403\n",
      "Epoch 2: train loss: 0.2445879429578781\n",
      "Epoch 2: train loss: 0.14097270369529724\n",
      "Epoch 2: train loss: 0.28154152631759644\n",
      "Epoch 2: train loss: 0.22895531356334686\n",
      "Epoch 2: train loss: 0.16900180280208588\n",
      "Epoch 2: train loss: 0.37697654962539673\n",
      "Epoch 2: train loss: 0.265094518661499\n",
      "Epoch 2: train loss: 0.18155641853809357\n",
      "Epoch 2: train loss: 0.21548157930374146\n",
      "Epoch 2: train loss: 0.22242604196071625\n",
      "Epoch 2: train loss: 0.33179545402526855\n",
      "Epoch 2: train loss: 0.11729001253843307\n",
      "Epoch 2: train loss: 0.20047004520893097\n",
      "Epoch 2: train loss: 0.38598042726516724\n",
      "Epoch 2: train loss: 0.13635903596878052\n",
      "Epoch 2: train loss: 0.17610345780849457\n",
      "Epoch 2: train loss: 0.2511940002441406\n",
      "Epoch 2: train loss: 0.08965371549129486\n",
      "Epoch 2: train loss: 0.04380885139107704\n",
      "Epoch 2: train loss: 0.11145385354757309\n",
      "Epoch 2: train loss: 0.2861229181289673\n",
      "Epoch 2: train loss: 0.1561787873506546\n",
      "Epoch 2: train loss: 0.25685033202171326\n",
      "Epoch 2: train loss: 0.20422664284706116\n",
      "Epoch 2: train loss: 0.10106655955314636\n",
      "Epoch 2: train loss: 0.27046602964401245\n",
      "Epoch 2: train loss: 0.24840699136257172\n",
      "Epoch 2: train loss: 0.3557220995426178\n",
      "Epoch 2: train loss: 0.37577757239341736\n",
      "Epoch 2: train loss: 0.3347613513469696\n",
      "Epoch 2: train loss: 0.3380705416202545\n",
      "Epoch 2: train loss: 0.14255158603191376\n",
      "Epoch 2: train loss: 0.08691808581352234\n",
      "Epoch 2: train loss: 0.23019658029079437\n",
      "Epoch 2: train loss: 0.26340919733047485\n",
      "Epoch 2: train loss: 0.32564985752105713\n",
      "Epoch 2: train loss: 0.17544446885585785\n",
      "Epoch 2: train loss: 0.24437235295772552\n",
      "Epoch 2: train loss: 0.2624848484992981\n",
      "Epoch 2: train loss: 0.41807419061660767\n",
      "Epoch 2: train loss: 0.14969402551651\n",
      "Epoch 2: train loss: 0.4764968752861023\n",
      "Epoch 2: train loss: 0.2909529507160187\n",
      "Epoch 2: train loss: 0.20219233632087708\n",
      "Epoch 2: train loss: 0.2231418788433075\n",
      "Epoch 2: train loss: 0.25097936391830444\n",
      "Epoch 2: train loss: 0.16044114530086517\n",
      "Epoch 2: train loss: 0.1541900932788849\n",
      "Epoch 2: train loss: 0.3028188645839691\n",
      "Epoch 2: train loss: 0.6420191526412964\n",
      "Epoch 2: train loss: 0.17500153183937073\n",
      "Epoch 2: train loss: 0.23797541856765747\n",
      "Epoch 2: train loss: 0.3624818027019501\n",
      "Epoch 2: train loss: 0.14851991832256317\n",
      "Epoch 2: train loss: 0.10199059545993805\n",
      "Epoch 2: train loss: 0.16652633249759674\n",
      "Epoch 2: train loss: 0.09957066923379898\n",
      "Epoch 2: train loss: 0.14318406581878662\n",
      "Epoch 2: train loss: 0.2881326973438263\n",
      "Epoch 2: train loss: 0.17666678130626678\n",
      "Epoch 2: train loss: 0.12291620671749115\n",
      "Epoch 2: train loss: 0.3473169207572937\n",
      "Epoch 2: train loss: 0.3176547884941101\n",
      "Epoch 2: train loss: 0.08516006916761398\n",
      "Epoch 2: train loss: 0.2665266990661621\n",
      "Epoch 2: train loss: 0.16530920565128326\n",
      "Epoch 2: train loss: 0.0854511484503746\n",
      "Epoch 2: train loss: 0.31073349714279175\n",
      "Epoch 2: train loss: 0.5294747352600098\n",
      "Epoch 2: train loss: 0.08554454892873764\n",
      "Epoch 2: train loss: 0.3998364508152008\n",
      "Epoch 2: train loss: 0.12999530136585236\n",
      "Epoch 2: train loss: 0.2466067522764206\n",
      "Epoch 2: train loss: 0.4732803702354431\n",
      "Epoch 2: train loss: 0.11491051316261292\n",
      "Epoch 2: train loss: 0.2401149421930313\n",
      "Epoch 2: train loss: 0.11846788972616196\n",
      "Epoch 2: train loss: 0.4170037806034088\n",
      "Epoch 2: train loss: 0.17802461981773376\n",
      "Epoch 2: train loss: 0.1996900588274002\n",
      "Epoch 2: train loss: 0.1992722749710083\n",
      "Epoch 2: train loss: 0.2469523549079895\n",
      "Epoch 2: train loss: 0.26899150013923645\n",
      "Epoch 2: train loss: 0.2027541846036911\n",
      "Epoch 2: train loss: 0.22078850865364075\n",
      "Epoch 2: train loss: 0.23004277050495148\n",
      "Epoch 2: train loss: 0.13736769556999207\n",
      "Epoch 2: train loss: 0.1527707427740097\n",
      "Epoch 2: train loss: 0.19586975872516632\n",
      "Epoch 2: train loss: 0.15842285752296448\n",
      "Epoch 2: train loss: 0.5534600019454956\n",
      "Epoch 2: train loss: 0.16861213743686676\n",
      "Epoch 2: train loss: 0.18324948847293854\n",
      "Epoch 2: train loss: 0.18965433537960052\n",
      "Epoch 2: train loss: 0.14704366028308868\n",
      "Epoch 2: train loss: 0.15684613585472107\n",
      "Epoch 2: train loss: 0.13116534054279327\n",
      "Epoch 2: train loss: 0.094092957675457\n",
      "Epoch 2: train loss: 0.08623632043600082\n",
      "Epoch 2: train loss: 0.0593329556286335\n",
      "Epoch 2: train loss: 0.21569162607192993\n",
      "Epoch 2: train loss: 0.03104185126721859\n",
      "Epoch 2: train loss: 0.19468002021312714\n",
      "Epoch 2: train loss: 0.06253134459257126\n",
      "Epoch 2: train loss: 0.04651020094752312\n",
      "Epoch 2: train loss: 0.34172871708869934\n",
      "Epoch 2: train loss: 0.24648715555667877\n",
      "Epoch 2: train loss: 0.024919966235756874\n",
      "Epoch 2: train loss: 0.05585027486085892\n",
      "Epoch 2: train loss: 0.05400238186120987\n",
      "Epoch 2: train loss: 0.04941895231604576\n",
      "Epoch 2: train loss: 0.3745233714580536\n",
      "Epoch 2: train loss: 0.047195885330438614\n",
      "Epoch 2: train loss: 0.2876788079738617\n",
      "Epoch 2: train loss: 0.017562853172421455\n",
      "Epoch 2: train loss: 0.1157834380865097\n",
      "Epoch 2: train loss: 0.11230994760990143\n",
      "Epoch 2: train loss: 0.23687966167926788\n",
      "Epoch 2: train loss: 0.07293672114610672\n",
      "Epoch 2: train loss: 0.414176344871521\n",
      "Epoch 2: train loss: 0.3728433847427368\n",
      "Epoch 2: train loss: 0.13016363978385925\n",
      "Epoch 2: train loss: 0.2464311718940735\n",
      "Epoch 2: train loss: 0.187753826379776\n",
      "Epoch 2: train loss: 0.14588002860546112\n",
      "Epoch 2: train loss: 0.3193274140357971\n",
      "Epoch 2: train loss: 0.2977627217769623\n",
      "Epoch 2: train loss: 0.29058021306991577\n",
      "Epoch 2: train loss: 0.09204212576150894\n",
      "Epoch 2: train loss: 0.13062714040279388\n",
      "Epoch 2: train loss: 0.20146779716014862\n",
      "Epoch 2: train loss: 0.09159407019615173\n",
      "Epoch 2: train loss: 0.22753654420375824\n",
      "Epoch 2: train loss: 0.056190866976976395\n",
      "Epoch 2: train loss: 0.2365918755531311\n",
      "Epoch 2: train loss: 0.1100744903087616\n",
      "Epoch 2: train loss: 0.2122485488653183\n",
      "Epoch 2: train loss: 0.1260663866996765\n",
      "Epoch 2: train loss: 0.3230848014354706\n",
      "Epoch 2: train loss: 0.21934393048286438\n",
      "Epoch 2: train loss: 0.07162032276391983\n",
      "Epoch 2: train loss: 0.051090143620967865\n",
      "Epoch 2: train loss: 0.04502909630537033\n",
      "Epoch 2: train loss: 0.03506144508719444\n",
      "Epoch 2: train loss: 0.30463966727256775\n",
      "Epoch 2: train loss: 0.15664993226528168\n",
      "Epoch 2: train loss: 0.5086212158203125\n",
      "Epoch 2: train loss: 0.44219717383384705\n",
      "Epoch 2: train loss: 0.210946723818779\n",
      "Epoch 2: train loss: 0.403890997171402\n",
      "Epoch 2: train loss: 0.3014134168624878\n",
      "Epoch 2: train loss: 0.18733686208724976\n",
      "Epoch 2: train loss: 0.09765307605266571\n",
      "Epoch 2: train loss: 0.20715434849262238\n",
      "Epoch 2: train loss: 0.08280344307422638\n",
      "Epoch 2: train loss: 0.3498464822769165\n",
      "Epoch 2: train loss: 0.16448567807674408\n",
      "Epoch 2: train loss: 0.12261360883712769\n",
      "Epoch 2: train loss: 0.3676203787326813\n",
      "Epoch 2: train loss: 0.10573519766330719\n",
      "Epoch 2: train loss: 0.32835885882377625\n",
      "Epoch 2: train loss: 0.1686811000108719\n",
      "Epoch 2: train loss: 0.16300970315933228\n",
      "Epoch 2: train loss: 0.34188491106033325\n",
      "Epoch 2: train loss: 0.37755683064460754\n",
      "Epoch 2: train loss: 0.07828149199485779\n",
      "Epoch 2: train loss: 0.10705035924911499\n",
      "Epoch 2: train loss: 0.4136732816696167\n",
      "Epoch 2: train loss: 0.18310853838920593\n",
      "Epoch 2: train loss: 0.21672527492046356\n",
      "Epoch 2: train loss: 0.5353320837020874\n",
      "Epoch 2: train loss: 0.28549274802207947\n",
      "Epoch 2: train loss: 0.15263739228248596\n",
      "Epoch 2: train loss: 0.2961885631084442\n",
      "Epoch 2: train loss: 0.1017647460103035\n",
      "Epoch 2: train loss: 0.31363335251808167\n",
      "Epoch 2: train loss: 0.0823487788438797\n",
      "Epoch 2: train loss: 0.2880895733833313\n",
      "Epoch 2: train loss: 0.3028564453125\n",
      "Epoch 2: train loss: 0.3049098551273346\n",
      "Epoch 2: train loss: 0.07938128709793091\n",
      "Epoch 2: train loss: 0.30735281109809875\n",
      "Epoch 2: train loss: 0.19606564939022064\n",
      "Epoch 2: train loss: 0.39903685450553894\n",
      "Epoch 2: train loss: 0.06297662854194641\n",
      "Epoch 2: train loss: 0.3098556101322174\n",
      "Epoch 2: train loss: 0.3718373775482178\n",
      "Epoch 2: train loss: 0.12705059349536896\n",
      "Epoch 2: train loss: 0.10947167873382568\n",
      "Epoch 2: train loss: 0.29134970903396606\n",
      "Epoch 2: train loss: 0.209888756275177\n",
      "Epoch 2: train loss: 0.1731133759021759\n",
      "Epoch 2: train loss: 0.14303289353847504\n",
      "Epoch 2: train loss: 0.18916770815849304\n",
      "Epoch 2: train loss: 0.21172760426998138\n",
      "Epoch 2: train loss: 0.26954060792922974\n",
      "Epoch 2: train loss: 0.316354364156723\n",
      "Epoch 2: train loss: 0.2721555233001709\n",
      "Epoch 2: train loss: 0.17162388563156128\n",
      "Epoch 2: train loss: 0.2843918800354004\n",
      "Epoch 2: train loss: 0.2617284059524536\n",
      "Epoch 2: train loss: 0.3028084933757782\n",
      "Epoch 2: train loss: 0.19726741313934326\n",
      "Epoch 2: train loss: 0.4693506360054016\n",
      "Epoch 2: train loss: 0.15006332099437714\n",
      "Epoch 2: train loss: 0.07244990020990372\n",
      "Epoch 2: train loss: 0.12849992513656616\n",
      "Epoch 2: train loss: 0.20861102640628815\n",
      "Epoch 2: train loss: 0.25582391023635864\n",
      "Epoch 2: train loss: 0.15627330541610718\n",
      "Epoch 2: train loss: 0.14822790026664734\n",
      "Epoch 2: train loss: 0.17577704787254333\n",
      "Epoch 2: train loss: 0.12798872590065002\n",
      "Epoch 2: train loss: 0.2079389989376068\n",
      "Epoch 2: train loss: 0.11157572269439697\n",
      "Epoch 2: train loss: 0.05931267887353897\n",
      "Epoch 2: train loss: 0.0485072061419487\n",
      "Epoch 2: train loss: 0.08881627023220062\n",
      "Epoch 2: train loss: 0.12732912600040436\n",
      "Epoch 2: train loss: 0.045492690056562424\n",
      "Epoch 2: train loss: 0.052008211612701416\n",
      "Epoch 2: train loss: 0.04412269592285156\n",
      "Epoch 2: train loss: 0.06433228403329849\n",
      "Epoch 2: train loss: 0.2564292252063751\n",
      "Epoch 2: train loss: 0.179710254073143\n",
      "Epoch 2: train loss: 0.12511298060417175\n",
      "Epoch 2: train loss: 0.32081928849220276\n",
      "Epoch 2: train loss: 0.06983024626970291\n",
      "Epoch 2: train loss: 0.030508816242218018\n",
      "Epoch 2: train loss: 0.044997438788414\n",
      "Epoch 2: train loss: 0.50697922706604\n",
      "Epoch 2: train loss: 0.34870681166648865\n",
      "Epoch 2: train loss: 0.1472809761762619\n",
      "Epoch 2: train loss: 0.3402819335460663\n",
      "Epoch 2: train loss: 0.5212092995643616\n",
      "Epoch 2: train loss: 0.31328168511390686\n",
      "Epoch 2: train loss: 0.1775849610567093\n",
      "Epoch 2: train loss: 0.1514793485403061\n",
      "Epoch 2: train loss: 0.0951773077249527\n",
      "Epoch 2: train loss: 0.3261536955833435\n",
      "Epoch 2: train loss: 0.29196688532829285\n",
      "Epoch 2: train loss: 0.35071924328804016\n",
      "Epoch 2: train loss: 0.06330560147762299\n",
      "Epoch 2: train loss: 0.27237510681152344\n",
      "Epoch 2: train loss: 0.2717539370059967\n",
      "Epoch 2: train loss: 0.09040451794862747\n",
      "Epoch 2: train loss: 0.331308513879776\n",
      "Epoch 2: train loss: 0.17785939574241638\n",
      "Epoch 2: train loss: 0.2799685299396515\n",
      "Epoch 2: train loss: 0.2944549322128296\n",
      "Epoch 2: train loss: 0.21032868325710297\n",
      "Epoch 2: train loss: 0.20280294120311737\n",
      "Epoch 2: train loss: 0.16623909771442413\n",
      "Epoch 2: train loss: 0.14372435212135315\n",
      "Epoch 2: train loss: 0.22581252455711365\n",
      "Epoch 2: train loss: 0.23700138926506042\n",
      "Epoch 2: train loss: 0.2311888337135315\n",
      "Epoch 2: train loss: 0.1156563013792038\n",
      "Epoch 2: train loss: 0.4201498329639435\n",
      "Epoch 2: train loss: 0.15498760342597961\n",
      "Epoch 2: train loss: 0.14232395589351654\n",
      "Epoch 2: train loss: 0.20603108406066895\n",
      "Epoch 2: train loss: 0.3302978277206421\n",
      "Epoch 2: train loss: 0.04849996790289879\n",
      "Epoch 2: train loss: 0.16957688331604004\n",
      "Epoch 2: train loss: 0.2644963562488556\n",
      "Epoch 2: train loss: 0.12932652235031128\n",
      "Epoch 2: train loss: 0.17560462653636932\n",
      "Epoch 2: train loss: 0.073478564620018\n",
      "Epoch 2: train loss: 0.23937517404556274\n",
      "Epoch 2: train loss: 0.14799900352954865\n",
      "Epoch 2: train loss: 0.050256434828042984\n",
      "Epoch 2: train loss: 0.16038396954536438\n",
      "Epoch 2: train loss: 0.31793180108070374\n",
      "Epoch 2: train loss: 0.2004992663860321\n",
      "Epoch 2: train loss: 0.28074848651885986\n",
      "Epoch 2: train loss: 0.17202672362327576\n",
      "Epoch 2: train loss: 0.2241506427526474\n",
      "Epoch 2: train loss: 0.04518970847129822\n",
      "Epoch 2: train loss: 0.2586057782173157\n",
      "Epoch 2: train loss: 0.21190457046031952\n",
      "Epoch 2: train loss: 0.22903166711330414\n",
      "Epoch 2: train loss: 0.032668501138687134\n",
      "Epoch 2: train loss: 0.3501526117324829\n",
      "Epoch 2: train loss: 0.24485009908676147\n",
      "Epoch 2: train loss: 0.07609579712152481\n",
      "Epoch 2: train loss: 0.07935179024934769\n",
      "Epoch 2: train loss: 0.09584414958953857\n",
      "Epoch 2: train loss: 0.20024286210536957\n",
      "Epoch 2: train loss: 0.11322028934955597\n",
      "Epoch 2: train loss: 0.23861299455165863\n",
      "Epoch 2: train loss: 0.17405582964420319\n",
      "Epoch 2: train loss: 0.13695578277111053\n",
      "Epoch 2: train loss: 0.11466734111309052\n",
      "Epoch 2: train loss: 0.07321198284626007\n",
      "Epoch 2: train loss: 0.20567332208156586\n",
      "Epoch 2: train loss: 0.6821647882461548\n",
      "Epoch 2: train loss: 0.2352149933576584\n",
      "Epoch 2: train loss: 0.17786580324172974\n",
      "Epoch 2: train loss: 0.14382289350032806\n",
      "Epoch 2: train loss: 0.23239676654338837\n",
      "Epoch 2: train loss: 0.15858714282512665\n",
      "Epoch 2: train loss: 0.2700786292552948\n",
      "Epoch 2: train loss: 0.3033183813095093\n",
      "Epoch 2: train loss: 0.24427300691604614\n",
      "Epoch 2: train loss: 0.05626927316188812\n",
      "Epoch 2: train loss: 0.180944561958313\n",
      "Epoch 2: train loss: 0.28605523705482483\n",
      "Epoch 2: train loss: 0.10829326510429382\n",
      "Epoch 2: train loss: 0.14802603423595428\n",
      "Epoch 2: train loss: 0.34583550691604614\n",
      "Epoch 2: train loss: 0.22121071815490723\n",
      "Epoch 2: train loss: 0.275926411151886\n",
      "Epoch 2: train loss: 0.1452702134847641\n",
      "Epoch 2: train loss: 0.256089985370636\n",
      "Epoch 2: train loss: 0.32150986790657043\n",
      "Epoch 2: train loss: 0.32271647453308105\n",
      "Epoch 2: train loss: 0.12874798476696014\n",
      "Epoch 2: train loss: 0.28303948044776917\n",
      "Epoch 2: train loss: 0.11665608733892441\n",
      "Epoch 2: train loss: 0.1890893280506134\n",
      "Epoch 2: train loss: 0.20202012360095978\n",
      "Epoch 2: train loss: 0.27813205122947693\n",
      "Epoch 2: train loss: 0.11933513730764389\n",
      "Epoch 2: train loss: 0.17510391771793365\n",
      "Epoch 2: train loss: 0.09116839617490768\n",
      "Epoch 2: train loss: 0.13298021256923676\n",
      "Epoch 2: train loss: 0.11780069768428802\n",
      "Epoch 2: train loss: 0.4445648193359375\n",
      "Epoch 2: train loss: 0.23846131563186646\n",
      "Epoch 2: train loss: 0.09525836259126663\n",
      "Epoch 2: train loss: 0.07697756588459015\n",
      "Epoch 2: train loss: 0.18559373915195465\n",
      "Epoch 2: train loss: 0.1493614763021469\n",
      "Epoch 2: train loss: 0.07383662462234497\n",
      "Epoch 2: train loss: 0.04510052129626274\n",
      "Epoch 2: train loss: 0.45995384454727173\n",
      "Epoch 2: train loss: 0.040418434888124466\n",
      "Epoch 2: train loss: 0.04737336188554764\n",
      "Epoch 2: train loss: 0.1938764452934265\n",
      "Epoch 2: train loss: 0.038386497646570206\n",
      "Epoch 2: train loss: 0.2270563840866089\n",
      "Epoch 2: train loss: 0.13235943019390106\n",
      "Epoch 2: train loss: 0.15182340145111084\n",
      "Epoch 2: train loss: 0.10696495324373245\n",
      "Epoch 2: train loss: 0.4415786862373352\n",
      "Epoch 2: train loss: 0.320746511220932\n",
      "Epoch 2: train loss: 0.3139449954032898\n",
      "Epoch 2: train loss: 0.05473184213042259\n",
      "Epoch 2: train loss: 0.11234112828969955\n",
      "Epoch 2: train loss: 0.17526626586914062\n",
      "Epoch 2: train loss: 0.1700555682182312\n",
      "Epoch 2: train loss: 0.16101978719234467\n",
      "Epoch 2: train loss: 0.17882482707500458\n",
      "Epoch 2: train loss: 0.2650757133960724\n",
      "Epoch 2: train loss: 0.06154968962073326\n",
      "Epoch 2: train loss: 0.07277526706457138\n",
      "Epoch 2: train loss: 0.11526218056678772\n",
      "Epoch 2: train loss: 0.26321712136268616\n",
      "Epoch 2: train loss: 0.24477291107177734\n",
      "Epoch 2: train loss: 0.20754675567150116\n",
      "Epoch 2: train loss: 0.21925480663776398\n",
      "Epoch 2: train loss: 0.13108594715595245\n",
      "Epoch 2: train loss: 0.31698113679885864\n",
      "Epoch 2: train loss: 0.062363505363464355\n",
      "Epoch 2: train loss: 0.21157290041446686\n",
      "Epoch 2: train loss: 0.2548414468765259\n",
      "Epoch 2: train loss: 0.21247732639312744\n",
      "Epoch 2: train loss: 0.36084744334220886\n",
      "Epoch 2: train loss: 0.08217932283878326\n",
      "Epoch 2: train loss: 0.17360079288482666\n",
      "Epoch 2: train loss: 0.19154947996139526\n",
      "Epoch 2: train loss: 0.206547349691391\n",
      "Epoch 2: train loss: 0.16991227865219116\n",
      "Epoch 2: train loss: 0.07003374397754669\n",
      "Epoch 2: train loss: 0.27031829953193665\n",
      "Epoch 2: train loss: 0.2493189126253128\n",
      "Epoch 2: train loss: 0.15320245921611786\n",
      "Epoch 2: train loss: 0.1236160397529602\n",
      "Epoch 2: train loss: 0.29670846462249756\n",
      "Epoch 2: train loss: 0.14640843868255615\n",
      "Epoch 2: train loss: 0.2204737812280655\n",
      "Epoch 2: train loss: 0.1894424557685852\n",
      "Epoch 2: train loss: 0.2570597529411316\n",
      "Epoch 2: train loss: 0.05961695685982704\n",
      "Epoch 2: train loss: 0.18548482656478882\n",
      "Epoch 2: train loss: 0.0770718902349472\n",
      "Epoch 2: train loss: 0.18350356817245483\n",
      "Epoch 2: train loss: 0.17402638494968414\n",
      "Epoch 2: train loss: 0.13612888753414154\n",
      "Epoch 2: train loss: 0.17435412108898163\n",
      "Epoch 2: train loss: 0.26251721382141113\n",
      "Epoch 2: train loss: 0.16628767549991608\n",
      "Epoch 2: train loss: 0.128950297832489\n",
      "Epoch 2: train loss: 0.3238028287887573\n",
      "Epoch 2: train loss: 0.1796698123216629\n",
      "Epoch 2: train loss: 0.06759567558765411\n",
      "Epoch 2: train loss: 0.34203284978866577\n",
      "Epoch 2: train loss: 0.44639697670936584\n",
      "Epoch 2: train loss: 0.10771510004997253\n",
      "Epoch 2: train loss: 0.1769597828388214\n",
      "Epoch 2: train loss: 0.20881478488445282\n",
      "Epoch 2: train loss: 0.19081997871398926\n",
      "Epoch 2: train loss: 0.08758758753538132\n",
      "Epoch 2: train loss: 0.42143669724464417\n",
      "Epoch 2: train loss: 0.1575997918844223\n",
      "Epoch 2: train loss: 0.059347089380025864\n",
      "Epoch 2: train loss: 0.12218695133924484\n",
      "Epoch 2: train loss: 0.140920951962471\n",
      "Epoch 2: train loss: 0.2079407423734665\n",
      "Epoch 2: train loss: 0.12435509264469147\n",
      "Epoch 2: train loss: 0.06163936108350754\n",
      "Epoch 2: train loss: 0.35958781838417053\n",
      "Epoch 2: train loss: 0.20374473929405212\n",
      "Epoch 2: train loss: 0.27266213297843933\n",
      "Epoch 2: train loss: 0.24435992538928986\n",
      "Epoch 2: train loss: 0.1731596291065216\n",
      "Epoch 2: train loss: 0.10608098655939102\n",
      "Epoch 2: train loss: 0.22666124999523163\n",
      "Epoch 2: train loss: 0.30308693647384644\n",
      "Epoch 2: train loss: 0.29980579018592834\n",
      "Epoch 2: train loss: 0.33920228481292725\n",
      "Epoch 2: train loss: 0.1866293102502823\n",
      "Epoch 2: train loss: 0.13889293372631073\n",
      "Epoch 2: train loss: 0.1863514482975006\n",
      "Epoch 2: train loss: 0.11329226940870285\n",
      "Epoch 2: train loss: 0.1098564863204956\n",
      "Epoch 2: train loss: 0.07992036640644073\n",
      "Epoch 2: train loss: 0.061229340732097626\n",
      "Epoch 2: train loss: 0.0988258495926857\n",
      "Epoch 2: train loss: 0.13472065329551697\n",
      "Epoch 2: train loss: 0.17749227583408356\n",
      "Epoch 2: train loss: 0.3402694761753082\n",
      "Epoch 2: train loss: 0.2673910856246948\n",
      "Epoch 2: train loss: 0.2762860655784607\n",
      "Epoch 2: train loss: 0.042635176330804825\n",
      "Epoch 2: train loss: 0.09303363412618637\n",
      "Epoch 2: train loss: 0.1825944185256958\n",
      "Epoch 2: train loss: 0.15150205790996552\n",
      "Epoch 2: train loss: 0.11674145609140396\n",
      "Epoch 2: train loss: 0.29062703251838684\n",
      "Epoch 2: train loss: 0.569294810295105\n",
      "Epoch 2: train loss: 0.136942520737648\n",
      "Epoch 2: train loss: 0.22494347393512726\n",
      "Epoch 2: train loss: 0.2582017481327057\n",
      "Epoch 2: train loss: 0.3050692081451416\n",
      "Epoch 2: train loss: 0.14396151900291443\n",
      "Epoch 2: train loss: 0.65192049741745\n",
      "Epoch 2: train loss: 0.0944579616189003\n",
      "Epoch 2: train loss: 0.3037538528442383\n",
      "Epoch 2: train loss: 0.1324266791343689\n",
      "Epoch 2: train loss: 0.3276609182357788\n",
      "Epoch 2: train loss: 0.1855253279209137\n",
      "Epoch 2: train loss: 0.19648399949073792\n",
      "Epoch 2: train loss: 0.17840968072414398\n",
      "Epoch 2: train loss: 0.23171338438987732\n",
      "Epoch 2: train loss: 0.16580551862716675\n",
      "Epoch 2: train loss: 0.1911413073539734\n",
      "Epoch 2: train loss: 0.17724305391311646\n",
      "Epoch 2: train loss: 0.13562114536762238\n",
      "Epoch 2: train loss: 0.14635668694972992\n",
      "Epoch 2: train loss: 0.18577909469604492\n",
      "Epoch 2: train loss: 0.3431382179260254\n",
      "Epoch 2: train loss: 0.1645077019929886\n",
      "Epoch 2: train loss: 0.13251686096191406\n",
      "Epoch 2: train loss: 0.2948145568370819\n",
      "Epoch 2: train loss: 0.2475052922964096\n",
      "Epoch 2: train loss: 0.03578969091176987\n",
      "Epoch 2: train loss: 0.056468695402145386\n",
      "Epoch 2: train loss: 0.1511431485414505\n",
      "Epoch 2: train loss: 0.39956772327423096\n",
      "Epoch 2: train loss: 0.15776658058166504\n",
      "Epoch 2: train loss: 0.1990371197462082\n",
      "Epoch 2: train loss: 0.45134660601615906\n",
      "Epoch 2: train loss: 0.12350396811962128\n",
      "Epoch 2: train loss: 0.1943865716457367\n",
      "Epoch 2: train loss: 0.4002983868122101\n",
      "Epoch 2: train loss: 0.1654016226530075\n",
      "Epoch 2: train loss: 0.15140162408351898\n",
      "Epoch 2: train loss: 0.1171058863401413\n",
      "Epoch 2: train loss: 0.16958501935005188\n",
      "Epoch 2: train loss: 0.25093549489974976\n",
      "Epoch 2: train loss: 0.11110544949769974\n",
      "Epoch 2: train loss: 0.11555980145931244\n",
      "Epoch 2: train loss: 0.1759975701570511\n",
      "Epoch 2: train loss: 0.2432183027267456\n",
      "Epoch 2: train loss: 0.26714852452278137\n",
      "Epoch 2: train loss: 0.08220993727445602\n",
      "Epoch 2: train loss: 0.31700360774993896\n",
      "Epoch 2: train loss: 0.3225875496864319\n",
      "Epoch 2: train loss: 0.26797303557395935\n",
      "Epoch 2: train loss: 0.2639380395412445\n",
      "Epoch 2: train loss: 0.07859767973423004\n",
      "Epoch 2: train loss: 0.17709268629550934\n",
      "Epoch 2: train loss: 0.22471898794174194\n",
      "Epoch 2: train loss: 0.38438281416893005\n",
      "Epoch 2: train loss: 0.24960832297801971\n",
      "Epoch 2: train loss: 0.17740921676158905\n",
      "Epoch 2: train loss: 0.2538144886493683\n",
      "Epoch 2: train loss: 0.0839776024222374\n",
      "Epoch 2: train loss: 0.1748310774564743\n",
      "Epoch 2: train loss: 0.1356644183397293\n",
      "Epoch 2: train loss: 0.25386491417884827\n",
      "Epoch 2: train loss: 0.12560498714447021\n",
      "Epoch 2: train loss: 0.3873822093009949\n",
      "Epoch 2: train loss: 0.05853815749287605\n",
      "Epoch 2: train loss: 0.10583735257387161\n",
      "Epoch 2: train loss: 0.05267145484685898\n",
      "Epoch 2: train loss: 0.203650563955307\n",
      "Epoch 2: train loss: 0.24983012676239014\n",
      "Epoch 2: train loss: 0.12283407151699066\n",
      "Epoch 2: train loss: 0.19543513655662537\n",
      "Epoch 2: train loss: 0.062049899250268936\n",
      "Epoch 2: train loss: 0.11612322926521301\n",
      "Epoch 2: train loss: 0.11251471191644669\n",
      "Epoch 2: train loss: 0.3046816885471344\n",
      "Epoch 2: train loss: 0.18870723247528076\n",
      "Epoch 2: train loss: 0.12319770455360413\n",
      "Epoch 2: train loss: 0.20760536193847656\n",
      "Epoch 2: train loss: 0.1796754151582718\n",
      "Epoch 2: train loss: 0.25223568081855774\n",
      "Epoch 2: train loss: 0.2600986361503601\n",
      "Epoch 2: train loss: 0.0762423723936081\n",
      "Epoch 2: train loss: 0.31281206011772156\n",
      "Epoch 2: train loss: 0.23459848761558533\n",
      "Epoch 2: train loss: 0.2420814335346222\n",
      "Epoch 2: train loss: 0.19011105597019196\n",
      "Epoch 2: train loss: 0.21792376041412354\n",
      "Epoch 2: train loss: 0.2029629796743393\n",
      "Epoch 2: train loss: 0.07595054060220718\n",
      "Epoch 2: train loss: 0.09072863310575485\n",
      "Epoch 2: train loss: 0.3680107295513153\n",
      "Epoch 2: train loss: 0.36385607719421387\n",
      "Epoch 2: train loss: 0.10697457939386368\n",
      "Epoch 2: train loss: 0.07664362341165543\n",
      "Epoch 2: train loss: 0.23677074909210205\n",
      "Epoch 2: train loss: 0.15574516355991364\n",
      "Epoch 2: train loss: 0.15311512351036072\n",
      "Epoch 2: train loss: 0.22330592572689056\n",
      "Epoch 2: train loss: 0.19417844712734222\n",
      "Epoch 2: train loss: 0.08588594198226929\n",
      "Epoch 2: train loss: 0.14501066505908966\n",
      "Epoch 2: train loss: 0.14266085624694824\n",
      "Epoch 2: train loss: 0.4159644842147827\n",
      "Epoch 2: train loss: 0.10493932664394379\n",
      "Epoch 2: train loss: 0.2533915042877197\n",
      "Epoch 2: train loss: 0.3002760708332062\n",
      "Epoch 2: train loss: 0.5135713219642639\n",
      "Epoch 2: train loss: 0.10848075151443481\n",
      "Epoch 2: train loss: 0.05569608882069588\n",
      "Epoch 2: train loss: 0.1897190660238266\n",
      "Epoch 2: train loss: 0.18993622064590454\n",
      "Epoch 2: train loss: 0.11909503489732742\n",
      "Epoch 2: train loss: 0.2939668893814087\n",
      "Epoch 2: train loss: 0.11922157555818558\n",
      "Epoch 2: train loss: 0.22094590961933136\n",
      "Epoch 2: train loss: 0.09923139959573746\n",
      "Epoch 2: train loss: 0.14363887906074524\n",
      "Epoch 2: train loss: 0.14798268675804138\n",
      "Epoch 2: train loss: 0.18740957975387573\n",
      "Epoch 2: train loss: 0.16816943883895874\n",
      "Epoch 2: train loss: 0.1295677274465561\n",
      "Epoch 2: train loss: 0.20253190398216248\n",
      "Epoch 2: train loss: 0.23347802460193634\n",
      "Epoch 2: train loss: 0.1744893193244934\n",
      "Epoch 2: train loss: 0.21760351955890656\n",
      "Epoch 2: train loss: 0.10600078850984573\n",
      "Epoch 2: train loss: 0.15895682573318481\n",
      "Epoch 2: train loss: 0.12561409175395966\n",
      "Epoch 2: train loss: 0.14199189841747284\n",
      "Epoch 2: train loss: 0.19494570791721344\n",
      "Epoch 2: train loss: 0.24722811579704285\n",
      "Epoch 2: train loss: 0.2504901885986328\n",
      "Epoch 2: train loss: 0.2904512286186218\n",
      "Epoch 2: train loss: 0.1847001314163208\n",
      "Epoch 2: train loss: 0.16930097341537476\n",
      "Epoch 2: train loss: 0.3310891389846802\n",
      "Epoch 2: train loss: 0.03715125843882561\n",
      "Epoch 2: train loss: 0.22228631377220154\n",
      "Epoch 2: train loss: 0.3415977954864502\n",
      "Epoch 2: train loss: 0.05073067173361778\n",
      "Epoch 2: train loss: 0.25579899549484253\n",
      "Epoch 2: train loss: 0.07770714908838272\n",
      "Epoch 2: train loss: 0.34004828333854675\n",
      "Epoch 2: train loss: 0.24962301552295685\n",
      "Epoch 2: train loss: 0.24694469571113586\n",
      "Epoch 2: train loss: 0.36749163269996643\n",
      "Epoch 2: train loss: 0.10790213197469711\n",
      "Epoch 2: train loss: 0.3330669105052948\n",
      "Epoch 2: train loss: 0.2811678946018219\n",
      "Epoch 2: train loss: 0.21160702407360077\n",
      "Epoch 2: train loss: 0.24790015816688538\n",
      "Epoch 2: train loss: 0.10198688507080078\n",
      "Epoch 2: train loss: 0.25701600313186646\n",
      "Epoch 2: train loss: 0.16962040960788727\n",
      "Epoch 2: train loss: 0.12816573679447174\n",
      "Epoch 2: train loss: 0.15918420255184174\n",
      "Epoch 2: train loss: 0.1944258213043213\n",
      "Epoch 2: train loss: 0.45227280259132385\n",
      "Epoch 2: train loss: 0.23007477819919586\n",
      "Epoch 2: train loss: 0.07190325111150742\n",
      "Epoch 2: train loss: 0.04808223992586136\n",
      "Epoch 2: train loss: 0.29478079080581665\n",
      "Epoch 2: train loss: 0.07390043139457703\n",
      "Epoch 2: train loss: 0.19288207590579987\n",
      "Epoch 2: train loss: 0.04295435920357704\n",
      "Epoch 2: train loss: 0.054955631494522095\n",
      "Epoch 2: train loss: 0.19923649728298187\n",
      "Epoch 2: train loss: 0.07283938676118851\n",
      "Epoch 2: train loss: 0.06203683838248253\n",
      "Epoch 2: train loss: 0.4434102475643158\n",
      "Epoch 2: train loss: 0.032690949738025665\n",
      "Epoch 2: train loss: 0.09558527171611786\n",
      "Epoch 2: train loss: 0.0860186442732811\n",
      "Epoch 2: train loss: 0.2560773193836212\n",
      "Epoch 2: train loss: 0.22427760064601898\n",
      "Epoch 2: train loss: 0.11521973460912704\n",
      "Epoch 2: train loss: 0.02252669632434845\n",
      "Epoch 2: train loss: 0.1542961746454239\n",
      "Epoch 2: train loss: 0.344937801361084\n",
      "Epoch 2: train loss: 0.24443626403808594\n",
      "Epoch 2: train loss: 0.169906884431839\n",
      "Epoch 2: train loss: 0.361329048871994\n",
      "Epoch 2: train loss: 0.42835304141044617\n",
      "Epoch 2: train loss: 0.3414534330368042\n",
      "Epoch 2: train loss: 0.0801679790019989\n",
      "Epoch 2: train loss: 0.20507080852985382\n",
      "Epoch 2: train loss: 0.30050647258758545\n",
      "Epoch 2: train loss: 0.16754552721977234\n",
      "Epoch 2: train loss: 0.2014550268650055\n",
      "Epoch 2: train loss: 0.2807442247867584\n",
      "Epoch 2: train loss: 0.35585543513298035\n",
      "Epoch 2: train loss: 0.22159834206104279\n",
      "Epoch 2: train loss: 0.16837632656097412\n",
      "Epoch 2: train loss: 0.28088948130607605\n",
      "Epoch 2: train loss: 0.30947136878967285\n",
      "Epoch 2: train loss: 0.23155038058757782\n",
      "Epoch 2: train loss: 0.20832328498363495\n",
      "Epoch 2: train loss: 0.31253936886787415\n",
      "Epoch 2: train loss: 0.27482470870018005\n",
      "Epoch 2: train loss: 0.12359855324029922\n",
      "Epoch 2: train loss: 0.2692258059978485\n",
      "Epoch 2: train loss: 0.14540019631385803\n",
      "Epoch 2: train loss: 0.14871400594711304\n",
      "Epoch 2: train loss: 0.2785187363624573\n",
      "Epoch 2: train loss: 0.3060306906700134\n",
      "Epoch 2: train loss: 0.17563389241695404\n",
      "Epoch 2: train loss: 0.05462757498025894\n",
      "Epoch 2: train loss: 0.4253731071949005\n",
      "Epoch 2: train loss: 0.5265147686004639\n",
      "Epoch 2: train loss: 0.1412385106086731\n",
      "Epoch 2: train loss: 0.047353923320770264\n",
      "Epoch 2: train loss: 0.11967577040195465\n",
      "Epoch 2: train loss: 0.22660250961780548\n",
      "Epoch 2: train loss: 0.09812606871128082\n",
      "Epoch 2: train loss: 0.19165165722370148\n",
      "Epoch 2: train loss: 0.28789839148521423\n",
      "Epoch 2: train loss: 0.42771652340888977\n",
      "Epoch 2: train loss: 0.10321887582540512\n",
      "Epoch 2: train loss: 0.1287262886762619\n",
      "Epoch 2: train loss: 0.31206104159355164\n",
      "Epoch 2: train loss: 0.07764147967100143\n",
      "Epoch 2: train loss: 0.11235090345144272\n",
      "Epoch 2: train loss: 0.07444300502538681\n",
      "Epoch 2: train loss: 0.14069817960262299\n",
      "Epoch 2: train loss: 0.047821998596191406\n",
      "Epoch 2: train loss: 0.12420521676540375\n",
      "Epoch 2: train loss: 0.17288397252559662\n",
      "Epoch 2: train loss: 0.4289231598377228\n",
      "Epoch 2: train loss: 0.3696499168872833\n",
      "Epoch 2: train loss: 0.3982316553592682\n",
      "Epoch 2: train loss: 0.06731308996677399\n",
      "Epoch 2: train loss: 0.20833837985992432\n",
      "Epoch 2: train loss: 0.20557059347629547\n",
      "Epoch 2: train loss: 0.16017039120197296\n",
      "Epoch 2: train loss: 0.2965472638607025\n",
      "Epoch 2: train loss: 0.1361403465270996\n",
      "Epoch 2: train loss: 0.09911061823368073\n",
      "Epoch 2: train loss: 0.28823280334472656\n",
      "Epoch 2: train loss: 0.2859608232975006\n",
      "Epoch 2: train loss: 0.04970955848693848\n",
      "Epoch 2: train loss: 0.2375761866569519\n",
      "Epoch 2: train loss: 0.20956175029277802\n",
      "Epoch 2: train loss: 0.24074219167232513\n",
      "Epoch 2: train loss: 0.16371025145053864\n",
      "Epoch 2: train loss: 0.26087865233421326\n",
      "Epoch 2: train loss: 0.149633526802063\n",
      "Epoch 2: train loss: 0.20904549956321716\n",
      "Epoch 2: train loss: 0.06705723702907562\n",
      "Epoch 2: train loss: 0.11333692818880081\n",
      "Epoch 2: train loss: 0.15275803208351135\n",
      "Epoch 2: train loss: 0.1154903694987297\n",
      "Epoch 2: train loss: 0.39882466197013855\n",
      "Epoch 2: train loss: 0.6175509095191956\n",
      "Epoch 2: train loss: 0.09208441525697708\n",
      "Epoch 2: train loss: 0.10771168023347855\n",
      "Epoch 2: train loss: 0.2200087457895279\n",
      "Epoch 2: train loss: 0.2519509792327881\n",
      "Epoch 2: train loss: 0.18918359279632568\n",
      "Epoch 2: train loss: 0.24074625968933105\n",
      "Epoch 2: train loss: 0.35390549898147583\n",
      "Epoch 2: train loss: 0.3782777786254883\n",
      "Epoch 2: train loss: 0.19281256198883057\n",
      "Epoch 2: train loss: 0.24988843500614166\n",
      "Epoch 2: train loss: 0.24952144920825958\n",
      "Epoch 2: train loss: 0.5009806156158447\n",
      "Epoch 2: train loss: 0.11603382229804993\n",
      "Epoch 2: train loss: 0.15930499136447906\n",
      "Epoch 2: train loss: 0.16593337059020996\n",
      "Epoch 2: train loss: 0.26950305700302124\n",
      "Epoch 2: train loss: 0.12429561465978622\n",
      "Epoch 2: train loss: 0.08875193446874619\n",
      "Epoch 2: train loss: 0.23139792680740356\n",
      "Epoch 2: train loss: 0.14500822126865387\n",
      "Epoch 2: train loss: 0.12147408723831177\n",
      "Epoch 2: train loss: 0.1077595204114914\n",
      "Epoch 2: train loss: 0.23005953431129456\n",
      "Epoch 2: train loss: 0.22249409556388855\n",
      "Epoch 2: train loss: 0.2696908414363861\n",
      "Epoch 2: train loss: 0.4732874631881714\n",
      "Epoch 2: train loss: 0.0776904970407486\n",
      "Epoch 2: train loss: 0.15702655911445618\n",
      "Epoch 2: train loss: 0.10719124972820282\n",
      "Epoch 2: train loss: 0.3195541501045227\n",
      "Epoch 2: train loss: 0.36056244373321533\n",
      "Epoch 2: train loss: 0.13664430379867554\n",
      "Epoch 2: train loss: 0.13041649758815765\n",
      "Epoch 2: train loss: 0.05916154012084007\n",
      "Epoch 2: train loss: 0.2876262366771698\n",
      "Epoch 2: train loss: 0.25135529041290283\n",
      "Epoch 2: train loss: 0.23892423510551453\n",
      "Epoch 2: train loss: 0.19758422672748566\n",
      "Epoch 2: train loss: 0.2008219212293625\n",
      "Epoch 2: train loss: 0.11246392130851746\n",
      "Epoch 2: train loss: 0.08545858412981033\n",
      "Epoch 2: train loss: 0.05679592862725258\n",
      "Epoch 2: train loss: 0.27927953004837036\n",
      "Epoch 2: train loss: 0.38005778193473816\n",
      "Epoch 2: train loss: 0.2696169316768646\n",
      "Epoch 2: train loss: 0.22961464524269104\n",
      "Epoch 2: train loss: 0.1111748218536377\n",
      "Epoch 2: train loss: 0.3004462718963623\n",
      "Epoch 2: train loss: 0.2786868214607239\n",
      "Epoch 2: train loss: 0.17957152426242828\n",
      "Epoch 2: train loss: 0.21715930104255676\n",
      "Epoch 2: train loss: 0.36723074316978455\n",
      "Epoch 2: train loss: 0.12155865132808685\n",
      "Epoch 2: train loss: 0.1568583995103836\n",
      "Epoch 2: train loss: 0.2133297324180603\n",
      "Epoch 2: train loss: 0.07287102937698364\n",
      "Epoch 2: train loss: 0.15000402927398682\n",
      "Epoch 2: train loss: 0.12504209578037262\n",
      "Epoch 2: train loss: 0.29734328389167786\n",
      "Epoch 2: train loss: 0.21720854938030243\n",
      "Epoch 2: train loss: 0.19410422444343567\n",
      "Epoch 2: train loss: 0.12596873939037323\n",
      "Epoch 2: train loss: 0.41446253657341003\n",
      "Epoch 2: train loss: 0.09530764073133469\n",
      "Epoch 2: train loss: 0.23530343174934387\n",
      "Epoch 2: train loss: 0.2708883285522461\n",
      "Epoch 2: train loss: 0.23763959109783173\n",
      "Epoch 2: train loss: 0.23747842013835907\n",
      "Epoch 2: train loss: 0.17935268580913544\n",
      "Epoch 2: train loss: 0.1481381058692932\n",
      "Epoch 2: train loss: 0.11756172776222229\n",
      "Epoch 2: train loss: 0.12961317598819733\n",
      "Epoch 2: train loss: 0.13149680197238922\n",
      "Epoch 2: train loss: 0.07052775472402573\n",
      "Epoch 2: train loss: 0.04212845489382744\n",
      "Epoch 2: train loss: 0.07878361642360687\n",
      "Epoch 2: train loss: 0.11636233329772949\n",
      "Epoch 2: train loss: 0.06894001364707947\n",
      "Epoch 2: train loss: 0.3160627782344818\n",
      "Epoch 2: train loss: 0.265168696641922\n",
      "Epoch 2: train loss: 0.20019623637199402\n",
      "Epoch 2: train loss: 0.6064882278442383\n",
      "Epoch 2: train loss: 0.1955035924911499\n",
      "Epoch 2: train loss: 0.16954851150512695\n",
      "Epoch 2: train loss: 0.23899433016777039\n",
      "Epoch 2: train loss: 0.30315548181533813\n",
      "Epoch 2: train loss: 0.05882100388407707\n",
      "Epoch 2: train loss: 0.0883418396115303\n",
      "Epoch 2: train loss: 0.15627849102020264\n",
      "Epoch 2: train loss: 0.2905779182910919\n",
      "Epoch 2: train loss: 0.26442718505859375\n",
      "Epoch 2: train loss: 0.399694561958313\n",
      "Epoch 2: train loss: 0.150847926735878\n",
      "Epoch 2: train loss: 0.07338561862707138\n",
      "Epoch 2: train loss: 0.24138088524341583\n",
      "Epoch 2: train loss: 0.10159024596214294\n",
      "Epoch 2: train loss: 0.09961728006601334\n",
      "Epoch 2: train loss: 0.3307858109474182\n",
      "Epoch 2: train loss: 0.09760081768035889\n",
      "Epoch 2: train loss: 0.2608320116996765\n",
      "Epoch 2: train loss: 0.261021226644516\n",
      "Epoch 2: train loss: 0.17812290787696838\n",
      "Epoch 2: train loss: 0.20069468021392822\n",
      "Epoch 2: train loss: 0.1211884468793869\n",
      "Epoch 2: train loss: 0.1968117356300354\n",
      "Epoch 2: train loss: 0.25405484437942505\n",
      "Epoch 2: train loss: 0.21907630562782288\n",
      "Epoch 2: train loss: 0.09055367112159729\n",
      "Epoch 2: train loss: 0.22196707129478455\n",
      "Epoch 2: train loss: 0.07373492419719696\n",
      "Epoch 2: train loss: 0.04136671870946884\n",
      "Epoch 2: train loss: 0.23026947677135468\n",
      "Epoch 2: train loss: 0.2898602783679962\n",
      "Epoch 2: train loss: 0.05744629353284836\n",
      "Epoch 2: train loss: 0.26075035333633423\n",
      "Epoch 2: train loss: 0.0401570163667202\n",
      "Epoch 2: train loss: 0.25184622406959534\n",
      "Epoch 2: train loss: 0.17817051708698273\n",
      "Epoch 2: train loss: 0.14501461386680603\n",
      "Epoch 2: train loss: 0.1381058543920517\n",
      "Epoch 2: train loss: 0.07895898073911667\n",
      "Epoch 2: train loss: 0.2205391526222229\n",
      "Epoch 2: train loss: 0.2533354163169861\n",
      "Epoch 2: train loss: 0.18113061785697937\n",
      "Epoch 2: train loss: 0.06413241475820541\n",
      "Epoch 2: train loss: 0.030108759179711342\n",
      "Epoch 2: train loss: 0.1553391069173813\n",
      "Epoch 2: train loss: 0.27618181705474854\n",
      "Epoch 2: train loss: 0.3001495897769928\n",
      "Epoch 2: train loss: 0.28199872374534607\n",
      "Epoch 2: train loss: 0.24456125497817993\n",
      "Epoch 2: train loss: 0.315638929605484\n",
      "Epoch 2: train loss: 0.1572800576686859\n",
      "Epoch 2: train loss: 0.2496291995048523\n",
      "Epoch 2: train loss: 0.04758424684405327\n",
      "Epoch 2: train loss: 0.33321329951286316\n",
      "Epoch 2: train loss: 0.3440041244029999\n",
      "Epoch 2: train loss: 0.19614087045192719\n",
      "Epoch 2: train loss: 0.14529210329055786\n",
      "Epoch 2: train loss: 0.4329752027988434\n",
      "Epoch 2: train loss: 0.1643715649843216\n",
      "Epoch 2: train loss: 0.09305965900421143\n",
      "Epoch 2: train loss: 0.263151079416275\n",
      "Epoch 2: train loss: 0.14555151760578156\n",
      "Epoch 2: train loss: 0.08386846631765366\n",
      "Epoch 2: train loss: 0.09122881293296814\n",
      "Epoch 2: train loss: 0.2806127071380615\n",
      "Epoch 2: train loss: 0.17255884408950806\n",
      "Epoch 2: train loss: 0.13458964228630066\n",
      "Epoch 2: train loss: 0.1410037875175476\n",
      "Epoch 2: train loss: 0.2543450593948364\n",
      "Epoch 2: train loss: 0.08016838878393173\n",
      "Epoch 2: train loss: 0.29239803552627563\n",
      "Epoch 2: train loss: 0.540371835231781\n",
      "Epoch 2: train loss: 0.05644049867987633\n",
      "Epoch 2: train loss: 0.5529062747955322\n",
      "Epoch 2: train loss: 0.28180259466171265\n",
      "Epoch 2: train loss: 0.17318522930145264\n",
      "Epoch 2: train loss: 0.1752956509590149\n",
      "Epoch 2: train loss: 0.02743787318468094\n",
      "Evaluations on training data\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " bad credit (0)      0.565     0.162     0.251      3093\n",
      "good credit (1)      0.943     0.991     0.966     43116\n",
      "\n",
      "       accuracy                          0.936     46209\n",
      "      macro avg      0.754     0.576     0.609     46209\n",
      "   weighted avg      0.918     0.936     0.918     46209\n",
      "\n",
      "Evaluations on testing data\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " bad credit (0)      0.605     0.168     0.263       773\n",
      "good credit (1)      0.943     0.992     0.967     10780\n",
      "\n",
      "       accuracy                          0.937     11553\n",
      "      macro avg      0.774     0.580     0.615     11553\n",
      "   weighted avg      0.921     0.937     0.920     11553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get a clf#\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(5)\n",
    "random_state = check_random_state(10)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "d = dataset\n",
    "torch_model = proplace.train_clf(d.X1_train, d.y1_train, d.X1_test, d.y1_test, 20, epochs=3, data_name=\"give_me_some_credit\", save_clf=False,\n",
    "                        load_clf=False)\n",
    "model = proplace.InnModel(dataset, torch_model, 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [01:22<00:00,  8.29s/it]\n",
      "100%|| 10/10 [00:40<00:00,  4.03s/it]\n"
     ]
    }
   ],
   "source": [
    "m2s = proplace.retrain_models(dataset, 20, 3) + proplace.retrain_models_leave_some_out(dataset, 20, 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare for exps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from exputils import *\n",
    "clf = model\n",
    "test_xs_vals, test_xs, test_xs_carla, utildataset, nodes = get_test_data(model, m2s, dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Baselines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56662it [23:33, 40.08it/s]\n"
     ]
    }
   ],
   "source": [
    "rnnce_ces, treer, X_class1_clf_robust = run_rnnce(d, clf, nodes, utildataset, 0.045, test_xs_vals)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [01:02,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "1.0 >>> validity\n",
      "1.0 >>> robustness - M2 validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [02:40,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.00529898026954905 >>> robustness - delta validity, avg bound\n",
      "0.05754727296614758 >>> l1 cost\n",
      "0.92 >>> percentage of inliers dataset class 1 points\n",
      "1.2366107807867035 >>> avg lof dataset class 1 points\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ours\n",
    "#rnnce_ces, treer, X_class1_clf_robust = run_rnnce(d, clf, nodes, utildataset, 0.045, test_xs_vals)\n",
    "proplace_ces = run_proplace(clf, nodes, utildataset, 0.045, treer, X_class1_clf_robust, test_xs_vals)\n",
    "proplace_scores = eval_ces(clf, m2s, proplace_ces, d, utildataset, test_xs_vals, 0.045)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "============================\n",
      "1.0 >>> validity\n",
      "0.8389999999999999 >>> robustness - M2 validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [02:37,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18 -0.14287575065669705 >>> robustness - delta validity, avg bound\n",
      "0.1481171087879949 >>> l1 cost\n",
      "0.02 >>> percentage of inliers dataset class 1 points\n",
      "2.8041599852762804 >>> avg lof dataset class 1 points\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wach_params = {\n",
    "            \"lr\": 0.1,\n",
    "            \"lambda_\": 0.001,\n",
    "            \"n_iter\": 100,\n",
    "            \"t_max_min\": 0.5,\n",
    "            \"norm\": 1,\n",
    "            \"clamp\": False,\n",
    "            \"loss_type\": \"MSE\",\n",
    "            \"y_target\": [1],\n",
    "            \"binary_cat_features\": False,\n",
    "        }\n",
    "wach_ces = run_wachter(copy.deepcopy(clf), copy.deepcopy(test_xs_carla), wach_params)\n",
    "wach_scores = eval_ces(clf, m2s, wach_ces, d, utildataset, test_xs_vals,  delta=0.045)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [05:39,  6.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "1.0 >>> validity\n",
      "0.9030000000000001 >>> robustness - M2 validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [02:38,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 -0.27059100796124036 >>> robustness - delta validity, avg bound\n",
      "0.04969111654362668 >>> l1 cost\n",
      "0.8 >>> percentage of inliers dataset class 1 points\n",
      "1.304884117171781 >>> avg lof dataset class 1 points\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rbr_ces = run_rbr(clf, d, random_state, test_xs_vals)\n",
    "rbr_scores = eval_ces(clf, m2s, rbr_ces, d, utildataset, test_xs_vals, 0.045)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56662it [01:08, 830.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53853, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:01, 45.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "1.0 >>> validity\n",
      "1.0 >>> robustness - M2 validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [02:48,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96 0.23101571633164536 >>> robustness - delta validity, avg bound\n",
      "0.07328271069198757 >>> l1 cost\n",
      "0.76 >>> percentage of inliers dataset class 1 points\n",
      "1.3500294402521293 >>> avg lof dataset class 1 points\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "robx_ces = run_robx(clf, d, test_xs_vals, tao=0.6)\n",
    "robx_scores = eval_ces(clf, m2s, robx_ces, d, utildataset, test_xs_vals, 0.045)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Start generating LIME coefficients [model.py get_counterfactuals]\n",
      "[INFO] Finished generating LIME coefficients [model.py get_counterfactuals]\n",
      "============================\n",
      "0.96 >>> validity\n",
      "0.9550000000000004 >>> robustness - M2 validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [02:41,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875 1.0550976057825483 >>> robustness - delta validity, avg bound\n",
      "0.18777945757417291 >>> l1 cost\n",
      "0.041666666666666664 >>> percentage of inliers dataset class 1 points\n",
      "4.220597524815384 >>> avg lof dataset class 1 points\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "roar_params = {\n",
    "        \"lr\": 0.1,\n",
    "        \"lambda_\": 0.08,\n",
    "        \"delta_max\": 0.2,\n",
    "        \"norm\": 1,\n",
    "        \"t_max_min\": 3,\n",
    "        \"loss_type\": \"MSE\",\n",
    "        \"y_target\": [1],\n",
    "        \"binary_cat_features\": False,\n",
    "        \"loss_threshold\": 1e-3,\n",
    "        \"discretize\": False,\n",
    "        \"sample\": False,\n",
    "        \"lime_seed\": 0,\n",
    "        \"seed\": 0,\n",
    "    }\n",
    "roar_ces = run_roar(clf, test_xs_carla, roar_params)\n",
    "roar_scores = eval_ces(clf, m2s, roar_ces, d, utildataset, test_xs_vals, delta=0.045)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] From D:\\Apps\\anaconda\\envs\\proplace\\lib\\site-packages\\alibi\\explainers\\cfproto.py:123: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      " [module_wrapper.py _tfmw_add_deprecation_warning]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:50, 50.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:42, 51.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:37, 52.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [03:30, 53.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [04:27, 54.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [05:22, 54.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [06:17, 54.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [07:11, 54.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [08:07, 55.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [09:01, 54.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [09:55, 54.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [10:49, 54.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [11:46, 55.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [12:40, 54.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [13:34, 54.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [14:28, 54.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [15:24, 54.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [16:20, 55.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [17:15, 55.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [18:09, 54.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [19:02, 54.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [19:56, 54.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [20:51, 54.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [21:45, 54.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [22:41, 54.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [23:38, 55.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [24:33, 55.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [25:29, 55.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [26:26, 56.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [27:22, 55.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [28:20, 56.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [29:15, 56.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [30:10, 55.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [31:05, 55.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [32:04, 56.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [33:00, 56.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [33:56, 56.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [34:53, 56.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [35:50, 56.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [36:47, 56.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [37:39, 55.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [38:30, 53.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [39:21, 53.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [40:12, 52.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [41:04, 52.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [41:57, 52.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [42:48, 52.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [43:40, 52.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [44:32, 51.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [45:25, 54.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "1.0 >>> validity\n",
      "1.0 >>> robustness - M2 validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [02:38,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.6436884312307138 >>> robustness - delta validity, avg bound\n",
      "0.06581595642719576 >>> l1 cost\n",
      "0.62 >>> percentage of inliers dataset class 1 points\n",
      "1.4865195067101893 >>> avg lof dataset class 1 points\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "protor_ces = run_proto_r(clf, d, utildataset, test_xs_vals, nodes, delta_target=0.045)\n",
    "protor_scores = eval_ces(clf, m2s, protor_ces, d, utildataset, test_xs_vals, 0.045)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [01:26,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "1.0 >>> validity\n",
      "1.0 >>> robustness - M2 validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [02:33,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.339208804254732 >>> robustness - delta validity, avg bound\n",
      "0.058646908382038815 >>> l1 cost\n",
      "0.18 >>> percentage of inliers dataset class 1 points\n",
      "2.0815658040120395 >>> avg lof dataset class 1 points\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "milpr_ces = run_milpr(clf, d, nodes, utildataset, 0.08, test_xs_vals)\n",
    "milpr_scores = eval_ces(clf, m2s, milpr_ces, d, utildataset, test_xs_vals, 0.045)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------------------+---------------+-------+-------------------+---------------+\n",
      "| name     |   validity |   delta validity |   M2 validity |    l1 |   %inlier class 1 |   lof class 1 |\n",
      "+==========+============+==================+===============+=======+===================+===============+\n",
      "| wach     |          1 |             0.18 |         0.839 | 0.148 |              0.02 |         2.804 |\n",
      "| rbr      |          1 |             0    |         0.903 | 0.05  |              0.8  |         1.305 |\n",
      "| robx     |          1 |             0.96 |         1     | 0.073 |              0.76 |         1.35  |\n",
      "| roar     |          1 |             0.82 |         0.998 | 0.226 |              0    |        12.203 |\n",
      "| proto-r  |          1 |             1    |         1     | 0.066 |              0.62 |         1.487 |\n",
      "| milp-r   |          1 |             1    |         1     | 0.059 |              0.18 |         2.082 |\n",
      "| proplace |          1 |             1    |         1     | 0.058 |              0.92 |         1.237 |\n",
      "+----------+------------+------------------+---------------+-------+-------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "# make table\n",
    "from tabulate import tabulate\n",
    "scores_names = [\"name\", \"validity\", \"delta validity\", \"M2 validity\", \"l1\", \"%inlier class 1\", \"lof class 1\"]\n",
    "scores_table = [scores_names,\n",
    "                np.concatenate((['wach'], np.round(wach_scores, 3))),\n",
    "                np.concatenate((['rbr'], np.round(rbr_scores, 3))),\n",
    "                np.concatenate((['robx'], np.round(robx_scores, 3))),\n",
    "                np.concatenate((['roar'], np.round(roar_scores, 3))),\n",
    "                np.concatenate((['proto-r'], np.round(protor_scores, 3))),\n",
    "                np.concatenate((['milp-r'], np.round(milpr_scores, 3))),\n",
    "                np.concatenate((['proplace'], np.round(proplace_scores, 3))), ]\n",
    "print(tabulate(scores_table, headers='firstrow', tablefmt='outline'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "--------+---------------+-------+-------------------+--------------"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

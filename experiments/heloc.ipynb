{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import check_random_state\n",
    "import pandas as pd\n",
    "from proplace.clfutils import HiddenPrints\n",
    "import proplace\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# load dataset utils\n",
    "dataset = proplace.InnDataSet(\"heloc\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Epoch 0: train loss: 0.6952842473983765\n",
      "Epoch 0: train loss: 0.7111822962760925\n",
      "Epoch 0: train loss: 0.6742647886276245\n",
      "Epoch 0: train loss: 0.7059459090232849\n",
      "Epoch 0: train loss: 0.6984533071517944\n",
      "Epoch 0: train loss: 0.6984993815422058\n",
      "Epoch 0: train loss: 0.7011096477508545\n",
      "Epoch 0: train loss: 0.6890342831611633\n",
      "Epoch 0: train loss: 0.6882796883583069\n",
      "Epoch 0: train loss: 0.6891630291938782\n",
      "Epoch 0: train loss: 0.6940578818321228\n",
      "Epoch 0: train loss: 0.678005576133728\n",
      "Epoch 0: train loss: 0.6832115650177002\n",
      "Epoch 0: train loss: 0.6769801378250122\n",
      "Epoch 0: train loss: 0.6658576130867004\n",
      "Epoch 0: train loss: 0.6678807139396667\n",
      "Epoch 0: train loss: 0.6722731590270996\n",
      "Epoch 0: train loss: 0.7068021893501282\n",
      "Epoch 0: train loss: 0.6696203947067261\n",
      "Epoch 0: train loss: 0.6686608195304871\n",
      "Epoch 0: train loss: 0.6788075566291809\n",
      "Epoch 0: train loss: 0.6146712899208069\n",
      "Epoch 0: train loss: 0.6419103741645813\n",
      "Epoch 0: train loss: 0.6744205355644226\n",
      "Epoch 0: train loss: 0.6410430073738098\n",
      "Epoch 0: train loss: 0.6290302872657776\n",
      "Epoch 0: train loss: 0.6496090888977051\n",
      "Epoch 0: train loss: 0.6165912747383118\n",
      "Epoch 0: train loss: 0.630676805973053\n",
      "Epoch 0: train loss: 0.633114755153656\n",
      "Epoch 0: train loss: 0.599589467048645\n",
      "Epoch 0: train loss: 0.6188265085220337\n",
      "Epoch 0: train loss: 0.6390817761421204\n",
      "Epoch 0: train loss: 0.5549045205116272\n",
      "Epoch 0: train loss: 0.7629426121711731\n",
      "Epoch 0: train loss: 0.5506364107131958\n",
      "Epoch 0: train loss: 0.6469914317131042\n",
      "Epoch 0: train loss: 0.6261048913002014\n",
      "Epoch 0: train loss: 0.5479289293289185\n",
      "Epoch 0: train loss: 0.5435146689414978\n",
      "Epoch 0: train loss: 0.53385990858078\n",
      "Epoch 0: train loss: 0.6338518261909485\n",
      "Epoch 0: train loss: 0.6526210904121399\n",
      "Epoch 0: train loss: 0.5617340803146362\n",
      "Epoch 0: train loss: 0.6481742262840271\n",
      "Epoch 0: train loss: 0.6408511400222778\n",
      "Epoch 0: train loss: 0.6037933826446533\n",
      "Epoch 0: train loss: 0.6073715686798096\n",
      "Epoch 0: train loss: 0.6208088397979736\n",
      "Epoch 0: train loss: 0.5208256840705872\n",
      "Epoch 0: train loss: 0.53163081407547\n",
      "Epoch 0: train loss: 0.45355963706970215\n",
      "Epoch 0: train loss: 0.4728299379348755\n",
      "Epoch 0: train loss: 0.5650166869163513\n",
      "Epoch 0: train loss: 0.5284090638160706\n",
      "Epoch 0: train loss: 0.5997450947761536\n",
      "Epoch 0: train loss: 0.4604308605194092\n",
      "Epoch 0: train loss: 0.5257861614227295\n",
      "Epoch 0: train loss: 0.6874836683273315\n",
      "Epoch 0: train loss: 0.4913979768753052\n",
      "Epoch 0: train loss: 0.7153031826019287\n",
      "Epoch 0: train loss: 0.5089221596717834\n",
      "Epoch 0: train loss: 0.6594175696372986\n",
      "Epoch 0: train loss: 0.6412582993507385\n",
      "Epoch 0: train loss: 0.5555790662765503\n",
      "Epoch 0: train loss: 0.6539537310600281\n",
      "Epoch 0: train loss: 0.7657533288002014\n",
      "Epoch 0: train loss: 0.5120577216148376\n",
      "Epoch 0: train loss: 0.43861937522888184\n",
      "Epoch 0: train loss: 0.577630877494812\n",
      "Epoch 0: train loss: 0.5502259731292725\n",
      "Epoch 0: train loss: 0.5657899379730225\n",
      "Epoch 0: train loss: 0.5796694755554199\n",
      "Epoch 0: train loss: 0.489602267742157\n",
      "Epoch 0: train loss: 0.5371024012565613\n",
      "Epoch 0: train loss: 0.6874344944953918\n",
      "Epoch 0: train loss: 0.6915283203125\n",
      "Epoch 0: train loss: 0.5043759942054749\n",
      "Epoch 0: train loss: 0.719346821308136\n",
      "Epoch 0: train loss: 0.597504198551178\n",
      "Epoch 0: train loss: 0.6258012652397156\n",
      "Epoch 0: train loss: 0.595864474773407\n",
      "Epoch 0: train loss: 0.5805397629737854\n",
      "Epoch 0: train loss: 0.7082598209381104\n",
      "Epoch 0: train loss: 0.6656540036201477\n",
      "Epoch 0: train loss: 0.5255968570709229\n",
      "Epoch 0: train loss: 0.576137363910675\n",
      "Epoch 0: train loss: 0.5419979095458984\n",
      "Epoch 0: train loss: 0.5061370134353638\n",
      "Epoch 0: train loss: 0.6435678601264954\n",
      "Epoch 0: train loss: 0.5430722832679749\n",
      "Epoch 0: train loss: 0.48332974314689636\n",
      "Epoch 0: train loss: 0.5011601448059082\n",
      "Epoch 0: train loss: 0.4320923686027527\n",
      "Epoch 0: train loss: 0.5842768549919128\n",
      "Epoch 0: train loss: 0.5824158191680908\n",
      "Epoch 0: train loss: 0.4581719636917114\n",
      "Epoch 0: train loss: 0.562102735042572\n",
      "Epoch 0: train loss: 0.5629255771636963\n",
      "Epoch 0: train loss: 0.5270581841468811\n",
      "Epoch 0: train loss: 0.6363523602485657\n",
      "Epoch 0: train loss: 0.4165914058685303\n",
      "Epoch 0: train loss: 0.5670608282089233\n",
      "Epoch 0: train loss: 0.44200146198272705\n",
      "Epoch 0: train loss: 0.5452563166618347\n",
      "Epoch 0: train loss: 0.5686620473861694\n",
      "Epoch 0: train loss: 0.4718989133834839\n",
      "Epoch 0: train loss: 0.4457054138183594\n",
      "Epoch 0: train loss: 0.4422253668308258\n",
      "Epoch 0: train loss: 0.4560725688934326\n",
      "Epoch 0: train loss: 0.6264898777008057\n",
      "Epoch 0: train loss: 0.7860748767852783\n",
      "Epoch 0: train loss: 0.2704204022884369\n",
      "Epoch 0: train loss: 0.6004868149757385\n",
      "Epoch 0: train loss: 0.5753089189529419\n",
      "Epoch 0: train loss: 0.41358283162117004\n",
      "Epoch 0: train loss: 0.8200397491455078\n",
      "Epoch 0: train loss: 0.6461290121078491\n",
      "Epoch 0: train loss: 0.5463026165962219\n",
      "Epoch 0: train loss: 0.46328720450401306\n",
      "Epoch 0: train loss: 0.5059143304824829\n",
      "Epoch 0: train loss: 0.45836496353149414\n",
      "Epoch 0: train loss: 0.6848145723342896\n",
      "Epoch 0: train loss: 0.48104599118232727\n",
      "Epoch 1: train loss: 0.5422298908233643\n",
      "Epoch 1: train loss: 0.4865044057369232\n",
      "Epoch 1: train loss: 0.545444130897522\n",
      "Epoch 1: train loss: 0.4999532401561737\n",
      "Epoch 1: train loss: 0.6203241944313049\n",
      "Epoch 1: train loss: 0.7053009867668152\n",
      "Epoch 1: train loss: 0.5944879055023193\n",
      "Epoch 1: train loss: 0.5758330225944519\n",
      "Epoch 1: train loss: 0.38390201330184937\n",
      "Epoch 1: train loss: 0.6361550688743591\n",
      "Epoch 1: train loss: 0.38547608256340027\n",
      "Epoch 1: train loss: 0.5886435508728027\n",
      "Epoch 1: train loss: 0.4551512598991394\n",
      "Epoch 1: train loss: 0.5492109060287476\n",
      "Epoch 1: train loss: 0.4818663001060486\n",
      "Epoch 1: train loss: 0.5841335654258728\n",
      "Epoch 1: train loss: 0.5820167660713196\n",
      "Epoch 1: train loss: 0.5643494129180908\n",
      "Epoch 1: train loss: 0.6492735743522644\n",
      "Epoch 1: train loss: 0.6061310768127441\n",
      "Epoch 1: train loss: 0.570870578289032\n",
      "Epoch 1: train loss: 0.6702796220779419\n",
      "Epoch 1: train loss: 0.5426955223083496\n",
      "Epoch 1: train loss: 0.46969547867774963\n",
      "Epoch 1: train loss: 0.7384401559829712\n",
      "Epoch 1: train loss: 0.5312328934669495\n",
      "Epoch 1: train loss: 0.6207094192504883\n",
      "Epoch 1: train loss: 0.5399422645568848\n",
      "Epoch 1: train loss: 0.6151860952377319\n",
      "Epoch 1: train loss: 0.552351713180542\n",
      "Epoch 1: train loss: 0.6745507121086121\n",
      "Epoch 1: train loss: 0.7640619277954102\n",
      "Epoch 1: train loss: 0.4726862609386444\n",
      "Epoch 1: train loss: 0.5056108832359314\n",
      "Epoch 1: train loss: 0.5018171668052673\n",
      "Epoch 1: train loss: 0.5242053866386414\n",
      "Epoch 1: train loss: 0.5453963279724121\n",
      "Epoch 1: train loss: 0.5513118505477905\n",
      "Epoch 1: train loss: 0.6159787774085999\n",
      "Epoch 1: train loss: 0.4556352198123932\n",
      "Epoch 1: train loss: 0.6058881878852844\n",
      "Epoch 1: train loss: 0.5466684699058533\n",
      "Epoch 1: train loss: 0.606316864490509\n",
      "Epoch 1: train loss: 0.6374386548995972\n",
      "Epoch 1: train loss: 0.6457396149635315\n",
      "Epoch 1: train loss: 0.5765262246131897\n",
      "Epoch 1: train loss: 0.43288886547088623\n",
      "Epoch 1: train loss: 0.6669352054595947\n",
      "Epoch 1: train loss: 0.4841810464859009\n",
      "Epoch 1: train loss: 0.5190825462341309\n",
      "Epoch 1: train loss: 0.5593776106834412\n",
      "Epoch 1: train loss: 0.5615204572677612\n",
      "Epoch 1: train loss: 0.47553551197052\n",
      "Epoch 1: train loss: 0.45922955870628357\n",
      "Epoch 1: train loss: 0.5934614539146423\n",
      "Epoch 1: train loss: 0.6289953589439392\n",
      "Epoch 1: train loss: 0.5174497961997986\n",
      "Epoch 1: train loss: 0.547210693359375\n",
      "Epoch 1: train loss: 0.47489941120147705\n",
      "Epoch 1: train loss: 0.4859488010406494\n",
      "Epoch 1: train loss: 0.4615078568458557\n",
      "Epoch 1: train loss: 0.7685476541519165\n",
      "Epoch 1: train loss: 0.5628615617752075\n",
      "Epoch 1: train loss: 0.5532057285308838\n",
      "Epoch 1: train loss: 0.6546143889427185\n",
      "Epoch 1: train loss: 0.44995927810668945\n",
      "Epoch 1: train loss: 0.6869693398475647\n",
      "Epoch 1: train loss: 0.6152167320251465\n",
      "Epoch 1: train loss: 0.5330600738525391\n",
      "Epoch 1: train loss: 0.606171727180481\n",
      "Epoch 1: train loss: 0.4752645194530487\n",
      "Epoch 1: train loss: 0.42940208315849304\n",
      "Epoch 1: train loss: 0.6551439166069031\n",
      "Epoch 1: train loss: 0.6524072885513306\n",
      "Epoch 1: train loss: 0.5999473333358765\n",
      "Epoch 1: train loss: 0.4544760584831238\n",
      "Epoch 1: train loss: 0.5402893424034119\n",
      "Epoch 1: train loss: 0.67718505859375\n",
      "Epoch 1: train loss: 0.6302362680435181\n",
      "Epoch 1: train loss: 0.527672529220581\n",
      "Epoch 1: train loss: 0.6156554222106934\n",
      "Epoch 1: train loss: 0.5897889137268066\n",
      "Epoch 1: train loss: 0.4762973189353943\n",
      "Epoch 1: train loss: 0.6686410903930664\n",
      "Epoch 1: train loss: 0.5491468906402588\n",
      "Epoch 1: train loss: 0.5299202799797058\n",
      "Epoch 1: train loss: 0.7596166133880615\n",
      "Epoch 1: train loss: 0.6002788543701172\n",
      "Epoch 1: train loss: 0.4821167588233948\n",
      "Epoch 1: train loss: 0.4572097957134247\n",
      "Epoch 1: train loss: 0.522510826587677\n",
      "Epoch 1: train loss: 0.6810159683227539\n",
      "Epoch 1: train loss: 0.5271955728530884\n",
      "Epoch 1: train loss: 0.7295438647270203\n",
      "Epoch 1: train loss: 0.5059935450553894\n",
      "Epoch 1: train loss: 0.5392443537712097\n",
      "Epoch 1: train loss: 0.5862165689468384\n",
      "Epoch 1: train loss: 0.53509521484375\n",
      "Epoch 1: train loss: 0.5390264391899109\n",
      "Epoch 1: train loss: 0.48557838797569275\n",
      "Epoch 1: train loss: 0.6523281335830688\n",
      "Epoch 1: train loss: 0.6398967504501343\n",
      "Epoch 1: train loss: 0.5640308260917664\n",
      "Epoch 1: train loss: 0.5473816394805908\n",
      "Epoch 1: train loss: 0.6740428805351257\n",
      "Epoch 1: train loss: 0.5293794274330139\n",
      "Epoch 1: train loss: 0.5871301293373108\n",
      "Epoch 1: train loss: 0.7553145885467529\n",
      "Epoch 1: train loss: 0.4679839015007019\n",
      "Epoch 1: train loss: 0.4847885072231293\n",
      "Epoch 1: train loss: 0.5431998372077942\n",
      "Epoch 1: train loss: 0.6092081665992737\n",
      "Epoch 1: train loss: 0.6045154333114624\n",
      "Epoch 1: train loss: 0.5523818731307983\n",
      "Epoch 1: train loss: 0.4917173981666565\n",
      "Epoch 1: train loss: 0.5824794173240662\n",
      "Epoch 1: train loss: 0.4989456832408905\n",
      "Epoch 1: train loss: 0.5761364102363586\n",
      "Epoch 1: train loss: 0.3818378448486328\n",
      "Epoch 1: train loss: 0.5450007319450378\n",
      "Epoch 1: train loss: 0.6665170192718506\n",
      "Epoch 1: train loss: 0.48401957750320435\n",
      "Epoch 1: train loss: 0.4642828404903412\n",
      "Epoch 1: train loss: 0.4273153245449066\n",
      "Epoch 2: train loss: 0.5306521058082581\n",
      "Epoch 2: train loss: 0.5930389165878296\n",
      "Epoch 2: train loss: 0.6792581081390381\n",
      "Epoch 2: train loss: 0.5589511394500732\n",
      "Epoch 2: train loss: 0.46573445200920105\n",
      "Epoch 2: train loss: 0.5190136432647705\n",
      "Epoch 2: train loss: 0.5462903380393982\n",
      "Epoch 2: train loss: 0.6628134846687317\n",
      "Epoch 2: train loss: 0.5005035400390625\n",
      "Epoch 2: train loss: 0.4390780031681061\n",
      "Epoch 2: train loss: 0.4833262264728546\n",
      "Epoch 2: train loss: 0.6381261348724365\n",
      "Epoch 2: train loss: 0.7858854532241821\n",
      "Epoch 2: train loss: 0.4517875015735626\n",
      "Epoch 2: train loss: 0.4687504470348358\n",
      "Epoch 2: train loss: 0.46095559000968933\n",
      "Epoch 2: train loss: 0.6078782677650452\n",
      "Epoch 2: train loss: 0.6477036476135254\n",
      "Epoch 2: train loss: 0.5624118447303772\n",
      "Epoch 2: train loss: 0.5322069525718689\n",
      "Epoch 2: train loss: 0.5338630676269531\n",
      "Epoch 2: train loss: 0.5329170227050781\n",
      "Epoch 2: train loss: 0.5627771019935608\n",
      "Epoch 2: train loss: 0.4933330714702606\n",
      "Epoch 2: train loss: 0.5602720975875854\n",
      "Epoch 2: train loss: 0.6489958763122559\n",
      "Epoch 2: train loss: 0.3786216974258423\n",
      "Epoch 2: train loss: 0.6529380083084106\n",
      "Epoch 2: train loss: 0.4597971439361572\n",
      "Epoch 2: train loss: 0.4728871285915375\n",
      "Epoch 2: train loss: 0.5401216745376587\n",
      "Epoch 2: train loss: 0.7917733192443848\n",
      "Epoch 2: train loss: 0.5427364110946655\n",
      "Epoch 2: train loss: 0.6130289435386658\n",
      "Epoch 2: train loss: 0.37854138016700745\n",
      "Epoch 2: train loss: 0.4905531108379364\n",
      "Epoch 2: train loss: 0.5441916584968567\n",
      "Epoch 2: train loss: 0.5126509666442871\n",
      "Epoch 2: train loss: 0.5146304368972778\n",
      "Epoch 2: train loss: 0.5647457838058472\n",
      "Epoch 2: train loss: 0.5864102244377136\n",
      "Epoch 2: train loss: 0.5766397714614868\n",
      "Epoch 2: train loss: 0.5790961980819702\n",
      "Epoch 2: train loss: 0.637217104434967\n",
      "Epoch 2: train loss: 0.5620782971382141\n",
      "Epoch 2: train loss: 0.5691933631896973\n",
      "Epoch 2: train loss: 0.5433999300003052\n",
      "Epoch 2: train loss: 0.5179506540298462\n",
      "Epoch 2: train loss: 0.5885528326034546\n",
      "Epoch 2: train loss: 0.6869319677352905\n",
      "Epoch 2: train loss: 0.6324377059936523\n",
      "Epoch 2: train loss: 0.582739531993866\n",
      "Epoch 2: train loss: 0.5202010869979858\n",
      "Epoch 2: train loss: 0.5727119445800781\n",
      "Epoch 2: train loss: 0.577164888381958\n",
      "Epoch 2: train loss: 0.530348002910614\n",
      "Epoch 2: train loss: 0.4659191370010376\n",
      "Epoch 2: train loss: 0.7335850596427917\n",
      "Epoch 2: train loss: 0.5489398837089539\n",
      "Epoch 2: train loss: 0.5576050877571106\n",
      "Epoch 2: train loss: 0.43314188718795776\n",
      "Epoch 2: train loss: 0.46416938304901123\n",
      "Epoch 2: train loss: 0.5849305391311646\n",
      "Epoch 2: train loss: 0.5682911276817322\n",
      "Epoch 2: train loss: 0.596362829208374\n",
      "Epoch 2: train loss: 0.6072155237197876\n",
      "Epoch 2: train loss: 0.5266833901405334\n",
      "Epoch 2: train loss: 0.44830843806266785\n",
      "Epoch 2: train loss: 0.5752242803573608\n",
      "Epoch 2: train loss: 0.6228266954421997\n",
      "Epoch 2: train loss: 0.7028678059577942\n",
      "Epoch 2: train loss: 0.47162383794784546\n",
      "Epoch 2: train loss: 0.5995373725891113\n",
      "Epoch 2: train loss: 0.6718997359275818\n",
      "Epoch 2: train loss: 0.7038418054580688\n",
      "Epoch 2: train loss: 0.5313853621482849\n",
      "Epoch 2: train loss: 0.5955840945243835\n",
      "Epoch 2: train loss: 0.45788681507110596\n",
      "Epoch 2: train loss: 0.657185971736908\n",
      "Epoch 2: train loss: 0.6547709703445435\n",
      "Epoch 2: train loss: 0.4721772074699402\n",
      "Epoch 2: train loss: 0.5542035102844238\n",
      "Epoch 2: train loss: 0.5796096920967102\n",
      "Epoch 2: train loss: 0.5669469237327576\n",
      "Epoch 2: train loss: 0.5478092432022095\n",
      "Epoch 2: train loss: 0.480712890625\n",
      "Epoch 2: train loss: 0.6039731502532959\n",
      "Epoch 2: train loss: 0.5724655389785767\n",
      "Epoch 2: train loss: 0.5120163559913635\n",
      "Epoch 2: train loss: 0.6627265810966492\n",
      "Epoch 2: train loss: 0.5180935263633728\n",
      "Epoch 2: train loss: 0.4437969923019409\n",
      "Epoch 2: train loss: 0.526025116443634\n",
      "Epoch 2: train loss: 0.6396254301071167\n",
      "Epoch 2: train loss: 0.4494895935058594\n",
      "Epoch 2: train loss: 0.5485973954200745\n",
      "Epoch 2: train loss: 0.635248064994812\n",
      "Epoch 2: train loss: 0.5030887126922607\n",
      "Epoch 2: train loss: 0.4491681158542633\n",
      "Epoch 2: train loss: 0.4993952214717865\n",
      "Epoch 2: train loss: 0.5280821323394775\n",
      "Epoch 2: train loss: 0.5205022096633911\n",
      "Epoch 2: train loss: 0.665078341960907\n",
      "Epoch 2: train loss: 0.7231669425964355\n",
      "Epoch 2: train loss: 0.36491575837135315\n",
      "Epoch 2: train loss: 0.5565319061279297\n",
      "Epoch 2: train loss: 0.7046213746070862\n",
      "Epoch 2: train loss: 0.5855167508125305\n",
      "Epoch 2: train loss: 0.5467439293861389\n",
      "Epoch 2: train loss: 0.5824531316757202\n",
      "Epoch 2: train loss: 0.49482086300849915\n",
      "Epoch 2: train loss: 0.4042210280895233\n",
      "Epoch 2: train loss: 0.44315019249916077\n",
      "Epoch 2: train loss: 0.43499407172203064\n",
      "Epoch 2: train loss: 0.6910994648933411\n",
      "Epoch 2: train loss: 0.5743734240531921\n",
      "Epoch 2: train loss: 0.5051918029785156\n",
      "Epoch 2: train loss: 0.7087421417236328\n",
      "Epoch 2: train loss: 0.48608067631721497\n",
      "Epoch 2: train loss: 0.4544399678707123\n",
      "Epoch 2: train loss: 0.5911808013916016\n",
      "Epoch 2: train loss: 0.5985561013221741\n",
      "Epoch 2: train loss: 0.6290147304534912\n",
      "Epoch 2: train loss: 0.3945673704147339\n",
      "Epoch 3: train loss: 0.6463674902915955\n",
      "Epoch 3: train loss: 0.6695908904075623\n",
      "Epoch 3: train loss: 0.6533629894256592\n",
      "Epoch 3: train loss: 0.5122793912887573\n",
      "Epoch 3: train loss: 0.5778001546859741\n",
      "Epoch 3: train loss: 0.49460914731025696\n",
      "Epoch 3: train loss: 0.584818959236145\n",
      "Epoch 3: train loss: 0.5113941431045532\n",
      "Epoch 3: train loss: 0.48316678404808044\n",
      "Epoch 3: train loss: 0.48616498708724976\n",
      "Epoch 3: train loss: 0.5422411561012268\n",
      "Epoch 3: train loss: 0.6434968709945679\n",
      "Epoch 3: train loss: 0.47529393434524536\n",
      "Epoch 3: train loss: 0.6167297959327698\n",
      "Epoch 3: train loss: 0.6826709508895874\n",
      "Epoch 3: train loss: 0.45922109484672546\n",
      "Epoch 3: train loss: 0.46991315484046936\n",
      "Epoch 3: train loss: 0.588440477848053\n",
      "Epoch 3: train loss: 0.48223498463630676\n",
      "Epoch 3: train loss: 0.5925866961479187\n",
      "Epoch 3: train loss: 0.4963727593421936\n",
      "Epoch 3: train loss: 0.47934219241142273\n",
      "Epoch 3: train loss: 0.4809110760688782\n",
      "Epoch 3: train loss: 0.5071606636047363\n",
      "Epoch 3: train loss: 0.772542417049408\n",
      "Epoch 3: train loss: 0.7708704471588135\n",
      "Epoch 3: train loss: 0.5777127146720886\n",
      "Epoch 3: train loss: 0.5668866038322449\n",
      "Epoch 3: train loss: 0.516692042350769\n",
      "Epoch 3: train loss: 0.6722432971000671\n",
      "Epoch 3: train loss: 0.4828447103500366\n",
      "Epoch 3: train loss: 0.5354307889938354\n",
      "Epoch 3: train loss: 0.4659065902233124\n",
      "Epoch 3: train loss: 0.5074284672737122\n",
      "Epoch 3: train loss: 0.596662163734436\n",
      "Epoch 3: train loss: 0.44264739751815796\n",
      "Epoch 3: train loss: 0.6546079516410828\n",
      "Epoch 3: train loss: 0.4812715947628021\n",
      "Epoch 3: train loss: 0.4653666019439697\n",
      "Epoch 3: train loss: 0.652008056640625\n",
      "Epoch 3: train loss: 0.4333442747592926\n",
      "Epoch 3: train loss: 0.45753243565559387\n",
      "Epoch 3: train loss: 0.4424862265586853\n",
      "Epoch 3: train loss: 0.8033333420753479\n",
      "Epoch 3: train loss: 0.5211951732635498\n",
      "Epoch 3: train loss: 0.5369461178779602\n",
      "Epoch 3: train loss: 0.5808407068252563\n",
      "Epoch 3: train loss: 0.519263505935669\n",
      "Epoch 3: train loss: 0.6057425737380981\n",
      "Epoch 3: train loss: 0.6101580262184143\n",
      "Epoch 3: train loss: 0.4223109185695648\n",
      "Epoch 3: train loss: 0.6749212145805359\n",
      "Epoch 3: train loss: 0.5174344778060913\n",
      "Epoch 3: train loss: 0.41667282581329346\n",
      "Epoch 3: train loss: 0.6191222667694092\n",
      "Epoch 3: train loss: 0.6816578507423401\n",
      "Epoch 3: train loss: 0.5385375618934631\n",
      "Epoch 3: train loss: 0.5942658185958862\n",
      "Epoch 3: train loss: 0.4139832556247711\n",
      "Epoch 3: train loss: 0.4408075511455536\n",
      "Epoch 3: train loss: 0.5219061374664307\n",
      "Epoch 3: train loss: 0.6294556260108948\n",
      "Epoch 3: train loss: 0.6066667437553406\n",
      "Epoch 3: train loss: 0.4927879273891449\n",
      "Epoch 3: train loss: 0.5432997345924377\n",
      "Epoch 3: train loss: 0.5842032432556152\n",
      "Epoch 3: train loss: 0.5103453993797302\n",
      "Epoch 3: train loss: 0.7016841173171997\n",
      "Epoch 3: train loss: 0.622645378112793\n",
      "Epoch 3: train loss: 0.5065000653266907\n",
      "Epoch 3: train loss: 0.4529215693473816\n",
      "Epoch 3: train loss: 0.4246477484703064\n",
      "Epoch 3: train loss: 0.45270249247550964\n",
      "Epoch 3: train loss: 0.4111979305744171\n",
      "Epoch 3: train loss: 0.638442873954773\n",
      "Epoch 3: train loss: 0.6274645924568176\n",
      "Epoch 3: train loss: 0.5687134861946106\n",
      "Epoch 3: train loss: 0.5900389552116394\n",
      "Epoch 3: train loss: 0.6211175918579102\n",
      "Epoch 3: train loss: 0.5376740097999573\n",
      "Epoch 3: train loss: 0.5575953722000122\n",
      "Epoch 3: train loss: 0.609732449054718\n",
      "Epoch 3: train loss: 0.47659286856651306\n",
      "Epoch 3: train loss: 0.45399850606918335\n",
      "Epoch 3: train loss: 0.5490289926528931\n",
      "Epoch 3: train loss: 0.545924723148346\n",
      "Epoch 3: train loss: 0.6448777318000793\n",
      "Epoch 3: train loss: 0.40639233589172363\n",
      "Epoch 3: train loss: 0.6288644075393677\n",
      "Epoch 3: train loss: 0.5941347479820251\n",
      "Epoch 3: train loss: 0.7496982216835022\n",
      "Epoch 3: train loss: 0.5202924609184265\n",
      "Epoch 3: train loss: 0.5824201107025146\n",
      "Epoch 3: train loss: 0.5205752849578857\n",
      "Epoch 3: train loss: 0.6344817280769348\n",
      "Epoch 3: train loss: 0.5104634165763855\n",
      "Epoch 3: train loss: 0.39939749240875244\n",
      "Epoch 3: train loss: 0.5138348937034607\n",
      "Epoch 3: train loss: 0.5227294564247131\n",
      "Epoch 3: train loss: 0.5460180044174194\n",
      "Epoch 3: train loss: 0.5825974941253662\n",
      "Epoch 3: train loss: 0.5551494359970093\n",
      "Epoch 3: train loss: 0.5758193731307983\n",
      "Epoch 3: train loss: 0.49337974190711975\n",
      "Epoch 3: train loss: 0.49065855145454407\n",
      "Epoch 3: train loss: 0.6256686449050903\n",
      "Epoch 3: train loss: 0.4569219946861267\n",
      "Epoch 3: train loss: 0.5024056434631348\n",
      "Epoch 3: train loss: 0.5396303534507751\n",
      "Epoch 3: train loss: 0.7050773501396179\n",
      "Epoch 3: train loss: 0.4914560317993164\n",
      "Epoch 3: train loss: 0.6002994775772095\n",
      "Epoch 3: train loss: 0.48082488775253296\n",
      "Epoch 3: train loss: 0.5227187871932983\n",
      "Epoch 3: train loss: 0.7827592492103577\n",
      "Epoch 3: train loss: 0.5784962177276611\n",
      "Epoch 3: train loss: 0.4465664327144623\n",
      "Epoch 3: train loss: 0.5074107646942139\n",
      "Epoch 3: train loss: 0.6703974008560181\n",
      "Epoch 3: train loss: 0.4968079924583435\n",
      "Epoch 3: train loss: 0.551956295967102\n",
      "Epoch 3: train loss: 0.48854130506515503\n",
      "Epoch 3: train loss: 0.7075507044792175\n",
      "Epoch 3: train loss: 0.5029934644699097\n",
      "Epoch 4: train loss: 0.7283198833465576\n",
      "Epoch 4: train loss: 0.5844308733940125\n",
      "Epoch 4: train loss: 0.5022947192192078\n",
      "Epoch 4: train loss: 0.5226258635520935\n",
      "Epoch 4: train loss: 0.545676052570343\n",
      "Epoch 4: train loss: 0.5985046625137329\n",
      "Epoch 4: train loss: 0.6632694005966187\n",
      "Epoch 4: train loss: 0.5540836453437805\n",
      "Epoch 4: train loss: 0.530779242515564\n",
      "Epoch 4: train loss: 0.6291168332099915\n",
      "Epoch 4: train loss: 0.5816324949264526\n",
      "Epoch 4: train loss: 0.4429006278514862\n",
      "Epoch 4: train loss: 0.454877644777298\n",
      "Epoch 4: train loss: 0.5010261535644531\n",
      "Epoch 4: train loss: 0.5195873379707336\n",
      "Epoch 4: train loss: 0.5618925094604492\n",
      "Epoch 4: train loss: 0.5858722925186157\n",
      "Epoch 4: train loss: 0.548007607460022\n",
      "Epoch 4: train loss: 0.6415939927101135\n",
      "Epoch 4: train loss: 0.42779040336608887\n",
      "Epoch 4: train loss: 0.5287863612174988\n",
      "Epoch 4: train loss: 0.4961724877357483\n",
      "Epoch 4: train loss: 0.5659022331237793\n",
      "Epoch 4: train loss: 0.6641077399253845\n",
      "Epoch 4: train loss: 0.4281207323074341\n",
      "Epoch 4: train loss: 0.41733723878860474\n",
      "Epoch 4: train loss: 0.7967972755432129\n",
      "Epoch 4: train loss: 0.5710904598236084\n",
      "Epoch 4: train loss: 0.5410023927688599\n",
      "Epoch 4: train loss: 0.6969294548034668\n",
      "Epoch 4: train loss: 0.5621118545532227\n",
      "Epoch 4: train loss: 0.5802589058876038\n",
      "Epoch 4: train loss: 0.3809184730052948\n",
      "Epoch 4: train loss: 0.5490697622299194\n",
      "Epoch 4: train loss: 0.477530837059021\n",
      "Epoch 4: train loss: 0.6269404292106628\n",
      "Epoch 4: train loss: 0.5115559697151184\n",
      "Epoch 4: train loss: 0.5007399320602417\n",
      "Epoch 4: train loss: 0.6817134022712708\n",
      "Epoch 4: train loss: 0.5974010229110718\n",
      "Epoch 4: train loss: 0.5206274390220642\n",
      "Epoch 4: train loss: 0.47062817215919495\n",
      "Epoch 4: train loss: 0.6042023301124573\n",
      "Epoch 4: train loss: 0.6205421686172485\n",
      "Epoch 4: train loss: 0.5189502239227295\n",
      "Epoch 4: train loss: 0.6623420715332031\n",
      "Epoch 4: train loss: 0.4499986469745636\n",
      "Epoch 4: train loss: 0.47570472955703735\n",
      "Epoch 4: train loss: 0.6022865176200867\n",
      "Epoch 4: train loss: 0.5640814304351807\n",
      "Epoch 4: train loss: 0.5627619028091431\n",
      "Epoch 4: train loss: 0.6414110064506531\n",
      "Epoch 4: train loss: 0.5556222796440125\n",
      "Epoch 4: train loss: 0.48455774784088135\n",
      "Epoch 4: train loss: 0.6735108494758606\n",
      "Epoch 4: train loss: 0.6012749671936035\n",
      "Epoch 4: train loss: 0.642424464225769\n",
      "Epoch 4: train loss: 0.589602530002594\n",
      "Epoch 4: train loss: 0.5200600624084473\n",
      "Epoch 4: train loss: 0.42641639709472656\n",
      "Epoch 4: train loss: 0.7608813643455505\n",
      "Epoch 4: train loss: 0.6097083687782288\n",
      "Epoch 4: train loss: 0.5434627532958984\n",
      "Epoch 4: train loss: 0.478082537651062\n",
      "Epoch 4: train loss: 0.6266650557518005\n",
      "Epoch 4: train loss: 0.6919881701469421\n",
      "Epoch 4: train loss: 0.7294000387191772\n",
      "Epoch 4: train loss: 0.4778355360031128\n",
      "Epoch 4: train loss: 0.49820780754089355\n",
      "Epoch 4: train loss: 0.5290859341621399\n",
      "Epoch 4: train loss: 0.6254304051399231\n",
      "Epoch 4: train loss: 0.574519157409668\n",
      "Epoch 4: train loss: 0.5802197456359863\n",
      "Epoch 4: train loss: 0.4551191031932831\n",
      "Epoch 4: train loss: 0.5492340922355652\n",
      "Epoch 4: train loss: 0.4598599672317505\n",
      "Epoch 4: train loss: 0.4848616421222687\n",
      "Epoch 4: train loss: 0.5345988273620605\n",
      "Epoch 4: train loss: 0.6714361310005188\n",
      "Epoch 4: train loss: 0.5581029057502747\n",
      "Epoch 4: train loss: 0.599902868270874\n",
      "Epoch 4: train loss: 0.40728121995925903\n",
      "Epoch 4: train loss: 0.5173393487930298\n",
      "Epoch 4: train loss: 0.5845659971237183\n",
      "Epoch 4: train loss: 0.5922025442123413\n",
      "Epoch 4: train loss: 0.5828571319580078\n",
      "Epoch 4: train loss: 0.4692654311656952\n",
      "Epoch 4: train loss: 0.5597882270812988\n",
      "Epoch 4: train loss: 0.6415295600891113\n",
      "Epoch 4: train loss: 0.46566256880760193\n",
      "Epoch 4: train loss: 0.5775184631347656\n",
      "Epoch 4: train loss: 0.4142509698867798\n",
      "Epoch 4: train loss: 0.5760188102722168\n",
      "Epoch 4: train loss: 0.5199041962623596\n",
      "Epoch 4: train loss: 0.6352961659431458\n",
      "Epoch 4: train loss: 0.7075116038322449\n",
      "Epoch 4: train loss: 0.596290111541748\n",
      "Epoch 4: train loss: 0.5074315667152405\n",
      "Epoch 4: train loss: 0.4551112949848175\n",
      "Epoch 4: train loss: 0.4164896309375763\n",
      "Epoch 4: train loss: 0.7882798314094543\n",
      "Epoch 4: train loss: 0.44562849402427673\n",
      "Epoch 4: train loss: 0.5665122270584106\n",
      "Epoch 4: train loss: 0.5024981498718262\n",
      "Epoch 4: train loss: 0.6359800100326538\n",
      "Epoch 4: train loss: 0.5057776570320129\n",
      "Epoch 4: train loss: 0.4504989683628082\n",
      "Epoch 4: train loss: 0.6108596324920654\n",
      "Epoch 4: train loss: 0.6724784970283508\n",
      "Epoch 4: train loss: 0.582835853099823\n",
      "Epoch 4: train loss: 0.514381468296051\n",
      "Epoch 4: train loss: 0.49044010043144226\n",
      "Epoch 4: train loss: 0.6018950939178467\n",
      "Epoch 4: train loss: 0.4944382607936859\n",
      "Epoch 4: train loss: 0.547585129737854\n",
      "Epoch 4: train loss: 0.5514940619468689\n",
      "Epoch 4: train loss: 0.582647979259491\n",
      "Epoch 4: train loss: 0.6924101710319519\n",
      "Epoch 4: train loss: 0.38023287057876587\n",
      "Epoch 4: train loss: 0.4526018798351288\n",
      "Epoch 4: train loss: 0.6691117286682129\n",
      "Epoch 4: train loss: 0.4799334704875946\n",
      "Epoch 4: train loss: 0.513190507888794\n",
      "Epoch 4: train loss: 0.7518411874771118\n",
      "Epoch 5: train loss: 0.6158068180084229\n",
      "Epoch 5: train loss: 0.5200701951980591\n",
      "Epoch 5: train loss: 0.5569711923599243\n",
      "Epoch 5: train loss: 0.533164381980896\n",
      "Epoch 5: train loss: 0.48274996876716614\n",
      "Epoch 5: train loss: 0.6854913234710693\n",
      "Epoch 5: train loss: 0.41040855646133423\n",
      "Epoch 5: train loss: 0.6231006979942322\n",
      "Epoch 5: train loss: 0.4512732923030853\n",
      "Epoch 5: train loss: 0.6312671303749084\n",
      "Epoch 5: train loss: 0.6028128266334534\n",
      "Epoch 5: train loss: 0.5939298272132874\n",
      "Epoch 5: train loss: 0.5341380834579468\n",
      "Epoch 5: train loss: 0.48919084668159485\n",
      "Epoch 5: train loss: 0.4720142185688019\n",
      "Epoch 5: train loss: 0.5366326570510864\n",
      "Epoch 5: train loss: 0.658577024936676\n",
      "Epoch 5: train loss: 0.5288643836975098\n",
      "Epoch 5: train loss: 0.5376655459403992\n",
      "Epoch 5: train loss: 0.5968385934829712\n",
      "Epoch 5: train loss: 0.6909889578819275\n",
      "Epoch 5: train loss: 0.5709515810012817\n",
      "Epoch 5: train loss: 0.46302878856658936\n",
      "Epoch 5: train loss: 0.5340622663497925\n",
      "Epoch 5: train loss: 0.544566810131073\n",
      "Epoch 5: train loss: 0.3651576638221741\n",
      "Epoch 5: train loss: 0.581204891204834\n",
      "Epoch 5: train loss: 0.4429696798324585\n",
      "Epoch 5: train loss: 0.6199837923049927\n",
      "Epoch 5: train loss: 0.41536572575569153\n",
      "Epoch 5: train loss: 0.6136265993118286\n",
      "Epoch 5: train loss: 0.6574985384941101\n",
      "Epoch 5: train loss: 0.5029425024986267\n",
      "Epoch 5: train loss: 0.6376491785049438\n",
      "Epoch 5: train loss: 0.5925955772399902\n",
      "Epoch 5: train loss: 0.5045144557952881\n",
      "Epoch 5: train loss: 0.6105153560638428\n",
      "Epoch 5: train loss: 0.5737743377685547\n",
      "Epoch 5: train loss: 0.5131900310516357\n",
      "Epoch 5: train loss: 0.7121942043304443\n",
      "Epoch 5: train loss: 0.5494160056114197\n",
      "Epoch 5: train loss: 0.579751193523407\n",
      "Epoch 5: train loss: 0.5451407432556152\n",
      "Epoch 5: train loss: 0.4850784242153168\n",
      "Epoch 5: train loss: 0.7291087508201599\n",
      "Epoch 5: train loss: 0.6016311049461365\n",
      "Epoch 5: train loss: 0.5067031979560852\n",
      "Epoch 5: train loss: 0.5593023896217346\n",
      "Epoch 5: train loss: 0.5814985036849976\n",
      "Epoch 5: train loss: 0.5352674722671509\n",
      "Epoch 5: train loss: 0.5794693827629089\n",
      "Epoch 5: train loss: 0.45732560753822327\n",
      "Epoch 5: train loss: 0.5602527260780334\n",
      "Epoch 5: train loss: 0.4511507451534271\n",
      "Epoch 5: train loss: 0.6203790903091431\n",
      "Epoch 5: train loss: 0.5869563817977905\n",
      "Epoch 5: train loss: 0.4766729176044464\n",
      "Epoch 5: train loss: 0.5457141995429993\n",
      "Epoch 5: train loss: 0.5010889172554016\n",
      "Epoch 5: train loss: 0.5513114333152771\n",
      "Epoch 5: train loss: 0.4538348913192749\n",
      "Epoch 5: train loss: 0.621565043926239\n",
      "Epoch 5: train loss: 0.5493091940879822\n",
      "Epoch 5: train loss: 0.5023211240768433\n",
      "Epoch 5: train loss: 0.6208477020263672\n",
      "Epoch 5: train loss: 0.5143811702728271\n",
      "Epoch 5: train loss: 0.6415160298347473\n",
      "Epoch 5: train loss: 0.5106176137924194\n",
      "Epoch 5: train loss: 0.6311254501342773\n",
      "Epoch 5: train loss: 0.5991162061691284\n",
      "Epoch 5: train loss: 0.5779618620872498\n",
      "Epoch 5: train loss: 0.4741213023662567\n",
      "Epoch 5: train loss: 0.4620688855648041\n",
      "Epoch 5: train loss: 0.5604051351547241\n",
      "Epoch 5: train loss: 0.5997178554534912\n",
      "Epoch 5: train loss: 0.6782484650611877\n",
      "Epoch 5: train loss: 0.5823421478271484\n",
      "Epoch 5: train loss: 0.6097428202629089\n",
      "Epoch 5: train loss: 0.6618058681488037\n",
      "Epoch 5: train loss: 0.45582306385040283\n",
      "Epoch 5: train loss: 0.5715224742889404\n",
      "Epoch 5: train loss: 0.6237306594848633\n",
      "Epoch 5: train loss: 0.547481894493103\n",
      "Epoch 5: train loss: 0.6661005616188049\n",
      "Epoch 5: train loss: 0.5953946709632874\n",
      "Epoch 5: train loss: 0.5653305053710938\n",
      "Epoch 5: train loss: 0.5820285081863403\n",
      "Epoch 5: train loss: 0.49223533272743225\n",
      "Epoch 5: train loss: 0.5194236636161804\n",
      "Epoch 5: train loss: 0.5932562351226807\n",
      "Epoch 5: train loss: 0.5205206871032715\n",
      "Epoch 5: train loss: 0.46145325899124146\n",
      "Epoch 5: train loss: 0.48436686396598816\n",
      "Epoch 5: train loss: 0.5081191658973694\n",
      "Epoch 5: train loss: 0.5024970769882202\n",
      "Epoch 5: train loss: 0.4987872838973999\n",
      "Epoch 5: train loss: 0.6006041765213013\n",
      "Epoch 5: train loss: 0.5686352849006653\n",
      "Epoch 5: train loss: 0.5573826432228088\n",
      "Epoch 5: train loss: 0.44455477595329285\n",
      "Epoch 5: train loss: 0.5708953738212585\n",
      "Epoch 5: train loss: 0.5923215746879578\n",
      "Epoch 5: train loss: 0.589105486869812\n",
      "Epoch 5: train loss: 0.5436246395111084\n",
      "Epoch 5: train loss: 0.6517022252082825\n",
      "Epoch 5: train loss: 0.6024051904678345\n",
      "Epoch 5: train loss: 0.5373690128326416\n",
      "Epoch 5: train loss: 0.4416336119174957\n",
      "Epoch 5: train loss: 0.5051044225692749\n",
      "Epoch 5: train loss: 0.5072647929191589\n",
      "Epoch 5: train loss: 0.5838526487350464\n",
      "Epoch 5: train loss: 0.6134362816810608\n",
      "Epoch 5: train loss: 0.516471266746521\n",
      "Epoch 5: train loss: 0.4657268822193146\n",
      "Epoch 5: train loss: 0.5847290754318237\n",
      "Epoch 5: train loss: 0.4969477355480194\n",
      "Epoch 5: train loss: 0.5452181696891785\n",
      "Epoch 5: train loss: 0.4984760880470276\n",
      "Epoch 5: train loss: 0.4648807644844055\n",
      "Epoch 5: train loss: 0.47652170062065125\n",
      "Epoch 5: train loss: 0.5356174111366272\n",
      "Epoch 5: train loss: 0.6545851230621338\n",
      "Epoch 5: train loss: 0.6391115784645081\n",
      "Epoch 5: train loss: 0.5966421961784363\n",
      "Epoch 6: train loss: 0.35284796357154846\n",
      "Epoch 6: train loss: 0.7264455556869507\n",
      "Epoch 6: train loss: 0.38211771845817566\n",
      "Epoch 6: train loss: 0.7339357733726501\n",
      "Epoch 6: train loss: 0.5562190413475037\n",
      "Epoch 6: train loss: 0.49080690741539\n",
      "Epoch 6: train loss: 0.48082780838012695\n",
      "Epoch 6: train loss: 0.626334547996521\n",
      "Epoch 6: train loss: 0.525000810623169\n",
      "Epoch 6: train loss: 0.5230686664581299\n",
      "Epoch 6: train loss: 0.5109959840774536\n",
      "Epoch 6: train loss: 0.6146016120910645\n",
      "Epoch 6: train loss: 0.5495103001594543\n",
      "Epoch 6: train loss: 0.441895991563797\n",
      "Epoch 6: train loss: 0.6139609217643738\n",
      "Epoch 6: train loss: 0.6647698879241943\n",
      "Epoch 6: train loss: 0.5181009769439697\n",
      "Epoch 6: train loss: 0.4273330569267273\n",
      "Epoch 6: train loss: 0.4920879602432251\n",
      "Epoch 6: train loss: 0.5861417651176453\n",
      "Epoch 6: train loss: 0.4778977632522583\n",
      "Epoch 6: train loss: 0.4746480882167816\n",
      "Epoch 6: train loss: 0.5266934633255005\n",
      "Epoch 6: train loss: 0.7087064981460571\n",
      "Epoch 6: train loss: 0.46589046716690063\n",
      "Epoch 6: train loss: 0.47482049465179443\n",
      "Epoch 6: train loss: 0.6205947995185852\n",
      "Epoch 6: train loss: 0.5254801511764526\n",
      "Epoch 6: train loss: 0.46962130069732666\n",
      "Epoch 6: train loss: 0.5276029706001282\n",
      "Epoch 6: train loss: 0.5329751372337341\n",
      "Epoch 6: train loss: 0.5069215297698975\n",
      "Epoch 6: train loss: 0.5265786647796631\n",
      "Epoch 6: train loss: 0.5939426422119141\n",
      "Epoch 6: train loss: 0.660851240158081\n",
      "Epoch 6: train loss: 0.6129581332206726\n",
      "Epoch 6: train loss: 0.6347306966781616\n",
      "Epoch 6: train loss: 0.5817531943321228\n",
      "Epoch 6: train loss: 0.4621042311191559\n",
      "Epoch 6: train loss: 0.6455984711647034\n",
      "Epoch 6: train loss: 0.40161922574043274\n",
      "Epoch 6: train loss: 0.49780750274658203\n",
      "Epoch 6: train loss: 0.46632546186447144\n",
      "Epoch 6: train loss: 0.5992002487182617\n",
      "Epoch 6: train loss: 0.5568321943283081\n",
      "Epoch 6: train loss: 0.575339138507843\n",
      "Epoch 6: train loss: 0.5019842982292175\n",
      "Epoch 6: train loss: 0.5360004305839539\n",
      "Epoch 6: train loss: 0.610716700553894\n",
      "Epoch 6: train loss: 0.5412358045578003\n",
      "Epoch 6: train loss: 0.4737991988658905\n",
      "Epoch 6: train loss: 0.5419335961341858\n",
      "Epoch 6: train loss: 0.6255683898925781\n",
      "Epoch 6: train loss: 0.6023692488670349\n",
      "Epoch 6: train loss: 0.5273930430412292\n",
      "Epoch 6: train loss: 0.49975910782814026\n",
      "Epoch 6: train loss: 0.4495873749256134\n",
      "Epoch 6: train loss: 0.5642741918563843\n",
      "Epoch 6: train loss: 0.48039183020591736\n",
      "Epoch 6: train loss: 0.48257943987846375\n",
      "Epoch 6: train loss: 0.5722450613975525\n",
      "Epoch 6: train loss: 0.6820712089538574\n",
      "Epoch 6: train loss: 0.4756906032562256\n",
      "Epoch 6: train loss: 0.5582836866378784\n",
      "Epoch 6: train loss: 0.546659529209137\n",
      "Epoch 6: train loss: 0.5408821702003479\n",
      "Epoch 6: train loss: 0.41700100898742676\n",
      "Epoch 6: train loss: 0.6079458594322205\n",
      "Epoch 6: train loss: 0.6220687627792358\n",
      "Epoch 6: train loss: 0.5151804685592651\n",
      "Epoch 6: train loss: 0.6440109610557556\n",
      "Epoch 6: train loss: 0.6169538497924805\n",
      "Epoch 6: train loss: 0.5510345697402954\n",
      "Epoch 6: train loss: 0.7023349404335022\n",
      "Epoch 6: train loss: 0.49540039896965027\n",
      "Epoch 6: train loss: 0.48618754744529724\n",
      "Epoch 6: train loss: 0.48468342423439026\n",
      "Epoch 6: train loss: 0.522596001625061\n",
      "Epoch 6: train loss: 0.6661382913589478\n",
      "Epoch 6: train loss: 0.5033567547798157\n",
      "Epoch 6: train loss: 0.5385382771492004\n",
      "Epoch 6: train loss: 0.4239708185195923\n",
      "Epoch 6: train loss: 0.5056286454200745\n",
      "Epoch 6: train loss: 0.41346070170402527\n",
      "Epoch 6: train loss: 0.40495672821998596\n",
      "Epoch 6: train loss: 0.48287323117256165\n",
      "Epoch 6: train loss: 0.5020116567611694\n",
      "Epoch 6: train loss: 0.5311234593391418\n",
      "Epoch 6: train loss: 0.53807133436203\n",
      "Epoch 6: train loss: 0.5900004506111145\n",
      "Epoch 6: train loss: 0.6069813966751099\n",
      "Epoch 6: train loss: 0.6156598329544067\n",
      "Epoch 6: train loss: 0.5532287955284119\n",
      "Epoch 6: train loss: 0.6404240727424622\n",
      "Epoch 6: train loss: 0.6664318442344666\n",
      "Epoch 6: train loss: 0.7283198237419128\n",
      "Epoch 6: train loss: 0.5385883450508118\n",
      "Epoch 6: train loss: 0.5864843130111694\n",
      "Epoch 6: train loss: 0.578027069568634\n",
      "Epoch 6: train loss: 0.6450088024139404\n",
      "Epoch 6: train loss: 0.5774664878845215\n",
      "Epoch 6: train loss: 0.6963756680488586\n",
      "Epoch 6: train loss: 0.4962043762207031\n",
      "Epoch 6: train loss: 0.4404946267604828\n",
      "Epoch 6: train loss: 0.6859726905822754\n",
      "Epoch 6: train loss: 0.651639997959137\n",
      "Epoch 6: train loss: 0.6176674365997314\n",
      "Epoch 6: train loss: 0.5716354846954346\n",
      "Epoch 6: train loss: 0.6840516924858093\n",
      "Epoch 6: train loss: 0.4813133478164673\n",
      "Epoch 6: train loss: 0.6064381003379822\n",
      "Epoch 6: train loss: 0.5953331589698792\n",
      "Epoch 6: train loss: 0.4729873836040497\n",
      "Epoch 6: train loss: 0.4951387345790863\n",
      "Epoch 6: train loss: 0.6253303289413452\n",
      "Epoch 6: train loss: 0.5612744092941284\n",
      "Epoch 6: train loss: 0.4577137529850006\n",
      "Epoch 6: train loss: 0.48279353976249695\n",
      "Epoch 6: train loss: 0.49648550152778625\n",
      "Epoch 6: train loss: 0.6113048791885376\n",
      "Epoch 6: train loss: 0.5394803285598755\n",
      "Epoch 6: train loss: 0.6082313060760498\n",
      "Epoch 6: train loss: 0.5134809613227844\n",
      "Epoch 6: train loss: 0.5092016458511353\n",
      "Epoch 7: train loss: 0.570037305355072\n",
      "Epoch 7: train loss: 0.5411649346351624\n",
      "Epoch 7: train loss: 0.4780867099761963\n",
      "Epoch 7: train loss: 0.5487578511238098\n",
      "Epoch 7: train loss: 0.6356319785118103\n",
      "Epoch 7: train loss: 0.544330358505249\n",
      "Epoch 7: train loss: 0.5251901149749756\n",
      "Epoch 7: train loss: 0.5817776322364807\n",
      "Epoch 7: train loss: 0.5682640075683594\n",
      "Epoch 7: train loss: 0.5759972333908081\n",
      "Epoch 7: train loss: 0.5722460150718689\n",
      "Epoch 7: train loss: 0.5749550461769104\n",
      "Epoch 7: train loss: 0.5587172508239746\n",
      "Epoch 7: train loss: 0.646492600440979\n",
      "Epoch 7: train loss: 0.5912705063819885\n",
      "Epoch 7: train loss: 0.7024754881858826\n",
      "Epoch 7: train loss: 0.4365203082561493\n",
      "Epoch 7: train loss: 0.44027823209762573\n",
      "Epoch 7: train loss: 0.57358318567276\n",
      "Epoch 7: train loss: 0.4039067327976227\n",
      "Epoch 7: train loss: 0.49377328157424927\n",
      "Epoch 7: train loss: 0.6295821070671082\n",
      "Epoch 7: train loss: 0.5917459726333618\n",
      "Epoch 7: train loss: 0.7729605436325073\n",
      "Epoch 7: train loss: 0.4902162253856659\n",
      "Epoch 7: train loss: 0.4415460228919983\n",
      "Epoch 7: train loss: 0.5626884698867798\n",
      "Epoch 7: train loss: 0.5295325517654419\n",
      "Epoch 7: train loss: 0.4958779513835907\n",
      "Epoch 7: train loss: 0.644103467464447\n",
      "Epoch 7: train loss: 0.5480502843856812\n",
      "Epoch 7: train loss: 0.4331086575984955\n",
      "Epoch 7: train loss: 0.5482840538024902\n",
      "Epoch 7: train loss: 0.6051719188690186\n",
      "Epoch 7: train loss: 0.42456504702568054\n",
      "Epoch 7: train loss: 0.5620230436325073\n",
      "Epoch 7: train loss: 0.45341262221336365\n",
      "Epoch 7: train loss: 0.5745444893836975\n",
      "Epoch 7: train loss: 0.653491199016571\n",
      "Epoch 7: train loss: 0.5561413764953613\n",
      "Epoch 7: train loss: 0.5616452097892761\n",
      "Epoch 7: train loss: 0.5695520639419556\n",
      "Epoch 7: train loss: 0.6315556168556213\n",
      "Epoch 7: train loss: 0.5881760716438293\n",
      "Epoch 7: train loss: 0.6087079644203186\n",
      "Epoch 7: train loss: 0.3918335735797882\n",
      "Epoch 7: train loss: 0.5251374840736389\n",
      "Epoch 7: train loss: 0.502994954586029\n",
      "Epoch 7: train loss: 0.5774823427200317\n",
      "Epoch 7: train loss: 0.4091610312461853\n",
      "Epoch 7: train loss: 0.5570472478866577\n",
      "Epoch 7: train loss: 0.41166913509368896\n",
      "Epoch 7: train loss: 0.5344908833503723\n",
      "Epoch 7: train loss: 0.46857312321662903\n",
      "Epoch 7: train loss: 0.6544975638389587\n",
      "Epoch 7: train loss: 0.5388548374176025\n",
      "Epoch 7: train loss: 0.44520169496536255\n",
      "Epoch 7: train loss: 0.4081151485443115\n",
      "Epoch 7: train loss: 0.7355841994285583\n",
      "Epoch 7: train loss: 0.545181393623352\n",
      "Epoch 7: train loss: 0.6432619094848633\n",
      "Epoch 7: train loss: 0.5272569060325623\n",
      "Epoch 7: train loss: 0.5920981764793396\n",
      "Epoch 7: train loss: 0.5674675703048706\n",
      "Epoch 7: train loss: 0.7275353670120239\n",
      "Epoch 7: train loss: 0.6425987482070923\n",
      "Epoch 7: train loss: 0.5928221940994263\n",
      "Epoch 7: train loss: 0.5799850225448608\n",
      "Epoch 7: train loss: 0.5038551092147827\n",
      "Epoch 7: train loss: 0.5313459038734436\n",
      "Epoch 7: train loss: 0.6718582510948181\n",
      "Epoch 7: train loss: 0.5643503665924072\n",
      "Epoch 7: train loss: 0.5329955220222473\n",
      "Epoch 7: train loss: 0.5331645607948303\n",
      "Epoch 7: train loss: 0.49497294425964355\n",
      "Epoch 7: train loss: 0.4848107099533081\n",
      "Epoch 7: train loss: 0.6094332337379456\n",
      "Epoch 7: train loss: 0.5826055407524109\n",
      "Epoch 7: train loss: 0.405186265707016\n",
      "Epoch 7: train loss: 0.49414801597595215\n",
      "Epoch 7: train loss: 0.5646083354949951\n",
      "Epoch 7: train loss: 0.48882073163986206\n",
      "Epoch 7: train loss: 0.43040743470191956\n",
      "Epoch 7: train loss: 0.45612573623657227\n",
      "Epoch 7: train loss: 0.5593056678771973\n",
      "Epoch 7: train loss: 0.5835065841674805\n",
      "Epoch 7: train loss: 0.5093476176261902\n",
      "Epoch 7: train loss: 0.5146310329437256\n",
      "Epoch 7: train loss: 0.6891106367111206\n",
      "Epoch 7: train loss: 0.5577920079231262\n",
      "Epoch 7: train loss: 0.6631777882575989\n",
      "Epoch 7: train loss: 0.5122230052947998\n",
      "Epoch 7: train loss: 0.5100888609886169\n",
      "Epoch 7: train loss: 0.5539697408676147\n",
      "Epoch 7: train loss: 0.5786665678024292\n",
      "Epoch 7: train loss: 0.6348150968551636\n",
      "Epoch 7: train loss: 0.5821852087974548\n",
      "Epoch 7: train loss: 0.4710102081298828\n",
      "Epoch 7: train loss: 0.5708733201026917\n",
      "Epoch 7: train loss: 0.774722695350647\n",
      "Epoch 7: train loss: 0.4968685805797577\n",
      "Epoch 7: train loss: 0.46010419726371765\n",
      "Epoch 7: train loss: 0.706226646900177\n",
      "Epoch 7: train loss: 0.583591103553772\n",
      "Epoch 7: train loss: 0.5500258803367615\n",
      "Epoch 7: train loss: 0.5865092873573303\n",
      "Epoch 7: train loss: 0.6287385821342468\n",
      "Epoch 7: train loss: 0.4343811273574829\n",
      "Epoch 7: train loss: 0.5345394015312195\n",
      "Epoch 7: train loss: 0.6503077745437622\n",
      "Epoch 7: train loss: 0.5910214781761169\n",
      "Epoch 7: train loss: 0.47963666915893555\n",
      "Epoch 7: train loss: 0.4720872938632965\n",
      "Epoch 7: train loss: 0.42991968989372253\n",
      "Epoch 7: train loss: 0.47207409143447876\n",
      "Epoch 7: train loss: 0.6070789694786072\n",
      "Epoch 7: train loss: 0.5617692470550537\n",
      "Epoch 7: train loss: 0.42757657170295715\n",
      "Epoch 7: train loss: 0.4506946802139282\n",
      "Epoch 7: train loss: 0.4851336181163788\n",
      "Epoch 7: train loss: 0.5030786991119385\n",
      "Epoch 7: train loss: 0.6728193163871765\n",
      "Epoch 7: train loss: 0.5357591509819031\n",
      "Epoch 7: train loss: 0.8400478959083557\n",
      "Epoch 8: train loss: 0.4782159924507141\n",
      "Epoch 8: train loss: 0.62495356798172\n",
      "Epoch 8: train loss: 0.611462414264679\n",
      "Epoch 8: train loss: 0.5067917108535767\n",
      "Epoch 8: train loss: 0.47379791736602783\n",
      "Epoch 8: train loss: 0.6753275394439697\n",
      "Epoch 8: train loss: 0.5167133808135986\n",
      "Epoch 8: train loss: 0.5954923033714294\n",
      "Epoch 8: train loss: 0.6160792708396912\n",
      "Epoch 8: train loss: 0.40880951285362244\n",
      "Epoch 8: train loss: 0.542259931564331\n",
      "Epoch 8: train loss: 0.37423470616340637\n",
      "Epoch 8: train loss: 0.5424559116363525\n",
      "Epoch 8: train loss: 0.5436061024665833\n",
      "Epoch 8: train loss: 0.5264912843704224\n",
      "Epoch 8: train loss: 0.5845988392829895\n",
      "Epoch 8: train loss: 0.548085629940033\n",
      "Epoch 8: train loss: 0.47730475664138794\n",
      "Epoch 8: train loss: 0.6812649965286255\n",
      "Epoch 8: train loss: 0.3807407021522522\n",
      "Epoch 8: train loss: 0.4991735816001892\n",
      "Epoch 8: train loss: 0.5475746393203735\n",
      "Epoch 8: train loss: 0.7043487429618835\n",
      "Epoch 8: train loss: 0.4077844023704529\n",
      "Epoch 8: train loss: 0.6613593697547913\n",
      "Epoch 8: train loss: 0.6251772046089172\n",
      "Epoch 8: train loss: 0.5861409902572632\n",
      "Epoch 8: train loss: 0.5383058786392212\n",
      "Epoch 8: train loss: 0.5311347842216492\n",
      "Epoch 8: train loss: 0.46125808358192444\n",
      "Epoch 8: train loss: 0.6032723784446716\n",
      "Epoch 8: train loss: 0.5620443820953369\n",
      "Epoch 8: train loss: 0.5915889739990234\n",
      "Epoch 8: train loss: 0.5809749960899353\n",
      "Epoch 8: train loss: 0.5310361981391907\n",
      "Epoch 8: train loss: 0.7409783601760864\n",
      "Epoch 8: train loss: 0.5559107661247253\n",
      "Epoch 8: train loss: 0.6061862707138062\n",
      "Epoch 8: train loss: 0.41509267687797546\n",
      "Epoch 8: train loss: 0.7211782932281494\n",
      "Epoch 8: train loss: 0.5419433116912842\n",
      "Epoch 8: train loss: 0.4945071339607239\n",
      "Epoch 8: train loss: 0.505754828453064\n",
      "Epoch 8: train loss: 0.5488301515579224\n",
      "Epoch 8: train loss: 0.4878765046596527\n",
      "Epoch 8: train loss: 0.545220136642456\n",
      "Epoch 8: train loss: 0.722221851348877\n",
      "Epoch 8: train loss: 0.6466312408447266\n",
      "Epoch 8: train loss: 0.42280280590057373\n",
      "Epoch 8: train loss: 0.4274982511997223\n",
      "Epoch 8: train loss: 0.489551305770874\n",
      "Epoch 8: train loss: 0.5038168430328369\n",
      "Epoch 8: train loss: 0.5926693081855774\n",
      "Epoch 8: train loss: 0.57865971326828\n",
      "Epoch 8: train loss: 0.5076801776885986\n",
      "Epoch 8: train loss: 0.6024842858314514\n",
      "Epoch 8: train loss: 0.6059337258338928\n",
      "Epoch 8: train loss: 0.6217600703239441\n",
      "Epoch 8: train loss: 0.6149260997772217\n",
      "Epoch 8: train loss: 0.5095680952072144\n",
      "Epoch 8: train loss: 0.4997327923774719\n",
      "Epoch 8: train loss: 0.6054103374481201\n",
      "Epoch 8: train loss: 0.5980086326599121\n",
      "Epoch 8: train loss: 0.6456514596939087\n",
      "Epoch 8: train loss: 0.5329434275627136\n",
      "Epoch 8: train loss: 0.5028801560401917\n",
      "Epoch 8: train loss: 0.598645806312561\n",
      "Epoch 8: train loss: 0.5150022506713867\n",
      "Epoch 8: train loss: 0.4592542052268982\n",
      "Epoch 8: train loss: 0.5380919575691223\n",
      "Epoch 8: train loss: 0.45676201581954956\n",
      "Epoch 8: train loss: 0.588510274887085\n",
      "Epoch 8: train loss: 0.6030082702636719\n",
      "Epoch 8: train loss: 0.49120646715164185\n",
      "Epoch 8: train loss: 0.515256941318512\n",
      "Epoch 8: train loss: 0.5581912994384766\n",
      "Epoch 8: train loss: 0.5977752208709717\n",
      "Epoch 8: train loss: 0.5549582839012146\n",
      "Epoch 8: train loss: 0.5236278772354126\n",
      "Epoch 8: train loss: 0.7017800807952881\n",
      "Epoch 8: train loss: 0.5277009010314941\n",
      "Epoch 8: train loss: 0.7060491442680359\n",
      "Epoch 8: train loss: 0.6354221105575562\n",
      "Epoch 8: train loss: 0.6204624772071838\n",
      "Epoch 8: train loss: 0.6159434914588928\n",
      "Epoch 8: train loss: 0.5449255704879761\n",
      "Epoch 8: train loss: 0.45909902453422546\n",
      "Epoch 8: train loss: 0.48375269770622253\n",
      "Epoch 8: train loss: 0.6168974041938782\n",
      "Epoch 8: train loss: 0.457823246717453\n",
      "Epoch 8: train loss: 0.5120163559913635\n",
      "Epoch 8: train loss: 0.5789611339569092\n",
      "Epoch 8: train loss: 0.5349848866462708\n",
      "Epoch 8: train loss: 0.597253680229187\n",
      "Epoch 8: train loss: 0.5779494643211365\n",
      "Epoch 8: train loss: 0.44265395402908325\n",
      "Epoch 8: train loss: 0.4571121633052826\n",
      "Epoch 8: train loss: 0.5673726797103882\n",
      "Epoch 8: train loss: 0.5900081396102905\n",
      "Epoch 8: train loss: 0.39151430130004883\n",
      "Epoch 8: train loss: 0.6105896234512329\n",
      "Epoch 8: train loss: 0.36371487379074097\n",
      "Epoch 8: train loss: 0.6671308875083923\n",
      "Epoch 8: train loss: 0.5057774186134338\n",
      "Epoch 8: train loss: 0.5769845247268677\n",
      "Epoch 8: train loss: 0.5802025198936462\n",
      "Epoch 8: train loss: 0.42919573187828064\n",
      "Epoch 8: train loss: 0.6722555756568909\n",
      "Epoch 8: train loss: 0.48296841979026794\n",
      "Epoch 8: train loss: 0.6125761866569519\n",
      "Epoch 8: train loss: 0.764758825302124\n",
      "Epoch 8: train loss: 0.3468591272830963\n",
      "Epoch 8: train loss: 0.47283437848091125\n",
      "Epoch 8: train loss: 0.5474852919578552\n",
      "Epoch 8: train loss: 0.48343193531036377\n",
      "Epoch 8: train loss: 0.6330053210258484\n",
      "Epoch 8: train loss: 0.4174933135509491\n",
      "Epoch 8: train loss: 0.4925973117351532\n",
      "Epoch 8: train loss: 0.3430679142475128\n",
      "Epoch 8: train loss: 0.3566760718822479\n",
      "Epoch 8: train loss: 0.5860000252723694\n",
      "Epoch 8: train loss: 0.4551502466201782\n",
      "Epoch 8: train loss: 0.4342358410358429\n",
      "Epoch 8: train loss: 0.34085923433303833\n",
      "Epoch 9: train loss: 0.433622270822525\n",
      "Epoch 9: train loss: 0.5308830142021179\n",
      "Epoch 9: train loss: 0.5995391011238098\n",
      "Epoch 9: train loss: 0.581087052822113\n",
      "Epoch 9: train loss: 0.5054469108581543\n",
      "Epoch 9: train loss: 0.5521014332771301\n",
      "Epoch 9: train loss: 0.442096084356308\n",
      "Epoch 9: train loss: 0.613955020904541\n",
      "Epoch 9: train loss: 0.7236038446426392\n",
      "Epoch 9: train loss: 0.3969718813896179\n",
      "Epoch 9: train loss: 0.5740635395050049\n",
      "Epoch 9: train loss: 0.6676192283630371\n",
      "Epoch 9: train loss: 0.5721103549003601\n",
      "Epoch 9: train loss: 0.5030524134635925\n",
      "Epoch 9: train loss: 0.5290197730064392\n",
      "Epoch 9: train loss: 0.5734508633613586\n",
      "Epoch 9: train loss: 0.5225450396537781\n",
      "Epoch 9: train loss: 0.5539941787719727\n",
      "Epoch 9: train loss: 0.6193061470985413\n",
      "Epoch 9: train loss: 0.45709970593452454\n",
      "Epoch 9: train loss: 0.6444833874702454\n",
      "Epoch 9: train loss: 0.5833411812782288\n",
      "Epoch 9: train loss: 0.5433835983276367\n",
      "Epoch 9: train loss: 0.5614776611328125\n",
      "Epoch 9: train loss: 0.5112047791481018\n",
      "Epoch 9: train loss: 0.578703761100769\n",
      "Epoch 9: train loss: 0.5494749546051025\n",
      "Epoch 9: train loss: 0.48933008313179016\n",
      "Epoch 9: train loss: 0.4524889886379242\n",
      "Epoch 9: train loss: 0.5667327046394348\n",
      "Epoch 9: train loss: 0.5174293518066406\n",
      "Epoch 9: train loss: 0.5185220241546631\n",
      "Epoch 9: train loss: 0.5068938732147217\n",
      "Epoch 9: train loss: 0.5761851668357849\n",
      "Epoch 9: train loss: 0.7086082696914673\n",
      "Epoch 9: train loss: 0.5229228138923645\n",
      "Epoch 9: train loss: 0.5534221529960632\n",
      "Epoch 9: train loss: 0.6796265840530396\n",
      "Epoch 9: train loss: 0.4532949924468994\n",
      "Epoch 9: train loss: 0.7590368390083313\n",
      "Epoch 9: train loss: 0.49819737672805786\n",
      "Epoch 9: train loss: 0.5359677672386169\n",
      "Epoch 9: train loss: 0.6032182574272156\n",
      "Epoch 9: train loss: 0.38278427720069885\n",
      "Epoch 9: train loss: 0.5370660424232483\n",
      "Epoch 9: train loss: 0.469615638256073\n",
      "Epoch 9: train loss: 0.5057923793792725\n",
      "Epoch 9: train loss: 0.4333231449127197\n",
      "Epoch 9: train loss: 0.5045443773269653\n",
      "Epoch 9: train loss: 0.5645810961723328\n",
      "Epoch 9: train loss: 0.6119015216827393\n",
      "Epoch 9: train loss: 0.47826725244522095\n",
      "Epoch 9: train loss: 0.4855232834815979\n",
      "Epoch 9: train loss: 0.4142170250415802\n",
      "Epoch 9: train loss: 0.6313080787658691\n",
      "Epoch 9: train loss: 0.5821120142936707\n",
      "Epoch 9: train loss: 0.572815477848053\n",
      "Epoch 9: train loss: 0.5536575317382812\n",
      "Epoch 9: train loss: 0.5447708964347839\n",
      "Epoch 9: train loss: 0.45362696051597595\n",
      "Epoch 9: train loss: 0.5542845726013184\n",
      "Epoch 9: train loss: 0.46358969807624817\n",
      "Epoch 9: train loss: 0.5247704386711121\n",
      "Epoch 9: train loss: 0.6395419239997864\n",
      "Epoch 9: train loss: 0.5353494882583618\n",
      "Epoch 9: train loss: 0.5950143933296204\n",
      "Epoch 9: train loss: 0.45441094040870667\n",
      "Epoch 9: train loss: 0.6013359427452087\n",
      "Epoch 9: train loss: 0.4020073711872101\n",
      "Epoch 9: train loss: 0.5574251413345337\n",
      "Epoch 9: train loss: 0.4618545472621918\n",
      "Epoch 9: train loss: 0.5432463884353638\n",
      "Epoch 9: train loss: 0.6353455781936646\n",
      "Epoch 9: train loss: 0.5785829424858093\n",
      "Epoch 9: train loss: 0.6179451942443848\n",
      "Epoch 9: train loss: 0.597709059715271\n",
      "Epoch 9: train loss: 0.7181628346443176\n",
      "Epoch 9: train loss: 0.6420149207115173\n",
      "Epoch 9: train loss: 0.55148845911026\n",
      "Epoch 9: train loss: 0.4627839922904968\n",
      "Epoch 9: train loss: 0.4225409924983978\n",
      "Epoch 9: train loss: 0.5225452780723572\n",
      "Epoch 9: train loss: 0.3710724711418152\n",
      "Epoch 9: train loss: 0.5033915042877197\n",
      "Epoch 9: train loss: 0.49838611483573914\n",
      "Epoch 9: train loss: 0.590297520160675\n",
      "Epoch 9: train loss: 0.5545755624771118\n",
      "Epoch 9: train loss: 0.5225743055343628\n",
      "Epoch 9: train loss: 0.5396603941917419\n",
      "Epoch 9: train loss: 0.6528306603431702\n",
      "Epoch 9: train loss: 0.6546989679336548\n",
      "Epoch 9: train loss: 0.6265517473220825\n",
      "Epoch 9: train loss: 0.562726616859436\n",
      "Epoch 9: train loss: 0.568466305732727\n",
      "Epoch 9: train loss: 0.3930898606777191\n",
      "Epoch 9: train loss: 0.4970007538795471\n",
      "Epoch 9: train loss: 0.609504759311676\n",
      "Epoch 9: train loss: 0.5659788846969604\n",
      "Epoch 9: train loss: 0.5721018314361572\n",
      "Epoch 9: train loss: 0.6353311538696289\n",
      "Epoch 9: train loss: 0.6376006007194519\n",
      "Epoch 9: train loss: 0.5806566476821899\n",
      "Epoch 9: train loss: 0.5170649290084839\n",
      "Epoch 9: train loss: 0.6731975674629211\n",
      "Epoch 9: train loss: 0.389599084854126\n",
      "Epoch 9: train loss: 0.53398597240448\n",
      "Epoch 9: train loss: 0.51567143201828\n",
      "Epoch 9: train loss: 0.5567623972892761\n",
      "Epoch 9: train loss: 0.4853881299495697\n",
      "Epoch 9: train loss: 0.5771381258964539\n",
      "Epoch 9: train loss: 0.4462131857872009\n",
      "Epoch 9: train loss: 0.521222710609436\n",
      "Epoch 9: train loss: 0.632919430732727\n",
      "Epoch 9: train loss: 0.5022491812705994\n",
      "Epoch 9: train loss: 0.47307634353637695\n",
      "Epoch 9: train loss: 0.49849480390548706\n",
      "Epoch 9: train loss: 0.6044973134994507\n",
      "Epoch 9: train loss: 0.6380950808525085\n",
      "Epoch 9: train loss: 0.5319420695304871\n",
      "Epoch 9: train loss: 0.6368037462234497\n",
      "Epoch 9: train loss: 0.5991730690002441\n",
      "Epoch 9: train loss: 0.5059858560562134\n",
      "Epoch 9: train loss: 0.5834790468215942\n",
      "Epoch 9: train loss: 0.47037458419799805\n",
      "Epoch 10: train loss: 0.4604795277118683\n",
      "Epoch 10: train loss: 0.5189465880393982\n",
      "Epoch 10: train loss: 0.6928985714912415\n",
      "Epoch 10: train loss: 0.5188764929771423\n",
      "Epoch 10: train loss: 0.4125005900859833\n",
      "Epoch 10: train loss: 0.5655791759490967\n",
      "Epoch 10: train loss: 0.4515362083911896\n",
      "Epoch 10: train loss: 0.5293258428573608\n",
      "Epoch 10: train loss: 0.5979061722755432\n",
      "Epoch 10: train loss: 0.5174102783203125\n",
      "Epoch 10: train loss: 0.5613634586334229\n",
      "Epoch 10: train loss: 0.6533499956130981\n",
      "Epoch 10: train loss: 0.3589714765548706\n",
      "Epoch 10: train loss: 0.5977634787559509\n",
      "Epoch 10: train loss: 0.5710026025772095\n",
      "Epoch 10: train loss: 0.5694054365158081\n",
      "Epoch 10: train loss: 0.4726668894290924\n",
      "Epoch 10: train loss: 0.559451699256897\n",
      "Epoch 10: train loss: 0.48866352438926697\n",
      "Epoch 10: train loss: 0.6409131288528442\n",
      "Epoch 10: train loss: 0.5383661985397339\n",
      "Epoch 10: train loss: 0.5243139863014221\n",
      "Epoch 10: train loss: 0.583007276058197\n",
      "Epoch 10: train loss: 0.4618220627307892\n",
      "Epoch 10: train loss: 0.5722864866256714\n",
      "Epoch 10: train loss: 0.4300517737865448\n",
      "Epoch 10: train loss: 0.5618838667869568\n",
      "Epoch 10: train loss: 0.5461763143539429\n",
      "Epoch 10: train loss: 0.558623194694519\n",
      "Epoch 10: train loss: 0.399770587682724\n",
      "Epoch 10: train loss: 0.5634814500808716\n",
      "Epoch 10: train loss: 0.5972892045974731\n",
      "Epoch 10: train loss: 0.360649436712265\n",
      "Epoch 10: train loss: 0.555442214012146\n",
      "Epoch 10: train loss: 0.7264873385429382\n",
      "Epoch 10: train loss: 0.5228229761123657\n",
      "Epoch 10: train loss: 0.5964989066123962\n",
      "Epoch 10: train loss: 0.6890867948532104\n",
      "Epoch 10: train loss: 0.48842689394950867\n",
      "Epoch 10: train loss: 0.4924522638320923\n",
      "Epoch 10: train loss: 0.46275779604911804\n",
      "Epoch 10: train loss: 0.6962100863456726\n",
      "Epoch 10: train loss: 0.5176836252212524\n",
      "Epoch 10: train loss: 0.3313896059989929\n",
      "Epoch 10: train loss: 0.380644291639328\n",
      "Epoch 10: train loss: 0.42283979058265686\n",
      "Epoch 10: train loss: 0.4855395257472992\n",
      "Epoch 10: train loss: 0.5431003570556641\n",
      "Epoch 10: train loss: 0.5507407188415527\n",
      "Epoch 10: train loss: 0.7149645090103149\n",
      "Epoch 10: train loss: 0.2948559820652008\n",
      "Epoch 10: train loss: 0.5455574989318848\n",
      "Epoch 10: train loss: 0.4834735095500946\n",
      "Epoch 10: train loss: 0.5816506147384644\n",
      "Epoch 10: train loss: 0.4455849230289459\n",
      "Epoch 10: train loss: 0.554207980632782\n",
      "Epoch 10: train loss: 0.364113986492157\n",
      "Epoch 10: train loss: 0.8246012926101685\n",
      "Epoch 10: train loss: 0.632142961025238\n",
      "Epoch 10: train loss: 0.6884114742279053\n",
      "Epoch 10: train loss: 0.6217206716537476\n",
      "Epoch 10: train loss: 0.5233796834945679\n",
      "Epoch 10: train loss: 0.6324070692062378\n",
      "Epoch 10: train loss: 0.6204582452774048\n",
      "Epoch 10: train loss: 0.45069199800491333\n",
      "Epoch 10: train loss: 0.5402427911758423\n",
      "Epoch 10: train loss: 0.599392831325531\n",
      "Epoch 10: train loss: 0.6229888200759888\n",
      "Epoch 10: train loss: 0.6753538250923157\n",
      "Epoch 10: train loss: 0.7353807687759399\n",
      "Epoch 10: train loss: 0.5317592620849609\n",
      "Epoch 10: train loss: 0.4558523893356323\n",
      "Epoch 10: train loss: 0.572998046875\n",
      "Epoch 10: train loss: 0.5527108907699585\n",
      "Epoch 10: train loss: 0.4777209758758545\n",
      "Epoch 10: train loss: 0.48556920886039734\n",
      "Epoch 10: train loss: 0.6098198294639587\n",
      "Epoch 10: train loss: 0.6057081818580627\n",
      "Epoch 10: train loss: 0.5491487979888916\n",
      "Epoch 10: train loss: 0.5865820050239563\n",
      "Epoch 10: train loss: 0.4940182864665985\n",
      "Epoch 10: train loss: 0.5000365972518921\n",
      "Epoch 10: train loss: 0.5508162975311279\n",
      "Epoch 10: train loss: 0.5574523210525513\n",
      "Epoch 10: train loss: 0.6067466735839844\n",
      "Epoch 10: train loss: 0.548905611038208\n",
      "Epoch 10: train loss: 0.5535551905632019\n",
      "Epoch 10: train loss: 0.3642297089099884\n",
      "Epoch 10: train loss: 0.4695958197116852\n",
      "Epoch 10: train loss: 0.5503214001655579\n",
      "Epoch 10: train loss: 0.652503252029419\n",
      "Epoch 10: train loss: 0.5624462366104126\n",
      "Epoch 10: train loss: 0.5668867826461792\n",
      "Epoch 10: train loss: 0.5338979959487915\n",
      "Epoch 10: train loss: 0.5540395379066467\n",
      "Epoch 10: train loss: 0.5283992290496826\n",
      "Epoch 10: train loss: 0.5186092257499695\n",
      "Epoch 10: train loss: 0.5217677354812622\n",
      "Epoch 10: train loss: 0.6461402773857117\n",
      "Epoch 10: train loss: 0.505719780921936\n",
      "Epoch 10: train loss: 0.6555718779563904\n",
      "Epoch 10: train loss: 0.6283477544784546\n",
      "Epoch 10: train loss: 0.6710271835327148\n",
      "Epoch 10: train loss: 0.495885968208313\n",
      "Epoch 10: train loss: 0.5934833884239197\n",
      "Epoch 10: train loss: 0.5343237519264221\n",
      "Epoch 10: train loss: 0.4499383270740509\n",
      "Epoch 10: train loss: 0.539818525314331\n",
      "Epoch 10: train loss: 0.5788733959197998\n",
      "Epoch 10: train loss: 0.5204062461853027\n",
      "Epoch 10: train loss: 0.4698823094367981\n",
      "Epoch 10: train loss: 0.6168418526649475\n",
      "Epoch 10: train loss: 0.7285729646682739\n",
      "Epoch 10: train loss: 0.4562520384788513\n",
      "Epoch 10: train loss: 0.5035416483879089\n",
      "Epoch 10: train loss: 0.6777534484863281\n",
      "Epoch 10: train loss: 0.49402284622192383\n",
      "Epoch 10: train loss: 0.4799134135246277\n",
      "Epoch 10: train loss: 0.5916950106620789\n",
      "Epoch 10: train loss: 0.7645003199577332\n",
      "Epoch 10: train loss: 0.47626402974128723\n",
      "Epoch 10: train loss: 0.605620265007019\n",
      "Epoch 10: train loss: 0.6079367399215698\n",
      "Epoch 10: train loss: 0.7352136969566345\n",
      "Epoch 11: train loss: 0.5831319689750671\n",
      "Epoch 11: train loss: 0.5931236743927002\n",
      "Epoch 11: train loss: 0.4194992482662201\n",
      "Epoch 11: train loss: 0.4906701445579529\n",
      "Epoch 11: train loss: 0.5894153118133545\n",
      "Epoch 11: train loss: 0.6613864898681641\n",
      "Epoch 11: train loss: 0.49467402696609497\n",
      "Epoch 11: train loss: 0.7668943405151367\n",
      "Epoch 11: train loss: 0.6036521196365356\n",
      "Epoch 11: train loss: 0.4350460171699524\n",
      "Epoch 11: train loss: 0.5684311389923096\n",
      "Epoch 11: train loss: 0.5946956276893616\n",
      "Epoch 11: train loss: 0.5436204671859741\n",
      "Epoch 11: train loss: 0.5907145738601685\n",
      "Epoch 11: train loss: 0.577564537525177\n",
      "Epoch 11: train loss: 0.5340563058853149\n",
      "Epoch 11: train loss: 0.6094398498535156\n",
      "Epoch 11: train loss: 0.5647061467170715\n",
      "Epoch 11: train loss: 0.5312300324440002\n",
      "Epoch 11: train loss: 0.45648786425590515\n",
      "Epoch 11: train loss: 0.5782335996627808\n",
      "Epoch 11: train loss: 0.55147385597229\n",
      "Epoch 11: train loss: 0.5534238815307617\n",
      "Epoch 11: train loss: 0.38319316506385803\n",
      "Epoch 11: train loss: 0.5344316363334656\n",
      "Epoch 11: train loss: 0.5065006017684937\n",
      "Epoch 11: train loss: 0.5743480324745178\n",
      "Epoch 11: train loss: 0.4080617129802704\n",
      "Epoch 11: train loss: 0.45845821499824524\n",
      "Epoch 11: train loss: 0.5040342807769775\n",
      "Epoch 11: train loss: 0.31767407059669495\n",
      "Epoch 11: train loss: 0.6363348364830017\n",
      "Epoch 11: train loss: 0.5671803951263428\n",
      "Epoch 11: train loss: 0.46348366141319275\n",
      "Epoch 11: train loss: 0.5287806391716003\n",
      "Epoch 11: train loss: 0.4030846655368805\n",
      "Epoch 11: train loss: 0.5416016578674316\n",
      "Epoch 11: train loss: 0.7296042442321777\n",
      "Epoch 11: train loss: 0.5317195653915405\n",
      "Epoch 11: train loss: 0.5381382703781128\n",
      "Epoch 11: train loss: 0.7007884979248047\n",
      "Epoch 11: train loss: 0.6585195660591125\n",
      "Epoch 11: train loss: 0.4909065365791321\n",
      "Epoch 11: train loss: 0.48750749230384827\n",
      "Epoch 11: train loss: 0.5428081750869751\n",
      "Epoch 11: train loss: 0.5892361402511597\n",
      "Epoch 11: train loss: 0.4956405460834503\n",
      "Epoch 11: train loss: 0.47767648100852966\n",
      "Epoch 11: train loss: 0.5465428829193115\n",
      "Epoch 11: train loss: 0.5368488430976868\n",
      "Epoch 11: train loss: 0.5180793404579163\n",
      "Epoch 11: train loss: 0.5378168225288391\n",
      "Epoch 11: train loss: 0.5693367719650269\n",
      "Epoch 11: train loss: 0.5992173552513123\n",
      "Epoch 11: train loss: 0.5971506834030151\n",
      "Epoch 11: train loss: 0.5420220494270325\n",
      "Epoch 11: train loss: 0.4988361895084381\n",
      "Epoch 11: train loss: 0.7110230922698975\n",
      "Epoch 11: train loss: 0.5154470801353455\n",
      "Epoch 11: train loss: 0.5075063109397888\n",
      "Epoch 11: train loss: 0.5268307328224182\n",
      "Epoch 11: train loss: 0.5447173118591309\n",
      "Epoch 11: train loss: 0.5818066000938416\n",
      "Epoch 11: train loss: 0.6403293609619141\n",
      "Epoch 11: train loss: 0.7100444436073303\n",
      "Epoch 11: train loss: 0.5679001808166504\n",
      "Epoch 11: train loss: 0.618180513381958\n",
      "Epoch 11: train loss: 0.4868997037410736\n",
      "Epoch 11: train loss: 0.4863528907299042\n",
      "Epoch 11: train loss: 0.6111658811569214\n",
      "Epoch 11: train loss: 0.5807733535766602\n",
      "Epoch 11: train loss: 0.5147337317466736\n",
      "Epoch 11: train loss: 0.41228243708610535\n",
      "Epoch 11: train loss: 0.53474360704422\n",
      "Epoch 11: train loss: 0.648354709148407\n",
      "Epoch 11: train loss: 0.5148215293884277\n",
      "Epoch 11: train loss: 0.6050037741661072\n",
      "Epoch 11: train loss: 0.6770693063735962\n",
      "Epoch 11: train loss: 0.4773625433444977\n",
      "Epoch 11: train loss: 0.6069392561912537\n",
      "Epoch 11: train loss: 0.41319501399993896\n",
      "Epoch 11: train loss: 0.46043774485588074\n",
      "Epoch 11: train loss: 0.4784707725048065\n",
      "Epoch 11: train loss: 0.6820148229598999\n",
      "Epoch 11: train loss: 0.44697463512420654\n",
      "Epoch 11: train loss: 0.5637724995613098\n",
      "Epoch 11: train loss: 0.4370412528514862\n",
      "Epoch 11: train loss: 0.6399140954017639\n",
      "Epoch 11: train loss: 0.5003660917282104\n",
      "Epoch 11: train loss: 0.3260444104671478\n",
      "Epoch 11: train loss: 0.6264236569404602\n",
      "Epoch 11: train loss: 0.3674130439758301\n",
      "Epoch 11: train loss: 0.4075809121131897\n",
      "Epoch 11: train loss: 0.4539776146411896\n",
      "Epoch 11: train loss: 0.6583462953567505\n",
      "Epoch 11: train loss: 0.5046632289886475\n",
      "Epoch 11: train loss: 0.6383687257766724\n",
      "Epoch 11: train loss: 0.5534796714782715\n",
      "Epoch 11: train loss: 0.4935424327850342\n",
      "Epoch 11: train loss: 0.41281992197036743\n",
      "Epoch 11: train loss: 0.6029559373855591\n",
      "Epoch 11: train loss: 0.4415198266506195\n",
      "Epoch 11: train loss: 0.4189254343509674\n",
      "Epoch 11: train loss: 0.35699114203453064\n",
      "Epoch 11: train loss: 0.5797749757766724\n",
      "Epoch 11: train loss: 0.5513429045677185\n",
      "Epoch 11: train loss: 0.5842574238777161\n",
      "Epoch 11: train loss: 0.5395833849906921\n",
      "Epoch 11: train loss: 0.5809049606323242\n",
      "Epoch 11: train loss: 0.6818839311599731\n",
      "Epoch 11: train loss: 0.5671958327293396\n",
      "Epoch 11: train loss: 0.47135022282600403\n",
      "Epoch 11: train loss: 0.4937770962715149\n",
      "Epoch 11: train loss: 0.7002084255218506\n",
      "Epoch 11: train loss: 0.48282667994499207\n",
      "Epoch 11: train loss: 0.5450836420059204\n",
      "Epoch 11: train loss: 0.6081068515777588\n",
      "Epoch 11: train loss: 0.5124620795249939\n",
      "Epoch 11: train loss: 0.6650463342666626\n",
      "Epoch 11: train loss: 0.5746634602546692\n",
      "Epoch 11: train loss: 0.48741915822029114\n",
      "Epoch 11: train loss: 0.6023015975952148\n",
      "Epoch 11: train loss: 0.7178129553794861\n",
      "Epoch 11: train loss: 0.7682018876075745\n",
      "Epoch 12: train loss: 0.4778073728084564\n",
      "Epoch 12: train loss: 0.5032684206962585\n",
      "Epoch 12: train loss: 0.49423912167549133\n",
      "Epoch 12: train loss: 0.717598021030426\n",
      "Epoch 12: train loss: 0.6057335734367371\n",
      "Epoch 12: train loss: 0.5165661573410034\n",
      "Epoch 12: train loss: 0.6171925067901611\n",
      "Epoch 12: train loss: 0.6590991616249084\n",
      "Epoch 12: train loss: 0.5008743405342102\n",
      "Epoch 12: train loss: 0.4669939875602722\n",
      "Epoch 12: train loss: 0.6270055174827576\n",
      "Epoch 12: train loss: 0.4473322331905365\n",
      "Epoch 12: train loss: 0.5027781128883362\n",
      "Epoch 12: train loss: 0.4558556079864502\n",
      "Epoch 12: train loss: 0.4465702772140503\n",
      "Epoch 12: train loss: 0.5133627653121948\n",
      "Epoch 12: train loss: 0.45128607749938965\n",
      "Epoch 12: train loss: 0.5378272533416748\n",
      "Epoch 12: train loss: 0.5634987354278564\n",
      "Epoch 12: train loss: 0.553780734539032\n",
      "Epoch 12: train loss: 0.6203794479370117\n",
      "Epoch 12: train loss: 0.4600123167037964\n",
      "Epoch 12: train loss: 0.5429401397705078\n",
      "Epoch 12: train loss: 0.3755488991737366\n",
      "Epoch 12: train loss: 0.41019439697265625\n",
      "Epoch 12: train loss: 0.652203381061554\n",
      "Epoch 12: train loss: 0.4629840552806854\n",
      "Epoch 12: train loss: 0.4139419496059418\n",
      "Epoch 12: train loss: 0.6045041680335999\n",
      "Epoch 12: train loss: 0.6028749346733093\n",
      "Epoch 12: train loss: 0.5737931728363037\n",
      "Epoch 12: train loss: 0.5095570087432861\n",
      "Epoch 12: train loss: 0.6104908585548401\n",
      "Epoch 12: train loss: 0.4315676689147949\n",
      "Epoch 12: train loss: 0.6035628914833069\n",
      "Epoch 12: train loss: 0.6106654405593872\n",
      "Epoch 12: train loss: 0.5522648692131042\n",
      "Epoch 12: train loss: 0.589483916759491\n",
      "Epoch 12: train loss: 0.48217126727104187\n",
      "Epoch 12: train loss: 0.5897250175476074\n",
      "Epoch 12: train loss: 0.48298293352127075\n",
      "Epoch 12: train loss: 0.588218092918396\n",
      "Epoch 12: train loss: 0.5742917060852051\n",
      "Epoch 12: train loss: 0.5227232575416565\n",
      "Epoch 12: train loss: 0.4640294313430786\n",
      "Epoch 12: train loss: 0.5816003084182739\n",
      "Epoch 12: train loss: 0.6330878138542175\n",
      "Epoch 12: train loss: 0.7413483262062073\n",
      "Epoch 12: train loss: 0.4449595510959625\n",
      "Epoch 12: train loss: 0.6044952869415283\n",
      "Epoch 12: train loss: 0.48254913091659546\n",
      "Epoch 12: train loss: 0.5003324747085571\n",
      "Epoch 12: train loss: 0.584040641784668\n",
      "Epoch 12: train loss: 0.49667271971702576\n",
      "Epoch 12: train loss: 0.444133460521698\n",
      "Epoch 12: train loss: 0.5384097695350647\n",
      "Epoch 12: train loss: 0.6071839332580566\n",
      "Epoch 12: train loss: 0.48123303055763245\n",
      "Epoch 12: train loss: 0.6757819056510925\n",
      "Epoch 12: train loss: 0.5098987817764282\n",
      "Epoch 12: train loss: 0.6176109313964844\n",
      "Epoch 12: train loss: 0.5334218740463257\n",
      "Epoch 12: train loss: 0.5512023568153381\n",
      "Epoch 12: train loss: 0.629410982131958\n",
      "Epoch 12: train loss: 0.5173644423484802\n",
      "Epoch 12: train loss: 0.5710999369621277\n",
      "Epoch 12: train loss: 0.4547867774963379\n",
      "Epoch 12: train loss: 0.6228623986244202\n",
      "Epoch 12: train loss: 0.6927775144577026\n",
      "Epoch 12: train loss: 0.6982924342155457\n",
      "Epoch 12: train loss: 0.5079198479652405\n",
      "Epoch 12: train loss: 0.5460459589958191\n",
      "Epoch 12: train loss: 0.4947185516357422\n",
      "Epoch 12: train loss: 0.648993968963623\n",
      "Epoch 12: train loss: 0.6332378387451172\n",
      "Epoch 12: train loss: 0.5463661551475525\n",
      "Epoch 12: train loss: 0.589949905872345\n",
      "Epoch 12: train loss: 0.5845174193382263\n",
      "Epoch 12: train loss: 0.5647281408309937\n",
      "Epoch 12: train loss: 0.5240275263786316\n",
      "Epoch 12: train loss: 0.46961116790771484\n",
      "Epoch 12: train loss: 0.5788170099258423\n",
      "Epoch 12: train loss: 0.5056530237197876\n",
      "Epoch 12: train loss: 0.5933051109313965\n",
      "Epoch 12: train loss: 0.44429299235343933\n",
      "Epoch 12: train loss: 0.6022589802742004\n",
      "Epoch 12: train loss: 0.5552117824554443\n",
      "Epoch 12: train loss: 0.585784912109375\n",
      "Epoch 12: train loss: 0.5064345002174377\n",
      "Epoch 12: train loss: 0.49046483635902405\n",
      "Epoch 12: train loss: 0.6041815876960754\n",
      "Epoch 12: train loss: 0.46974074840545654\n",
      "Epoch 12: train loss: 0.6217124462127686\n",
      "Epoch 12: train loss: 0.6798478960990906\n",
      "Epoch 12: train loss: 0.46354609727859497\n",
      "Epoch 12: train loss: 0.5243209600448608\n",
      "Epoch 12: train loss: 0.6711344718933105\n",
      "Epoch 12: train loss: 0.7288216352462769\n",
      "Epoch 12: train loss: 0.4745582640171051\n",
      "Epoch 12: train loss: 0.510391354560852\n",
      "Epoch 12: train loss: 0.5758638381958008\n",
      "Epoch 12: train loss: 0.5754407048225403\n",
      "Epoch 12: train loss: 0.5262953639030457\n",
      "Epoch 12: train loss: 0.6352558135986328\n",
      "Epoch 12: train loss: 0.48712337017059326\n",
      "Epoch 12: train loss: 0.46049126982688904\n",
      "Epoch 12: train loss: 0.5583594441413879\n",
      "Epoch 12: train loss: 0.569074273109436\n",
      "Epoch 12: train loss: 0.6976915597915649\n",
      "Epoch 12: train loss: 0.6281351447105408\n",
      "Epoch 12: train loss: 0.3974606394767761\n",
      "Epoch 12: train loss: 0.6039814949035645\n",
      "Epoch 12: train loss: 0.5506969690322876\n",
      "Epoch 12: train loss: 0.48559102416038513\n",
      "Epoch 12: train loss: 0.36063632369041443\n",
      "Epoch 12: train loss: 0.4580025374889374\n",
      "Epoch 12: train loss: 0.5230284929275513\n",
      "Epoch 12: train loss: 0.5234231352806091\n",
      "Epoch 12: train loss: 0.46897926926612854\n",
      "Epoch 12: train loss: 0.5493770241737366\n",
      "Epoch 12: train loss: 0.44121038913726807\n",
      "Epoch 12: train loss: 0.5488982200622559\n",
      "Epoch 12: train loss: 0.6413028836250305\n",
      "Epoch 12: train loss: 0.3783349096775055\n",
      "Epoch 13: train loss: 0.6482095718383789\n",
      "Epoch 13: train loss: 0.5369337797164917\n",
      "Epoch 13: train loss: 0.5890276432037354\n",
      "Epoch 13: train loss: 0.6291087865829468\n",
      "Epoch 13: train loss: 0.5471553206443787\n",
      "Epoch 13: train loss: 0.45740455389022827\n",
      "Epoch 13: train loss: 0.458583801984787\n",
      "Epoch 13: train loss: 0.43228229880332947\n",
      "Epoch 13: train loss: 0.6220998167991638\n",
      "Epoch 13: train loss: 0.5547935962677002\n",
      "Epoch 13: train loss: 0.6146628260612488\n",
      "Epoch 13: train loss: 0.5246127843856812\n",
      "Epoch 13: train loss: 0.5298922657966614\n",
      "Epoch 13: train loss: 0.64571613073349\n",
      "Epoch 13: train loss: 0.656130850315094\n",
      "Epoch 13: train loss: 0.5759933590888977\n",
      "Epoch 13: train loss: 0.5230201482772827\n",
      "Epoch 13: train loss: 0.4759119153022766\n",
      "Epoch 13: train loss: 0.4660784602165222\n",
      "Epoch 13: train loss: 0.575626790523529\n",
      "Epoch 13: train loss: 0.3930553197860718\n",
      "Epoch 13: train loss: 0.5683004260063171\n",
      "Epoch 13: train loss: 0.4430484473705292\n",
      "Epoch 13: train loss: 0.5220451354980469\n",
      "Epoch 13: train loss: 0.618908703327179\n",
      "Epoch 13: train loss: 0.5309179425239563\n",
      "Epoch 13: train loss: 0.543351411819458\n",
      "Epoch 13: train loss: 0.6846306920051575\n",
      "Epoch 13: train loss: 0.65287184715271\n",
      "Epoch 13: train loss: 0.5444686412811279\n",
      "Epoch 13: train loss: 0.4899440109729767\n",
      "Epoch 13: train loss: 0.3320830464363098\n",
      "Epoch 13: train loss: 0.5895732045173645\n",
      "Epoch 13: train loss: 0.6504555344581604\n",
      "Epoch 13: train loss: 0.553184986114502\n",
      "Epoch 13: train loss: 0.4796670973300934\n",
      "Epoch 13: train loss: 0.5467833280563354\n",
      "Epoch 13: train loss: 0.537257194519043\n",
      "Epoch 13: train loss: 0.6435227990150452\n",
      "Epoch 13: train loss: 0.4620906412601471\n",
      "Epoch 13: train loss: 0.5096888542175293\n",
      "Epoch 13: train loss: 0.4958372414112091\n",
      "Epoch 13: train loss: 0.6683646440505981\n",
      "Epoch 13: train loss: 0.6420698165893555\n",
      "Epoch 13: train loss: 0.5730366110801697\n",
      "Epoch 13: train loss: 0.5862486362457275\n",
      "Epoch 13: train loss: 0.5002557635307312\n",
      "Epoch 13: train loss: 0.4081091284751892\n",
      "Epoch 13: train loss: 0.5614985227584839\n",
      "Epoch 13: train loss: 0.3986818492412567\n",
      "Epoch 13: train loss: 0.540198802947998\n",
      "Epoch 13: train loss: 0.6648553013801575\n",
      "Epoch 13: train loss: 0.48549219965934753\n",
      "Epoch 13: train loss: 0.52009117603302\n",
      "Epoch 13: train loss: 0.6318093538284302\n",
      "Epoch 13: train loss: 0.468840092420578\n",
      "Epoch 13: train loss: 0.5645104050636292\n",
      "Epoch 13: train loss: 0.45517829060554504\n",
      "Epoch 13: train loss: 0.7107350826263428\n",
      "Epoch 13: train loss: 0.500903844833374\n",
      "Epoch 13: train loss: 0.3019161522388458\n",
      "Epoch 13: train loss: 0.3686307370662689\n",
      "Epoch 13: train loss: 0.44132375717163086\n",
      "Epoch 13: train loss: 0.39143744111061096\n",
      "Epoch 13: train loss: 0.5452072620391846\n",
      "Epoch 13: train loss: 0.5352877974510193\n",
      "Epoch 13: train loss: 0.5720484256744385\n",
      "Epoch 13: train loss: 0.5478512644767761\n",
      "Epoch 13: train loss: 0.5847708582878113\n",
      "Epoch 13: train loss: 0.5066072940826416\n",
      "Epoch 13: train loss: 0.5322754979133606\n",
      "Epoch 13: train loss: 0.623435378074646\n",
      "Epoch 13: train loss: 0.6740644574165344\n",
      "Epoch 13: train loss: 0.5250694751739502\n",
      "Epoch 13: train loss: 0.6028726100921631\n",
      "Epoch 13: train loss: 0.6731815338134766\n",
      "Epoch 13: train loss: 0.7142658829689026\n",
      "Epoch 13: train loss: 0.40026527643203735\n",
      "Epoch 13: train loss: 0.5647672414779663\n",
      "Epoch 13: train loss: 0.6229508519172668\n",
      "Epoch 13: train loss: 0.8520755171775818\n",
      "Epoch 13: train loss: 0.36917659640312195\n",
      "Epoch 13: train loss: 0.5624541640281677\n",
      "Epoch 13: train loss: 0.544058620929718\n",
      "Epoch 13: train loss: 0.5089447498321533\n",
      "Epoch 13: train loss: 0.6543696522712708\n",
      "Epoch 13: train loss: 0.3892047703266144\n",
      "Epoch 13: train loss: 0.4341548681259155\n",
      "Epoch 13: train loss: 0.4543265998363495\n",
      "Epoch 13: train loss: 0.5208802819252014\n",
      "Epoch 13: train loss: 0.4320249855518341\n",
      "Epoch 13: train loss: 0.4805733561515808\n",
      "Epoch 13: train loss: 0.5617750883102417\n",
      "Epoch 13: train loss: 0.48130276799201965\n",
      "Epoch 13: train loss: 0.5542545914649963\n",
      "Epoch 13: train loss: 0.529582679271698\n",
      "Epoch 13: train loss: 0.656467080116272\n",
      "Epoch 13: train loss: 0.4976159632205963\n",
      "Epoch 13: train loss: 0.5706468224525452\n",
      "Epoch 13: train loss: 0.5942333936691284\n",
      "Epoch 13: train loss: 0.5575622320175171\n",
      "Epoch 13: train loss: 0.6792628765106201\n",
      "Epoch 13: train loss: 0.5128728747367859\n",
      "Epoch 13: train loss: 0.5353417992591858\n",
      "Epoch 13: train loss: 0.4462471008300781\n",
      "Epoch 13: train loss: 0.4640408456325531\n",
      "Epoch 13: train loss: 0.3825300633907318\n",
      "Epoch 13: train loss: 0.5059404373168945\n",
      "Epoch 13: train loss: 0.5345026850700378\n",
      "Epoch 13: train loss: 0.6160807609558105\n",
      "Epoch 13: train loss: 0.4528878927230835\n",
      "Epoch 13: train loss: 0.6551284790039062\n",
      "Epoch 13: train loss: 0.40416738390922546\n",
      "Epoch 13: train loss: 0.6412603855133057\n",
      "Epoch 13: train loss: 0.6699066162109375\n",
      "Epoch 13: train loss: 0.5314989686012268\n",
      "Epoch 13: train loss: 0.649309515953064\n",
      "Epoch 13: train loss: 0.5543773770332336\n",
      "Epoch 13: train loss: 0.6551237106323242\n",
      "Epoch 13: train loss: 0.653911828994751\n",
      "Epoch 13: train loss: 0.4532735049724579\n",
      "Epoch 13: train loss: 0.5618860125541687\n",
      "Epoch 13: train loss: 0.5293447375297546\n",
      "Epoch 13: train loss: 0.4252733588218689\n",
      "Epoch 14: train loss: 0.5630636811256409\n",
      "Epoch 14: train loss: 0.6363036036491394\n",
      "Epoch 14: train loss: 0.5916538238525391\n",
      "Epoch 14: train loss: 0.645412802696228\n",
      "Epoch 14: train loss: 0.4385034143924713\n",
      "Epoch 14: train loss: 0.5402699112892151\n",
      "Epoch 14: train loss: 0.4886690080165863\n",
      "Epoch 14: train loss: 0.4735241234302521\n",
      "Epoch 14: train loss: 0.5508112907409668\n",
      "Epoch 14: train loss: 0.45582905411720276\n",
      "Epoch 14: train loss: 0.6319652795791626\n",
      "Epoch 14: train loss: 0.60177081823349\n",
      "Epoch 14: train loss: 0.5429627895355225\n",
      "Epoch 14: train loss: 0.480680912733078\n",
      "Epoch 14: train loss: 0.46177732944488525\n",
      "Epoch 14: train loss: 0.5713667869567871\n",
      "Epoch 14: train loss: 0.4645484685897827\n",
      "Epoch 14: train loss: 0.49799755215644836\n",
      "Epoch 14: train loss: 0.6038147807121277\n",
      "Epoch 14: train loss: 0.6701505184173584\n",
      "Epoch 14: train loss: 0.5269774794578552\n",
      "Epoch 14: train loss: 0.7523168921470642\n",
      "Epoch 14: train loss: 0.5976590514183044\n",
      "Epoch 14: train loss: 0.4191477298736572\n",
      "Epoch 14: train loss: 0.6854987144470215\n",
      "Epoch 14: train loss: 0.5540743470191956\n",
      "Epoch 14: train loss: 0.5422081351280212\n",
      "Epoch 14: train loss: 0.5027211904525757\n",
      "Epoch 14: train loss: 0.5538671016693115\n",
      "Epoch 14: train loss: 0.5743319988250732\n",
      "Epoch 14: train loss: 0.4936662018299103\n",
      "Epoch 14: train loss: 0.6474621891975403\n",
      "Epoch 14: train loss: 0.5334892868995667\n",
      "Epoch 14: train loss: 0.4691397249698639\n",
      "Epoch 14: train loss: 0.6213196516036987\n",
      "Epoch 14: train loss: 0.7599135041236877\n",
      "Epoch 14: train loss: 0.4826301634311676\n",
      "Epoch 14: train loss: 0.44495177268981934\n",
      "Epoch 14: train loss: 0.39605972170829773\n",
      "Epoch 14: train loss: 0.5330100059509277\n",
      "Epoch 14: train loss: 0.6099017262458801\n",
      "Epoch 14: train loss: 0.590461015701294\n",
      "Epoch 14: train loss: 0.3777300715446472\n",
      "Epoch 14: train loss: 0.5260679721832275\n",
      "Epoch 14: train loss: 0.6535446643829346\n",
      "Epoch 14: train loss: 0.5115121603012085\n",
      "Epoch 14: train loss: 0.40895751118659973\n",
      "Epoch 14: train loss: 0.4557051956653595\n",
      "Epoch 14: train loss: 0.4075712561607361\n",
      "Epoch 14: train loss: 0.6587531566619873\n",
      "Epoch 14: train loss: 0.4299749433994293\n",
      "Epoch 14: train loss: 0.37454554438591003\n",
      "Epoch 14: train loss: 0.502053439617157\n",
      "Epoch 14: train loss: 0.6401251554489136\n",
      "Epoch 14: train loss: 0.5734348297119141\n",
      "Epoch 14: train loss: 0.4207223653793335\n",
      "Epoch 14: train loss: 0.40993860363960266\n",
      "Epoch 14: train loss: 0.5272183418273926\n",
      "Epoch 14: train loss: 0.5100670456886292\n",
      "Epoch 14: train loss: 0.8743003010749817\n",
      "Epoch 14: train loss: 0.5143054127693176\n",
      "Epoch 14: train loss: 0.6398536562919617\n",
      "Epoch 14: train loss: 0.7102926969528198\n",
      "Epoch 14: train loss: 0.5258693099021912\n",
      "Epoch 14: train loss: 0.4825904965400696\n",
      "Epoch 14: train loss: 0.42370185256004333\n",
      "Epoch 14: train loss: 0.605562150478363\n",
      "Epoch 14: train loss: 0.6362208127975464\n",
      "Epoch 14: train loss: 0.5689722299575806\n",
      "Epoch 14: train loss: 0.40211454033851624\n",
      "Epoch 14: train loss: 0.5096668601036072\n",
      "Epoch 14: train loss: 0.4409712255001068\n",
      "Epoch 14: train loss: 0.5951013565063477\n",
      "Epoch 14: train loss: 0.4499059021472931\n",
      "Epoch 14: train loss: 0.5728395581245422\n",
      "Epoch 14: train loss: 0.5021174550056458\n",
      "Epoch 14: train loss: 0.4640520513057709\n",
      "Epoch 14: train loss: 0.484580397605896\n",
      "Epoch 14: train loss: 0.4284990131855011\n",
      "Epoch 14: train loss: 0.4461650848388672\n",
      "Epoch 14: train loss: 0.529362142086029\n",
      "Epoch 14: train loss: 0.6322137713432312\n",
      "Epoch 14: train loss: 0.48959124088287354\n",
      "Epoch 14: train loss: 0.6831270456314087\n",
      "Epoch 14: train loss: 0.5367567539215088\n",
      "Epoch 14: train loss: 0.44212672114372253\n",
      "Epoch 14: train loss: 0.5188551545143127\n",
      "Epoch 14: train loss: 0.6039502620697021\n",
      "Epoch 14: train loss: 0.5564590096473694\n",
      "Epoch 14: train loss: 0.5685600638389587\n",
      "Epoch 14: train loss: 0.5168564319610596\n",
      "Epoch 14: train loss: 0.40280014276504517\n",
      "Epoch 14: train loss: 0.6287980079650879\n",
      "Epoch 14: train loss: 0.6046149730682373\n",
      "Epoch 14: train loss: 0.7221095561981201\n",
      "Epoch 14: train loss: 0.6283084154129028\n",
      "Epoch 14: train loss: 0.56708163022995\n",
      "Epoch 14: train loss: 0.3177390694618225\n",
      "Epoch 14: train loss: 0.3933613896369934\n",
      "Epoch 14: train loss: 0.38142138719558716\n",
      "Epoch 14: train loss: 0.5357058048248291\n",
      "Epoch 14: train loss: 0.6262162327766418\n",
      "Epoch 14: train loss: 0.6262611746788025\n",
      "Epoch 14: train loss: 0.6481991410255432\n",
      "Epoch 14: train loss: 0.5974121689796448\n",
      "Epoch 14: train loss: 0.4416316747665405\n",
      "Epoch 14: train loss: 0.6713007688522339\n",
      "Epoch 14: train loss: 0.5684522390365601\n",
      "Epoch 14: train loss: 0.5527338981628418\n",
      "Epoch 14: train loss: 0.7127522826194763\n",
      "Epoch 14: train loss: 0.5349159836769104\n",
      "Epoch 14: train loss: 0.4462970495223999\n",
      "Epoch 14: train loss: 0.474979430437088\n",
      "Epoch 14: train loss: 0.6064236164093018\n",
      "Epoch 14: train loss: 0.6195108890533447\n",
      "Epoch 14: train loss: 0.42583519220352173\n",
      "Epoch 14: train loss: 0.5551444292068481\n",
      "Epoch 14: train loss: 0.5292009115219116\n",
      "Epoch 14: train loss: 0.4965299069881439\n",
      "Epoch 14: train loss: 0.5704672932624817\n",
      "Epoch 14: train loss: 0.5655134320259094\n",
      "Epoch 14: train loss: 0.5235165357589722\n",
      "Epoch 14: train loss: 0.5005258321762085\n",
      "Epoch 14: train loss: 0.39370712637901306\n",
      "Epoch 15: train loss: 0.5067585110664368\n",
      "Epoch 15: train loss: 0.43820902705192566\n",
      "Epoch 15: train loss: 0.46266067028045654\n",
      "Epoch 15: train loss: 0.5456252098083496\n",
      "Epoch 15: train loss: 0.7978262305259705\n",
      "Epoch 15: train loss: 0.7241914868354797\n",
      "Epoch 15: train loss: 0.5759435296058655\n",
      "Epoch 15: train loss: 0.536188542842865\n",
      "Epoch 15: train loss: 0.6304136514663696\n",
      "Epoch 15: train loss: 0.4767206311225891\n",
      "Epoch 15: train loss: 0.6931695938110352\n",
      "Epoch 15: train loss: 0.5411849617958069\n",
      "Epoch 15: train loss: 0.5452966094017029\n",
      "Epoch 15: train loss: 0.6192038059234619\n",
      "Epoch 15: train loss: 0.643457293510437\n",
      "Epoch 15: train loss: 0.5351899266242981\n",
      "Epoch 15: train loss: 0.5914692282676697\n",
      "Epoch 15: train loss: 0.49771466851234436\n",
      "Epoch 15: train loss: 0.4781452715396881\n",
      "Epoch 15: train loss: 0.4593160152435303\n",
      "Epoch 15: train loss: 0.6102505922317505\n",
      "Epoch 15: train loss: 0.4434376060962677\n",
      "Epoch 15: train loss: 0.6680099368095398\n",
      "Epoch 15: train loss: 0.5383236408233643\n",
      "Epoch 15: train loss: 0.5543079376220703\n",
      "Epoch 15: train loss: 0.5944482684135437\n",
      "Epoch 15: train loss: 0.5157656669616699\n",
      "Epoch 15: train loss: 0.683546245098114\n",
      "Epoch 15: train loss: 0.483005166053772\n",
      "Epoch 15: train loss: 0.5278259515762329\n",
      "Epoch 15: train loss: 0.47302696108818054\n",
      "Epoch 15: train loss: 0.42957600951194763\n",
      "Epoch 15: train loss: 0.6596730947494507\n",
      "Epoch 15: train loss: 0.5257998704910278\n",
      "Epoch 15: train loss: 0.4755606949329376\n",
      "Epoch 15: train loss: 0.6129893064498901\n",
      "Epoch 15: train loss: 0.6584994792938232\n",
      "Epoch 15: train loss: 0.5317859649658203\n",
      "Epoch 15: train loss: 0.5894135236740112\n",
      "Epoch 15: train loss: 0.49488067626953125\n",
      "Epoch 15: train loss: 0.5632081627845764\n",
      "Epoch 15: train loss: 0.6861100792884827\n",
      "Epoch 15: train loss: 0.5374347567558289\n",
      "Epoch 15: train loss: 0.41530898213386536\n",
      "Epoch 15: train loss: 0.46815410256385803\n",
      "Epoch 15: train loss: 0.6149405241012573\n",
      "Epoch 15: train loss: 0.6016747355461121\n",
      "Epoch 15: train loss: 0.5092537999153137\n",
      "Epoch 15: train loss: 0.4964428246021271\n",
      "Epoch 15: train loss: 0.555566668510437\n",
      "Epoch 15: train loss: 0.42211949825286865\n",
      "Epoch 15: train loss: 0.5158623456954956\n",
      "Epoch 15: train loss: 0.6201051473617554\n",
      "Epoch 15: train loss: 0.6538101434707642\n",
      "Epoch 15: train loss: 0.5609022974967957\n",
      "Epoch 15: train loss: 0.5093393921852112\n",
      "Epoch 15: train loss: 0.3920772075653076\n",
      "Epoch 15: train loss: 0.6689788103103638\n",
      "Epoch 15: train loss: 0.49496084451675415\n",
      "Epoch 15: train loss: 0.4695548713207245\n",
      "Epoch 15: train loss: 0.5658612847328186\n",
      "Epoch 15: train loss: 0.47210168838500977\n",
      "Epoch 15: train loss: 0.6528476476669312\n",
      "Epoch 15: train loss: 0.569381833076477\n",
      "Epoch 15: train loss: 0.5848329663276672\n",
      "Epoch 15: train loss: 0.6227066516876221\n",
      "Epoch 15: train loss: 0.4666716754436493\n",
      "Epoch 15: train loss: 0.4519299268722534\n",
      "Epoch 15: train loss: 0.5250785946846008\n",
      "Epoch 15: train loss: 0.4687970280647278\n",
      "Epoch 15: train loss: 0.6247830390930176\n",
      "Epoch 15: train loss: 0.45731478929519653\n",
      "Epoch 15: train loss: 0.513135552406311\n",
      "Epoch 15: train loss: 0.4956611096858978\n",
      "Epoch 15: train loss: 0.4696381390094757\n",
      "Epoch 15: train loss: 0.4224117696285248\n",
      "Epoch 15: train loss: 0.6408936977386475\n",
      "Epoch 15: train loss: 0.6355298757553101\n",
      "Epoch 15: train loss: 0.5390408635139465\n",
      "Epoch 15: train loss: 0.4718652367591858\n",
      "Epoch 15: train loss: 0.5662906765937805\n",
      "Epoch 15: train loss: 0.4481555223464966\n",
      "Epoch 15: train loss: 0.6685423851013184\n",
      "Epoch 15: train loss: 0.5862544178962708\n",
      "Epoch 15: train loss: 0.6557803153991699\n",
      "Epoch 15: train loss: 0.5298252701759338\n",
      "Epoch 15: train loss: 0.45919185876846313\n",
      "Epoch 15: train loss: 0.49067994952201843\n",
      "Epoch 15: train loss: 0.5542969107627869\n",
      "Epoch 15: train loss: 0.6917515993118286\n",
      "Epoch 15: train loss: 0.44272536039352417\n",
      "Epoch 15: train loss: 0.5361334085464478\n",
      "Epoch 15: train loss: 0.39164069294929504\n",
      "Epoch 15: train loss: 0.6177529692649841\n",
      "Epoch 15: train loss: 0.3465564250946045\n",
      "Epoch 15: train loss: 0.6030564904212952\n",
      "Epoch 15: train loss: 0.5834324955940247\n",
      "Epoch 15: train loss: 0.5226985216140747\n",
      "Epoch 15: train loss: 0.461312472820282\n",
      "Epoch 15: train loss: 0.4806288182735443\n",
      "Epoch 15: train loss: 0.4342306852340698\n",
      "Epoch 15: train loss: 0.5100550651550293\n",
      "Epoch 15: train loss: 0.5810466408729553\n",
      "Epoch 15: train loss: 0.5484099388122559\n",
      "Epoch 15: train loss: 0.5532065629959106\n",
      "Epoch 15: train loss: 0.5290868282318115\n",
      "Epoch 15: train loss: 0.6223040819168091\n",
      "Epoch 15: train loss: 0.6899948120117188\n",
      "Epoch 15: train loss: 0.39454367756843567\n",
      "Epoch 15: train loss: 0.6147764921188354\n",
      "Epoch 15: train loss: 0.5096247792243958\n",
      "Epoch 15: train loss: 0.4644387662410736\n",
      "Epoch 15: train loss: 0.5812217593193054\n",
      "Epoch 15: train loss: 0.5782001614570618\n",
      "Epoch 15: train loss: 0.636835515499115\n",
      "Epoch 15: train loss: 0.3764379918575287\n",
      "Epoch 15: train loss: 0.7910807728767395\n",
      "Epoch 15: train loss: 0.4990156590938568\n",
      "Epoch 15: train loss: 0.5509073138237\n",
      "Epoch 15: train loss: 0.4473942220211029\n",
      "Epoch 15: train loss: 0.6788614988327026\n",
      "Epoch 15: train loss: 0.45214587450027466\n",
      "Epoch 15: train loss: 0.5330156683921814\n",
      "Epoch 15: train loss: 0.470913290977478\n",
      "Epoch 16: train loss: 0.6709562540054321\n",
      "Epoch 16: train loss: 0.6013922095298767\n",
      "Epoch 16: train loss: 0.4587239623069763\n",
      "Epoch 16: train loss: 0.47099384665489197\n",
      "Epoch 16: train loss: 0.4617859423160553\n",
      "Epoch 16: train loss: 0.5221429467201233\n",
      "Epoch 16: train loss: 0.5837008953094482\n",
      "Epoch 16: train loss: 0.5613262057304382\n",
      "Epoch 16: train loss: 0.4355618953704834\n",
      "Epoch 16: train loss: 0.44305872917175293\n",
      "Epoch 16: train loss: 0.4925787150859833\n",
      "Epoch 16: train loss: 0.5783340334892273\n",
      "Epoch 16: train loss: 0.4772662818431854\n",
      "Epoch 16: train loss: 0.48393744230270386\n",
      "Epoch 16: train loss: 0.5469606518745422\n",
      "Epoch 16: train loss: 0.435108482837677\n",
      "Epoch 16: train loss: 0.5542830228805542\n",
      "Epoch 16: train loss: 0.5331364274024963\n",
      "Epoch 16: train loss: 0.6201592683792114\n",
      "Epoch 16: train loss: 0.5689048171043396\n",
      "Epoch 16: train loss: 0.6430134773254395\n",
      "Epoch 16: train loss: 0.5231618285179138\n",
      "Epoch 16: train loss: 0.6229852437973022\n",
      "Epoch 16: train loss: 0.5333150625228882\n",
      "Epoch 16: train loss: 0.43808096647262573\n",
      "Epoch 16: train loss: 0.5682206153869629\n",
      "Epoch 16: train loss: 0.5188822150230408\n",
      "Epoch 16: train loss: 0.48232778906822205\n",
      "Epoch 16: train loss: 0.7930552959442139\n",
      "Epoch 16: train loss: 0.5206276774406433\n",
      "Epoch 16: train loss: 0.6492553353309631\n",
      "Epoch 16: train loss: 0.3958854377269745\n",
      "Epoch 16: train loss: 0.6216044425964355\n",
      "Epoch 16: train loss: 0.5219324827194214\n",
      "Epoch 16: train loss: 0.4679725170135498\n",
      "Epoch 16: train loss: 0.5630536675453186\n",
      "Epoch 16: train loss: 0.4552912712097168\n",
      "Epoch 16: train loss: 0.4076034724712372\n",
      "Epoch 16: train loss: 0.5898319482803345\n",
      "Epoch 16: train loss: 0.4854983687400818\n",
      "Epoch 16: train loss: 0.6816437244415283\n",
      "Epoch 16: train loss: 0.46194303035736084\n",
      "Epoch 16: train loss: 0.4834428131580353\n",
      "Epoch 16: train loss: 0.5566552877426147\n",
      "Epoch 16: train loss: 0.47003477811813354\n",
      "Epoch 16: train loss: 0.6105324625968933\n",
      "Epoch 16: train loss: 0.6417962312698364\n",
      "Epoch 16: train loss: 0.5513580441474915\n",
      "Epoch 16: train loss: 0.62725830078125\n",
      "Epoch 16: train loss: 0.5215707421302795\n",
      "Epoch 16: train loss: 0.4345506727695465\n",
      "Epoch 16: train loss: 0.6951686143875122\n",
      "Epoch 16: train loss: 0.6122488975524902\n",
      "Epoch 16: train loss: 0.48894286155700684\n",
      "Epoch 16: train loss: 0.5411897897720337\n",
      "Epoch 16: train loss: 0.40025126934051514\n",
      "Epoch 16: train loss: 0.6447979807853699\n",
      "Epoch 16: train loss: 0.5946281552314758\n",
      "Epoch 16: train loss: 0.5628674030303955\n",
      "Epoch 16: train loss: 0.5078281164169312\n",
      "Epoch 16: train loss: 0.5168381333351135\n",
      "Epoch 16: train loss: 0.5414246916770935\n",
      "Epoch 16: train loss: 0.5721390843391418\n",
      "Epoch 16: train loss: 0.5647370219230652\n",
      "Epoch 16: train loss: 0.6017552614212036\n",
      "Epoch 16: train loss: 0.49423861503601074\n",
      "Epoch 16: train loss: 0.7179026007652283\n",
      "Epoch 16: train loss: 0.4286745488643646\n",
      "Epoch 16: train loss: 0.46599555015563965\n",
      "Epoch 16: train loss: 0.45105838775634766\n",
      "Epoch 16: train loss: 0.5585346221923828\n",
      "Epoch 16: train loss: 0.6171448230743408\n",
      "Epoch 16: train loss: 0.511857807636261\n",
      "Epoch 16: train loss: 0.6117309927940369\n",
      "Epoch 16: train loss: 0.5697706937789917\n",
      "Epoch 16: train loss: 0.47852393984794617\n",
      "Epoch 16: train loss: 0.6989599466323853\n",
      "Epoch 16: train loss: 0.5138976573944092\n",
      "Epoch 16: train loss: 0.47866547107696533\n",
      "Epoch 16: train loss: 0.4852798879146576\n",
      "Epoch 16: train loss: 0.4933237135410309\n",
      "Epoch 16: train loss: 0.49726465344429016\n",
      "Epoch 16: train loss: 0.4694584012031555\n",
      "Epoch 16: train loss: 0.5609655976295471\n",
      "Epoch 16: train loss: 0.5455045104026794\n",
      "Epoch 16: train loss: 0.43276354670524597\n",
      "Epoch 16: train loss: 0.49878403544425964\n",
      "Epoch 16: train loss: 0.6334835886955261\n",
      "Epoch 16: train loss: 0.5294029712677002\n",
      "Epoch 16: train loss: 0.44413527846336365\n",
      "Epoch 16: train loss: 0.5685979127883911\n",
      "Epoch 16: train loss: 0.4849095940589905\n",
      "Epoch 16: train loss: 0.4742794334888458\n",
      "Epoch 16: train loss: 0.4575798213481903\n",
      "Epoch 16: train loss: 0.5939695835113525\n",
      "Epoch 16: train loss: 0.3707673251628876\n",
      "Epoch 16: train loss: 0.5183508992195129\n",
      "Epoch 16: train loss: 0.4171502888202667\n",
      "Epoch 16: train loss: 0.6304280161857605\n",
      "Epoch 16: train loss: 0.7764759063720703\n",
      "Epoch 16: train loss: 0.5084181427955627\n",
      "Epoch 16: train loss: 0.588519275188446\n",
      "Epoch 16: train loss: 0.5721762180328369\n",
      "Epoch 16: train loss: 0.5566054582595825\n",
      "Epoch 16: train loss: 0.7279950976371765\n",
      "Epoch 16: train loss: 0.5405359268188477\n",
      "Epoch 16: train loss: 0.5642004013061523\n",
      "Epoch 16: train loss: 0.5087505578994751\n",
      "Epoch 16: train loss: 0.610099732875824\n",
      "Epoch 16: train loss: 0.49685138463974\n",
      "Epoch 16: train loss: 0.480857253074646\n",
      "Epoch 16: train loss: 0.48849427700042725\n",
      "Epoch 16: train loss: 0.43776676058769226\n",
      "Epoch 16: train loss: 0.5485104322433472\n",
      "Epoch 16: train loss: 0.71063631772995\n",
      "Epoch 16: train loss: 0.5661280751228333\n",
      "Epoch 16: train loss: 0.5559829473495483\n",
      "Epoch 16: train loss: 0.5820840001106262\n",
      "Epoch 16: train loss: 0.40523475408554077\n",
      "Epoch 16: train loss: 0.3795206844806671\n",
      "Epoch 16: train loss: 0.5259930491447449\n",
      "Epoch 16: train loss: 0.5355480313301086\n",
      "Epoch 16: train loss: 0.5046276450157166\n",
      "Epoch 16: train loss: 0.54869544506073\n",
      "Epoch 17: train loss: 0.4559181034564972\n",
      "Epoch 17: train loss: 0.4436482787132263\n",
      "Epoch 17: train loss: 0.5042189359664917\n",
      "Epoch 17: train loss: 0.3854276239871979\n",
      "Epoch 17: train loss: 0.568794846534729\n",
      "Epoch 17: train loss: 0.4033181369304657\n",
      "Epoch 17: train loss: 0.6428921818733215\n",
      "Epoch 17: train loss: 0.6695012450218201\n",
      "Epoch 17: train loss: 0.4186467230319977\n",
      "Epoch 17: train loss: 0.610822319984436\n",
      "Epoch 17: train loss: 0.44796639680862427\n",
      "Epoch 17: train loss: 0.6536596417427063\n",
      "Epoch 17: train loss: 0.6381745934486389\n",
      "Epoch 17: train loss: 0.6974464058876038\n",
      "Epoch 17: train loss: 0.5828617811203003\n",
      "Epoch 17: train loss: 0.3874831199645996\n",
      "Epoch 17: train loss: 0.5058521628379822\n",
      "Epoch 17: train loss: 0.48155540227890015\n",
      "Epoch 17: train loss: 0.4373790919780731\n",
      "Epoch 17: train loss: 0.6405791640281677\n",
      "Epoch 17: train loss: 0.654124915599823\n",
      "Epoch 17: train loss: 0.5251590013504028\n",
      "Epoch 17: train loss: 0.6612812876701355\n",
      "Epoch 17: train loss: 0.5571149587631226\n",
      "Epoch 17: train loss: 0.49710074067115784\n",
      "Epoch 17: train loss: 0.6503597497940063\n",
      "Epoch 17: train loss: 0.4185447692871094\n",
      "Epoch 17: train loss: 0.6237345337867737\n",
      "Epoch 17: train loss: 0.4210103750228882\n",
      "Epoch 17: train loss: 0.4546451270580292\n",
      "Epoch 17: train loss: 0.6165581345558167\n",
      "Epoch 17: train loss: 0.5993595719337463\n",
      "Epoch 17: train loss: 0.38046446442604065\n",
      "Epoch 17: train loss: 0.6321893334388733\n",
      "Epoch 17: train loss: 0.47902846336364746\n",
      "Epoch 17: train loss: 0.49066126346588135\n",
      "Epoch 17: train loss: 0.49168574810028076\n",
      "Epoch 17: train loss: 0.5983383059501648\n",
      "Epoch 17: train loss: 0.5176451802253723\n",
      "Epoch 17: train loss: 0.4624151289463043\n",
      "Epoch 17: train loss: 0.46037518978118896\n",
      "Epoch 17: train loss: 0.37950509786605835\n",
      "Epoch 17: train loss: 0.48515456914901733\n",
      "Epoch 17: train loss: 0.5810406804084778\n",
      "Epoch 17: train loss: 0.5317602157592773\n",
      "Epoch 17: train loss: 0.5731217265129089\n",
      "Epoch 17: train loss: 0.4302518963813782\n",
      "Epoch 17: train loss: 0.5308080911636353\n",
      "Epoch 17: train loss: 0.6934838891029358\n",
      "Epoch 17: train loss: 0.5505999326705933\n",
      "Epoch 17: train loss: 0.6634848117828369\n",
      "Epoch 17: train loss: 0.4924320578575134\n",
      "Epoch 17: train loss: 0.3698466122150421\n",
      "Epoch 17: train loss: 0.477468878030777\n",
      "Epoch 17: train loss: 0.402906209230423\n",
      "Epoch 17: train loss: 0.5849387645721436\n",
      "Epoch 17: train loss: 0.5472061038017273\n",
      "Epoch 17: train loss: 0.4748745262622833\n",
      "Epoch 17: train loss: 0.4789806604385376\n",
      "Epoch 17: train loss: 0.4733424186706543\n",
      "Epoch 17: train loss: 0.5144729614257812\n",
      "Epoch 17: train loss: 0.6711858510971069\n",
      "Epoch 17: train loss: 0.6854819059371948\n",
      "Epoch 17: train loss: 0.5962960720062256\n",
      "Epoch 17: train loss: 0.46896281838417053\n",
      "Epoch 17: train loss: 0.5452694296836853\n",
      "Epoch 17: train loss: 0.527703046798706\n",
      "Epoch 17: train loss: 0.6737440228462219\n",
      "Epoch 17: train loss: 0.3911716043949127\n",
      "Epoch 17: train loss: 0.5605639815330505\n",
      "Epoch 17: train loss: 0.4965283274650574\n",
      "Epoch 17: train loss: 0.4877570867538452\n",
      "Epoch 17: train loss: 0.5681251287460327\n",
      "Epoch 17: train loss: 0.40063774585723877\n",
      "Epoch 17: train loss: 0.6216803193092346\n",
      "Epoch 17: train loss: 0.7434513568878174\n",
      "Epoch 17: train loss: 0.587700366973877\n",
      "Epoch 17: train loss: 0.505578875541687\n",
      "Epoch 17: train loss: 0.5967427492141724\n",
      "Epoch 17: train loss: 0.5771879553794861\n",
      "Epoch 17: train loss: 0.47247639298439026\n",
      "Epoch 17: train loss: 0.3501253128051758\n",
      "Epoch 17: train loss: 0.4663506746292114\n",
      "Epoch 17: train loss: 0.5535467267036438\n",
      "Epoch 17: train loss: 0.4658104181289673\n",
      "Epoch 17: train loss: 0.5271058082580566\n",
      "Epoch 17: train loss: 0.7151817083358765\n",
      "Epoch 17: train loss: 0.6607456207275391\n",
      "Epoch 17: train loss: 0.5545852780342102\n",
      "Epoch 17: train loss: 0.5035749077796936\n",
      "Epoch 17: train loss: 0.6572084426879883\n",
      "Epoch 17: train loss: 0.4632354974746704\n",
      "Epoch 17: train loss: 0.42628899216651917\n",
      "Epoch 17: train loss: 0.5042403340339661\n",
      "Epoch 17: train loss: 0.6775379180908203\n",
      "Epoch 17: train loss: 0.5492909550666809\n",
      "Epoch 17: train loss: 0.6125575304031372\n",
      "Epoch 17: train loss: 0.4987238645553589\n",
      "Epoch 17: train loss: 0.614493727684021\n",
      "Epoch 17: train loss: 0.49765777587890625\n",
      "Epoch 17: train loss: 0.5710843801498413\n",
      "Epoch 17: train loss: 0.5021864771842957\n",
      "Epoch 17: train loss: 0.5289990901947021\n",
      "Epoch 17: train loss: 0.633790910243988\n",
      "Epoch 17: train loss: 0.7109823822975159\n",
      "Epoch 17: train loss: 0.4277658760547638\n",
      "Epoch 17: train loss: 0.6317430734634399\n",
      "Epoch 17: train loss: 0.4669114947319031\n",
      "Epoch 17: train loss: 0.5443857908248901\n",
      "Epoch 17: train loss: 0.556224524974823\n",
      "Epoch 17: train loss: 0.5959343910217285\n",
      "Epoch 17: train loss: 0.4884845018386841\n",
      "Epoch 17: train loss: 0.5675442218780518\n",
      "Epoch 17: train loss: 0.49395105242729187\n",
      "Epoch 17: train loss: 0.5658360719680786\n",
      "Epoch 17: train loss: 0.5594167113304138\n",
      "Epoch 17: train loss: 0.3662894368171692\n",
      "Epoch 17: train loss: 0.6482488512992859\n",
      "Epoch 17: train loss: 0.5985150337219238\n",
      "Epoch 17: train loss: 0.6102638840675354\n",
      "Epoch 17: train loss: 0.4493781626224518\n",
      "Epoch 17: train loss: 0.5369362831115723\n",
      "Epoch 17: train loss: 0.5244724750518799\n",
      "Epoch 17: train loss: 0.7078043222427368\n",
      "Epoch 18: train loss: 0.5630196332931519\n",
      "Epoch 18: train loss: 0.5204369425773621\n",
      "Epoch 18: train loss: 0.5908443927764893\n",
      "Epoch 18: train loss: 0.6041824817657471\n",
      "Epoch 18: train loss: 0.5771257281303406\n",
      "Epoch 18: train loss: 0.5052723288536072\n",
      "Epoch 18: train loss: 0.42695459723472595\n",
      "Epoch 18: train loss: 0.4907973110675812\n",
      "Epoch 18: train loss: 0.7075483798980713\n",
      "Epoch 18: train loss: 0.6521945595741272\n",
      "Epoch 18: train loss: 0.4735376834869385\n",
      "Epoch 18: train loss: 0.5020496845245361\n",
      "Epoch 18: train loss: 0.464265376329422\n",
      "Epoch 18: train loss: 0.37658390402793884\n",
      "Epoch 18: train loss: 0.5239834189414978\n",
      "Epoch 18: train loss: 0.4809420108795166\n",
      "Epoch 18: train loss: 0.7580318450927734\n",
      "Epoch 18: train loss: 0.6123625040054321\n",
      "Epoch 18: train loss: 0.5028959512710571\n",
      "Epoch 18: train loss: 0.6136226058006287\n",
      "Epoch 18: train loss: 0.5696958303451538\n",
      "Epoch 18: train loss: 0.6498765349388123\n",
      "Epoch 18: train loss: 0.6193113327026367\n",
      "Epoch 18: train loss: 0.38114023208618164\n",
      "Epoch 18: train loss: 0.5727777481079102\n",
      "Epoch 18: train loss: 0.5187292098999023\n",
      "Epoch 18: train loss: 0.4515414237976074\n",
      "Epoch 18: train loss: 0.47683537006378174\n",
      "Epoch 18: train loss: 0.6603118181228638\n",
      "Epoch 18: train loss: 0.5008549094200134\n",
      "Epoch 18: train loss: 0.49909427762031555\n",
      "Epoch 18: train loss: 0.5244786739349365\n",
      "Epoch 18: train loss: 0.6160150766372681\n",
      "Epoch 18: train loss: 0.45192375779151917\n",
      "Epoch 18: train loss: 0.5549579858779907\n",
      "Epoch 18: train loss: 0.4218968451023102\n",
      "Epoch 18: train loss: 0.4905981719493866\n",
      "Epoch 18: train loss: 0.5630597472190857\n",
      "Epoch 18: train loss: 0.35592517256736755\n",
      "Epoch 18: train loss: 0.6638069748878479\n",
      "Epoch 18: train loss: 0.516311764717102\n",
      "Epoch 18: train loss: 0.5625663995742798\n",
      "Epoch 18: train loss: 0.5870816707611084\n",
      "Epoch 18: train loss: 0.4945903718471527\n",
      "Epoch 18: train loss: 0.5268468856811523\n",
      "Epoch 18: train loss: 0.5982652306556702\n",
      "Epoch 18: train loss: 0.5370451211929321\n",
      "Epoch 18: train loss: 0.5724393725395203\n",
      "Epoch 18: train loss: 0.49049413204193115\n",
      "Epoch 18: train loss: 0.6004939079284668\n",
      "Epoch 18: train loss: 0.5303215384483337\n",
      "Epoch 18: train loss: 0.477498859167099\n",
      "Epoch 18: train loss: 0.47312432527542114\n",
      "Epoch 18: train loss: 0.47144654393196106\n",
      "Epoch 18: train loss: 0.5312923192977905\n",
      "Epoch 18: train loss: 0.529666543006897\n",
      "Epoch 18: train loss: 0.6214269995689392\n",
      "Epoch 18: train loss: 0.5063096284866333\n",
      "Epoch 18: train loss: 0.7055156826972961\n",
      "Epoch 18: train loss: 0.37605980038642883\n",
      "Epoch 18: train loss: 0.5861719846725464\n",
      "Epoch 18: train loss: 0.49863994121551514\n",
      "Epoch 18: train loss: 0.5354220271110535\n",
      "Epoch 18: train loss: 0.5166673064231873\n",
      "Epoch 18: train loss: 0.5332826375961304\n",
      "Epoch 18: train loss: 0.542529284954071\n",
      "Epoch 18: train loss: 0.5904552936553955\n",
      "Epoch 18: train loss: 0.4998070299625397\n",
      "Epoch 18: train loss: 0.4952583909034729\n",
      "Epoch 18: train loss: 0.5552153587341309\n",
      "Epoch 18: train loss: 0.5219993591308594\n",
      "Epoch 18: train loss: 0.5381901860237122\n",
      "Epoch 18: train loss: 0.4372542202472687\n",
      "Epoch 18: train loss: 0.48104327917099\n",
      "Epoch 18: train loss: 0.40041786432266235\n",
      "Epoch 18: train loss: 0.5674809813499451\n",
      "Epoch 18: train loss: 0.6487693190574646\n",
      "Epoch 18: train loss: 0.6216912865638733\n",
      "Epoch 18: train loss: 0.49282166361808777\n",
      "Epoch 18: train loss: 0.5148205161094666\n",
      "Epoch 18: train loss: 0.4935610294342041\n",
      "Epoch 18: train loss: 0.5184282064437866\n",
      "Epoch 18: train loss: 0.42447325587272644\n",
      "Epoch 18: train loss: 0.5408731698989868\n",
      "Epoch 18: train loss: 0.4873240292072296\n",
      "Epoch 18: train loss: 0.5366483926773071\n",
      "Epoch 18: train loss: 0.518922746181488\n",
      "Epoch 18: train loss: 0.4130423963069916\n",
      "Epoch 18: train loss: 0.53025221824646\n",
      "Epoch 18: train loss: 0.6634009480476379\n",
      "Epoch 18: train loss: 0.5506235361099243\n",
      "Epoch 18: train loss: 0.7238462567329407\n",
      "Epoch 18: train loss: 0.5266035199165344\n",
      "Epoch 18: train loss: 0.45967695116996765\n",
      "Epoch 18: train loss: 0.4852723479270935\n",
      "Epoch 18: train loss: 0.6238994002342224\n",
      "Epoch 18: train loss: 0.4987506568431854\n",
      "Epoch 18: train loss: 0.5506156086921692\n",
      "Epoch 18: train loss: 0.6032909750938416\n",
      "Epoch 18: train loss: 0.4494270086288452\n",
      "Epoch 18: train loss: 0.8338363766670227\n",
      "Epoch 18: train loss: 0.5714384913444519\n",
      "Epoch 18: train loss: 0.7705517411231995\n",
      "Epoch 18: train loss: 0.5376032590866089\n",
      "Epoch 18: train loss: 0.6627107858657837\n",
      "Epoch 18: train loss: 0.4928763210773468\n",
      "Epoch 18: train loss: 0.44897517561912537\n",
      "Epoch 18: train loss: 0.5296380519866943\n",
      "Epoch 18: train loss: 0.6729918718338013\n",
      "Epoch 18: train loss: 0.6359125375747681\n",
      "Epoch 18: train loss: 0.5916242599487305\n",
      "Epoch 18: train loss: 0.5168837308883667\n",
      "Epoch 18: train loss: 0.3798772990703583\n",
      "Epoch 18: train loss: 0.5674911737442017\n",
      "Epoch 18: train loss: 0.6548442840576172\n",
      "Epoch 18: train loss: 0.6647391319274902\n",
      "Epoch 18: train loss: 0.5112517476081848\n",
      "Epoch 18: train loss: 0.4534950852394104\n",
      "Epoch 18: train loss: 0.5852444767951965\n",
      "Epoch 18: train loss: 0.4994507133960724\n",
      "Epoch 18: train loss: 0.5344429612159729\n",
      "Epoch 18: train loss: 0.5044636130332947\n",
      "Epoch 18: train loss: 0.44845107197761536\n",
      "Epoch 18: train loss: 0.4355705976486206\n",
      "Epoch 19: train loss: 0.7322759628295898\n",
      "Epoch 19: train loss: 0.5103419423103333\n",
      "Epoch 19: train loss: 0.4627605676651001\n",
      "Epoch 19: train loss: 0.6067522168159485\n",
      "Epoch 19: train loss: 0.6782364845275879\n",
      "Epoch 19: train loss: 0.46250101923942566\n",
      "Epoch 19: train loss: 0.5369482636451721\n",
      "Epoch 19: train loss: 0.5905211567878723\n",
      "Epoch 19: train loss: 0.560848593711853\n",
      "Epoch 19: train loss: 0.5604791641235352\n",
      "Epoch 19: train loss: 0.5785976648330688\n",
      "Epoch 19: train loss: 0.7009678483009338\n",
      "Epoch 19: train loss: 0.6371237635612488\n",
      "Epoch 19: train loss: 0.5593498349189758\n",
      "Epoch 19: train loss: 0.4986765682697296\n",
      "Epoch 19: train loss: 0.4355218708515167\n",
      "Epoch 19: train loss: 0.5400823354721069\n",
      "Epoch 19: train loss: 0.5647041201591492\n",
      "Epoch 19: train loss: 0.36896517872810364\n",
      "Epoch 19: train loss: 0.4935896694660187\n",
      "Epoch 19: train loss: 0.7347679734230042\n",
      "Epoch 19: train loss: 0.5684213638305664\n",
      "Epoch 19: train loss: 0.7260197997093201\n",
      "Epoch 19: train loss: 0.5691816210746765\n",
      "Epoch 19: train loss: 0.4799058735370636\n",
      "Epoch 19: train loss: 0.5894765257835388\n",
      "Epoch 19: train loss: 0.5725911259651184\n",
      "Epoch 19: train loss: 0.6592397093772888\n",
      "Epoch 19: train loss: 0.5239894986152649\n",
      "Epoch 19: train loss: 0.44181618094444275\n",
      "Epoch 19: train loss: 0.5126312375068665\n",
      "Epoch 19: train loss: 0.4229436218738556\n",
      "Epoch 19: train loss: 0.4718104302883148\n",
      "Epoch 19: train loss: 0.46617454290390015\n",
      "Epoch 19: train loss: 0.5420956015586853\n",
      "Epoch 19: train loss: 0.47830843925476074\n",
      "Epoch 19: train loss: 0.5342365503311157\n",
      "Epoch 19: train loss: 0.5780414342880249\n",
      "Epoch 19: train loss: 0.616849958896637\n",
      "Epoch 19: train loss: 0.519921064376831\n",
      "Epoch 19: train loss: 0.632401704788208\n",
      "Epoch 19: train loss: 0.5396085381507874\n",
      "Epoch 19: train loss: 0.43078869581222534\n",
      "Epoch 19: train loss: 0.3944852948188782\n",
      "Epoch 19: train loss: 0.6252604126930237\n",
      "Epoch 19: train loss: 0.5752153396606445\n",
      "Epoch 19: train loss: 0.49088624119758606\n",
      "Epoch 19: train loss: 0.6928446292877197\n",
      "Epoch 19: train loss: 0.39150097966194153\n",
      "Epoch 19: train loss: 0.6438413858413696\n",
      "Epoch 19: train loss: 0.5206368565559387\n",
      "Epoch 19: train loss: 0.4994218051433563\n",
      "Epoch 19: train loss: 0.5488048791885376\n",
      "Epoch 19: train loss: 0.49422577023506165\n",
      "Epoch 19: train loss: 0.5248368978500366\n",
      "Epoch 19: train loss: 0.5925298929214478\n",
      "Epoch 19: train loss: 0.6902720332145691\n",
      "Epoch 19: train loss: 0.528927206993103\n",
      "Epoch 19: train loss: 0.6096944808959961\n",
      "Epoch 19: train loss: 0.5886868834495544\n",
      "Epoch 19: train loss: 0.5416173338890076\n",
      "Epoch 19: train loss: 0.4626033306121826\n",
      "Epoch 19: train loss: 0.5364269614219666\n",
      "Epoch 19: train loss: 0.4001997113227844\n",
      "Epoch 19: train loss: 0.46440985798835754\n",
      "Epoch 19: train loss: 0.6408910751342773\n",
      "Epoch 19: train loss: 0.5262848734855652\n",
      "Epoch 19: train loss: 0.6255331039428711\n",
      "Epoch 19: train loss: 0.4415533244609833\n",
      "Epoch 19: train loss: 0.5440986156463623\n",
      "Epoch 19: train loss: 0.6486490368843079\n",
      "Epoch 19: train loss: 0.6690330505371094\n",
      "Epoch 19: train loss: 0.5411690473556519\n",
      "Epoch 19: train loss: 0.5101162791252136\n",
      "Epoch 19: train loss: 0.5790243744850159\n",
      "Epoch 19: train loss: 0.45972317457199097\n",
      "Epoch 19: train loss: 0.43053990602493286\n",
      "Epoch 19: train loss: 0.4823119640350342\n",
      "Epoch 19: train loss: 0.3710821866989136\n",
      "Epoch 19: train loss: 0.42234909534454346\n",
      "Epoch 19: train loss: 0.6289780735969543\n",
      "Epoch 19: train loss: 0.48331406712532043\n",
      "Epoch 19: train loss: 0.44583478569984436\n",
      "Epoch 19: train loss: 0.5156329870223999\n",
      "Epoch 19: train loss: 0.3734666109085083\n",
      "Epoch 19: train loss: 0.47600212693214417\n",
      "Epoch 19: train loss: 0.5061213374137878\n",
      "Epoch 19: train loss: 0.4210413992404938\n",
      "Epoch 19: train loss: 0.6130227446556091\n",
      "Epoch 19: train loss: 0.3806008994579315\n",
      "Epoch 19: train loss: 0.3504098653793335\n",
      "Epoch 19: train loss: 0.4372502863407135\n",
      "Epoch 19: train loss: 0.8452468514442444\n",
      "Epoch 19: train loss: 0.5746833086013794\n",
      "Epoch 19: train loss: 0.463891863822937\n",
      "Epoch 19: train loss: 0.596092939376831\n",
      "Epoch 19: train loss: 0.620834469795227\n",
      "Epoch 19: train loss: 0.5682244896888733\n",
      "Epoch 19: train loss: 0.6366406679153442\n",
      "Epoch 19: train loss: 0.6642207503318787\n",
      "Epoch 19: train loss: 0.5944899320602417\n",
      "Epoch 19: train loss: 0.2953815758228302\n",
      "Epoch 19: train loss: 0.46282488107681274\n",
      "Epoch 19: train loss: 0.43572941422462463\n",
      "Epoch 19: train loss: 0.5184939503669739\n",
      "Epoch 19: train loss: 0.5382924675941467\n",
      "Epoch 19: train loss: 0.7318196296691895\n",
      "Epoch 19: train loss: 0.5275800824165344\n",
      "Epoch 19: train loss: 0.7311255931854248\n",
      "Epoch 19: train loss: 0.6344020366668701\n",
      "Epoch 19: train loss: 0.48236963152885437\n",
      "Epoch 19: train loss: 0.5450496673583984\n",
      "Epoch 19: train loss: 0.480045884847641\n",
      "Epoch 19: train loss: 0.6287353038787842\n",
      "Epoch 19: train loss: 0.6020711660385132\n",
      "Epoch 19: train loss: 0.5315048098564148\n",
      "Epoch 19: train loss: 0.4933484196662903\n",
      "Epoch 19: train loss: 0.5448525547981262\n",
      "Epoch 19: train loss: 0.5267245173454285\n",
      "Epoch 19: train loss: 0.5144190788269043\n",
      "Epoch 19: train loss: 0.4485298991203308\n",
      "Epoch 19: train loss: 0.4834996461868286\n",
      "Epoch 19: train loss: 0.5406678318977356\n",
      "Epoch 19: train loss: 0.5087704062461853\n",
      "Epoch 20: train loss: 0.62961745262146\n",
      "Epoch 20: train loss: 0.5414035320281982\n",
      "Epoch 20: train loss: 0.46968233585357666\n",
      "Epoch 20: train loss: 0.482134073972702\n",
      "Epoch 20: train loss: 0.5460784435272217\n",
      "Epoch 20: train loss: 0.46270668506622314\n",
      "Epoch 20: train loss: 0.5447391867637634\n",
      "Epoch 20: train loss: 0.6296110153198242\n",
      "Epoch 20: train loss: 0.6364332437515259\n",
      "Epoch 20: train loss: 0.5458416938781738\n",
      "Epoch 20: train loss: 0.7284551858901978\n",
      "Epoch 20: train loss: 0.4766794741153717\n",
      "Epoch 20: train loss: 0.6360068321228027\n",
      "Epoch 20: train loss: 0.5265010595321655\n",
      "Epoch 20: train loss: 0.47374653816223145\n",
      "Epoch 20: train loss: 0.5377744436264038\n",
      "Epoch 20: train loss: 0.6105840802192688\n",
      "Epoch 20: train loss: 0.5468015670776367\n",
      "Epoch 20: train loss: 0.6532434225082397\n",
      "Epoch 20: train loss: 0.5228068232536316\n",
      "Epoch 20: train loss: 0.5739414095878601\n",
      "Epoch 20: train loss: 0.444821298122406\n",
      "Epoch 20: train loss: 0.5956427454948425\n",
      "Epoch 20: train loss: 0.48292243480682373\n",
      "Epoch 20: train loss: 0.4790624976158142\n",
      "Epoch 20: train loss: 0.5084426403045654\n",
      "Epoch 20: train loss: 0.6221083402633667\n",
      "Epoch 20: train loss: 0.5009493231773376\n",
      "Epoch 20: train loss: 0.5601411461830139\n",
      "Epoch 20: train loss: 0.5547511577606201\n",
      "Epoch 20: train loss: 0.5472381114959717\n",
      "Epoch 20: train loss: 0.6406264901161194\n",
      "Epoch 20: train loss: 0.5103331804275513\n",
      "Epoch 20: train loss: 0.5480061769485474\n",
      "Epoch 20: train loss: 0.5715711116790771\n",
      "Epoch 20: train loss: 0.6890009045600891\n",
      "Epoch 20: train loss: 0.340731143951416\n",
      "Epoch 20: train loss: 0.53521329164505\n",
      "Epoch 20: train loss: 0.4444924592971802\n",
      "Epoch 20: train loss: 0.5397475957870483\n",
      "Epoch 20: train loss: 0.5748845338821411\n",
      "Epoch 20: train loss: 0.6660444140434265\n",
      "Epoch 20: train loss: 0.3382393717765808\n",
      "Epoch 20: train loss: 0.48306262493133545\n",
      "Epoch 20: train loss: 0.5032483339309692\n",
      "Epoch 20: train loss: 0.5927621722221375\n",
      "Epoch 20: train loss: 0.6459535360336304\n",
      "Epoch 20: train loss: 0.43098896741867065\n",
      "Epoch 20: train loss: 0.5431264638900757\n",
      "Epoch 20: train loss: 0.4565292000770569\n",
      "Epoch 20: train loss: 0.47501832246780396\n",
      "Epoch 20: train loss: 0.6403546929359436\n",
      "Epoch 20: train loss: 0.5063059329986572\n",
      "Epoch 20: train loss: 0.5813764333724976\n",
      "Epoch 20: train loss: 0.4462776780128479\n",
      "Epoch 20: train loss: 0.5473845601081848\n",
      "Epoch 20: train loss: 0.47018885612487793\n",
      "Epoch 20: train loss: 0.4247249662876129\n",
      "Epoch 20: train loss: 0.4783419072628021\n",
      "Epoch 20: train loss: 0.5311955809593201\n",
      "Epoch 20: train loss: 0.5582916736602783\n",
      "Epoch 20: train loss: 0.5279947519302368\n",
      "Epoch 20: train loss: 0.6065388917922974\n",
      "Epoch 20: train loss: 0.5036229491233826\n",
      "Epoch 20: train loss: 0.5283721685409546\n",
      "Epoch 20: train loss: 0.46710509061813354\n",
      "Epoch 20: train loss: 0.5797560811042786\n",
      "Epoch 20: train loss: 0.5553941130638123\n",
      "Epoch 20: train loss: 0.466467022895813\n",
      "Epoch 20: train loss: 0.6066141724586487\n",
      "Epoch 20: train loss: 0.7970703840255737\n",
      "Epoch 20: train loss: 0.4234980344772339\n",
      "Epoch 20: train loss: 0.48488545417785645\n",
      "Epoch 20: train loss: 0.5412880778312683\n",
      "Epoch 20: train loss: 0.5491565465927124\n",
      "Epoch 20: train loss: 0.5231538414955139\n",
      "Epoch 20: train loss: 0.4901655912399292\n",
      "Epoch 20: train loss: 0.5049847960472107\n",
      "Epoch 20: train loss: 0.6468309760093689\n",
      "Epoch 20: train loss: 0.8401114344596863\n",
      "Epoch 20: train loss: 0.39979028701782227\n",
      "Epoch 20: train loss: 0.6112483143806458\n",
      "Epoch 20: train loss: 0.5018160939216614\n",
      "Epoch 20: train loss: 0.555265486240387\n",
      "Epoch 20: train loss: 0.5730456113815308\n",
      "Epoch 20: train loss: 0.5528790950775146\n",
      "Epoch 20: train loss: 0.49752724170684814\n",
      "Epoch 20: train loss: 0.4142443835735321\n",
      "Epoch 20: train loss: 0.6179683804512024\n",
      "Epoch 20: train loss: 0.43318596482276917\n",
      "Epoch 20: train loss: 0.5706480741500854\n",
      "Epoch 20: train loss: 0.49839502573013306\n",
      "Epoch 20: train loss: 0.5578485131263733\n",
      "Epoch 20: train loss: 0.6459071040153503\n",
      "Epoch 20: train loss: 0.5994201898574829\n",
      "Epoch 20: train loss: 0.43220585584640503\n",
      "Epoch 20: train loss: 0.5073080062866211\n",
      "Epoch 20: train loss: 0.5615002512931824\n",
      "Epoch 20: train loss: 0.5115583539009094\n",
      "Epoch 20: train loss: 0.4857698082923889\n",
      "Epoch 20: train loss: 0.5070570111274719\n",
      "Epoch 20: train loss: 0.5098156929016113\n",
      "Epoch 20: train loss: 0.6849749684333801\n",
      "Epoch 20: train loss: 0.6836566925048828\n",
      "Epoch 20: train loss: 0.5005089640617371\n",
      "Epoch 20: train loss: 0.5757970809936523\n",
      "Epoch 20: train loss: 0.5541324615478516\n",
      "Epoch 20: train loss: 0.49504920840263367\n",
      "Epoch 20: train loss: 0.7246472835540771\n",
      "Epoch 20: train loss: 0.5742176175117493\n",
      "Epoch 20: train loss: 0.6910204291343689\n",
      "Epoch 20: train loss: 0.6007940173149109\n",
      "Epoch 20: train loss: 0.6242657899856567\n",
      "Epoch 20: train loss: 0.5034890174865723\n",
      "Epoch 20: train loss: 0.42833200097084045\n",
      "Epoch 20: train loss: 0.5781061053276062\n",
      "Epoch 20: train loss: 0.5356555581092834\n",
      "Epoch 20: train loss: 0.463704913854599\n",
      "Epoch 20: train loss: 0.470834344625473\n",
      "Epoch 20: train loss: 0.4717228412628174\n",
      "Epoch 20: train loss: 0.4135894477367401\n",
      "Epoch 20: train loss: 0.4167976677417755\n",
      "Epoch 20: train loss: 0.5533303618431091\n",
      "Epoch 20: train loss: 0.5302731394767761\n",
      "Epoch 21: train loss: 0.45772865414619446\n",
      "Epoch 21: train loss: 0.41079288721084595\n",
      "Epoch 21: train loss: 0.49312248826026917\n",
      "Epoch 21: train loss: 0.6661509871482849\n",
      "Epoch 21: train loss: 0.6145113110542297\n",
      "Epoch 21: train loss: 0.5074535608291626\n",
      "Epoch 21: train loss: 0.5655592083930969\n",
      "Epoch 21: train loss: 0.5723797678947449\n",
      "Epoch 21: train loss: 0.7646216750144958\n",
      "Epoch 21: train loss: 0.5296497344970703\n",
      "Epoch 21: train loss: 0.5229931473731995\n",
      "Epoch 21: train loss: 0.3879004418849945\n",
      "Epoch 21: train loss: 0.6447698473930359\n",
      "Epoch 21: train loss: 0.5607311129570007\n",
      "Epoch 21: train loss: 0.4375811219215393\n",
      "Epoch 21: train loss: 0.5223454833030701\n",
      "Epoch 21: train loss: 0.5320019125938416\n",
      "Epoch 21: train loss: 0.5452736020088196\n",
      "Epoch 21: train loss: 0.35522788763046265\n",
      "Epoch 21: train loss: 0.6133684515953064\n",
      "Epoch 21: train loss: 0.6447949409484863\n",
      "Epoch 21: train loss: 0.47829562425613403\n",
      "Epoch 21: train loss: 0.5705768465995789\n",
      "Epoch 21: train loss: 0.519706130027771\n",
      "Epoch 21: train loss: 0.5496007204055786\n",
      "Epoch 21: train loss: 0.39200860261917114\n",
      "Epoch 21: train loss: 0.6923763155937195\n",
      "Epoch 21: train loss: 0.5424281358718872\n",
      "Epoch 21: train loss: 0.4187392592430115\n",
      "Epoch 21: train loss: 0.4720854163169861\n",
      "Epoch 21: train loss: 0.4304269552230835\n",
      "Epoch 21: train loss: 0.5726003646850586\n",
      "Epoch 21: train loss: 0.5598933100700378\n",
      "Epoch 21: train loss: 0.5000998377799988\n",
      "Epoch 21: train loss: 0.4739631116390228\n",
      "Epoch 21: train loss: 0.6315692067146301\n",
      "Epoch 21: train loss: 0.5347229242324829\n",
      "Epoch 21: train loss: 0.5398052930831909\n",
      "Epoch 21: train loss: 0.5766109824180603\n",
      "Epoch 21: train loss: 0.4436154067516327\n",
      "Epoch 21: train loss: 0.44246166944503784\n",
      "Epoch 21: train loss: 0.5633296966552734\n",
      "Epoch 21: train loss: 0.47382843494415283\n",
      "Epoch 21: train loss: 0.5268043279647827\n",
      "Epoch 21: train loss: 0.5455490350723267\n",
      "Epoch 21: train loss: 0.8028491735458374\n",
      "Epoch 21: train loss: 0.4317878484725952\n",
      "Epoch 21: train loss: 0.4445083737373352\n",
      "Epoch 21: train loss: 0.4573197364807129\n",
      "Epoch 21: train loss: 0.48414701223373413\n",
      "Epoch 21: train loss: 0.5342828035354614\n",
      "Epoch 21: train loss: 0.5897688269615173\n",
      "Epoch 21: train loss: 0.4175233840942383\n",
      "Epoch 21: train loss: 0.4158521592617035\n",
      "Epoch 21: train loss: 0.6883538961410522\n",
      "Epoch 21: train loss: 0.6496427059173584\n",
      "Epoch 21: train loss: 0.5267292857170105\n",
      "Epoch 21: train loss: 0.47275611758232117\n",
      "Epoch 21: train loss: 0.5357537269592285\n",
      "Epoch 21: train loss: 0.6225124001502991\n",
      "Epoch 21: train loss: 0.5426102876663208\n",
      "Epoch 21: train loss: 0.49232056736946106\n",
      "Epoch 21: train loss: 0.5558470487594604\n",
      "Epoch 21: train loss: 0.4596436023712158\n",
      "Epoch 21: train loss: 0.3913452625274658\n",
      "Epoch 21: train loss: 0.5153288245201111\n",
      "Epoch 21: train loss: 0.5173116326332092\n",
      "Epoch 21: train loss: 0.5776247978210449\n",
      "Epoch 21: train loss: 0.40687623620033264\n",
      "Epoch 21: train loss: 0.5103690028190613\n",
      "Epoch 21: train loss: 0.359478235244751\n",
      "Epoch 21: train loss: 0.4419105350971222\n",
      "Epoch 21: train loss: 0.6526055335998535\n",
      "Epoch 21: train loss: 0.4696997106075287\n",
      "Epoch 21: train loss: 0.5339950323104858\n",
      "Epoch 21: train loss: 0.6141539812088013\n",
      "Epoch 21: train loss: 0.4856332540512085\n",
      "Epoch 21: train loss: 0.5434088706970215\n",
      "Epoch 21: train loss: 0.7460117340087891\n",
      "Epoch 21: train loss: 0.5057606101036072\n",
      "Epoch 21: train loss: 0.5076870322227478\n",
      "Epoch 21: train loss: 0.5223017930984497\n",
      "Epoch 21: train loss: 0.5384507775306702\n",
      "Epoch 21: train loss: 0.48126092553138733\n",
      "Epoch 21: train loss: 0.570501983165741\n",
      "Epoch 21: train loss: 0.4506562352180481\n",
      "Epoch 21: train loss: 0.5903502702713013\n",
      "Epoch 21: train loss: 0.5165874361991882\n",
      "Epoch 21: train loss: 0.5769135355949402\n",
      "Epoch 21: train loss: 0.6603823304176331\n",
      "Epoch 21: train loss: 0.5367916822433472\n",
      "Epoch 21: train loss: 0.4437427520751953\n",
      "Epoch 21: train loss: 0.5512312054634094\n",
      "Epoch 21: train loss: 0.529840350151062\n",
      "Epoch 21: train loss: 0.6038618683815002\n",
      "Epoch 21: train loss: 0.5201454758644104\n",
      "Epoch 21: train loss: 0.5543041229248047\n",
      "Epoch 21: train loss: 0.6123975515365601\n",
      "Epoch 21: train loss: 0.5325913429260254\n",
      "Epoch 21: train loss: 0.5652515888214111\n",
      "Epoch 21: train loss: 0.5971550345420837\n",
      "Epoch 21: train loss: 0.6984423398971558\n",
      "Epoch 21: train loss: 0.5013992786407471\n",
      "Epoch 21: train loss: 0.4973662197589874\n",
      "Epoch 21: train loss: 0.6954345703125\n",
      "Epoch 21: train loss: 0.6208116412162781\n",
      "Epoch 21: train loss: 0.6752928495407104\n",
      "Epoch 21: train loss: 0.5243653059005737\n",
      "Epoch 21: train loss: 0.6835963726043701\n",
      "Epoch 21: train loss: 0.5083072781562805\n",
      "Epoch 21: train loss: 0.5089995861053467\n",
      "Epoch 21: train loss: 0.6876764297485352\n",
      "Epoch 21: train loss: 0.5535122752189636\n",
      "Epoch 21: train loss: 0.5909042954444885\n",
      "Epoch 21: train loss: 0.5389469265937805\n",
      "Epoch 21: train loss: 0.6796056628227234\n",
      "Epoch 21: train loss: 0.5854200124740601\n",
      "Epoch 21: train loss: 0.7588147521018982\n",
      "Epoch 21: train loss: 0.5321519374847412\n",
      "Epoch 21: train loss: 0.4809389114379883\n",
      "Epoch 21: train loss: 0.5030035972595215\n",
      "Epoch 21: train loss: 0.5533103942871094\n",
      "Epoch 21: train loss: 0.5724184513092041\n",
      "Epoch 21: train loss: 0.4808587431907654\n",
      "Epoch 22: train loss: 0.49140673875808716\n",
      "Epoch 22: train loss: 0.539703369140625\n",
      "Epoch 22: train loss: 0.5322859287261963\n",
      "Epoch 22: train loss: 0.5598123073577881\n",
      "Epoch 22: train loss: 0.40856751799583435\n",
      "Epoch 22: train loss: 0.6522364616394043\n",
      "Epoch 22: train loss: 0.6387431025505066\n",
      "Epoch 22: train loss: 0.471870481967926\n",
      "Epoch 22: train loss: 0.5185856223106384\n",
      "Epoch 22: train loss: 0.6461039781570435\n",
      "Epoch 22: train loss: 0.5531184673309326\n",
      "Epoch 22: train loss: 0.5169018507003784\n",
      "Epoch 22: train loss: 0.5558302402496338\n",
      "Epoch 22: train loss: 0.37748274207115173\n",
      "Epoch 22: train loss: 0.4873577058315277\n",
      "Epoch 22: train loss: 0.5876616835594177\n",
      "Epoch 22: train loss: 0.5249977111816406\n",
      "Epoch 22: train loss: 0.620834469795227\n",
      "Epoch 22: train loss: 0.42344653606414795\n",
      "Epoch 22: train loss: 0.5259937047958374\n",
      "Epoch 22: train loss: 0.5314680337905884\n",
      "Epoch 22: train loss: 0.6107620596885681\n",
      "Epoch 22: train loss: 0.5965811014175415\n",
      "Epoch 22: train loss: 0.5005912184715271\n",
      "Epoch 22: train loss: 0.4309394061565399\n",
      "Epoch 22: train loss: 0.569596529006958\n",
      "Epoch 22: train loss: 0.7305338978767395\n",
      "Epoch 22: train loss: 0.5071007013320923\n",
      "Epoch 22: train loss: 0.5163174867630005\n",
      "Epoch 22: train loss: 0.4405713677406311\n",
      "Epoch 22: train loss: 0.49966126680374146\n",
      "Epoch 22: train loss: 0.6086810231208801\n",
      "Epoch 22: train loss: 0.5857173800468445\n",
      "Epoch 22: train loss: 0.8274657726287842\n",
      "Epoch 22: train loss: 0.4016232192516327\n",
      "Epoch 22: train loss: 0.5586589574813843\n",
      "Epoch 22: train loss: 0.6153412461280823\n",
      "Epoch 22: train loss: 0.5670141577720642\n",
      "Epoch 22: train loss: 0.6151878833770752\n",
      "Epoch 22: train loss: 0.474996417760849\n",
      "Epoch 22: train loss: 0.4721772372722626\n",
      "Epoch 22: train loss: 0.5306560397148132\n",
      "Epoch 22: train loss: 0.393375039100647\n",
      "Epoch 22: train loss: 0.5192998051643372\n",
      "Epoch 22: train loss: 0.48975709080696106\n",
      "Epoch 22: train loss: 0.40986454486846924\n",
      "Epoch 22: train loss: 0.645808756351471\n",
      "Epoch 22: train loss: 0.46498289704322815\n",
      "Epoch 22: train loss: 0.5550413727760315\n",
      "Epoch 22: train loss: 0.6351572871208191\n",
      "Epoch 22: train loss: 0.4335497319698334\n",
      "Epoch 22: train loss: 0.5275208950042725\n",
      "Epoch 22: train loss: 0.6272725462913513\n",
      "Epoch 22: train loss: 0.5645532608032227\n",
      "Epoch 22: train loss: 0.4554694890975952\n",
      "Epoch 22: train loss: 0.5937735438346863\n",
      "Epoch 22: train loss: 0.5748644471168518\n",
      "Epoch 22: train loss: 0.5351951122283936\n",
      "Epoch 22: train loss: 0.5349470376968384\n",
      "Epoch 22: train loss: 0.7102068066596985\n",
      "Epoch 22: train loss: 0.49810275435447693\n",
      "Epoch 22: train loss: 0.5547746419906616\n",
      "Epoch 22: train loss: 0.48301810026168823\n",
      "Epoch 22: train loss: 0.3646146357059479\n",
      "Epoch 22: train loss: 0.47663941979408264\n",
      "Epoch 22: train loss: 0.4233596622943878\n",
      "Epoch 22: train loss: 0.5573954582214355\n",
      "Epoch 22: train loss: 0.6698722839355469\n",
      "Epoch 22: train loss: 0.599043071269989\n",
      "Epoch 22: train loss: 0.42816048860549927\n",
      "Epoch 22: train loss: 0.5583711266517639\n",
      "Epoch 22: train loss: 0.49471908807754517\n",
      "Epoch 22: train loss: 0.5298948884010315\n",
      "Epoch 22: train loss: 0.7328411340713501\n",
      "Epoch 22: train loss: 0.5736697316169739\n",
      "Epoch 22: train loss: 0.6301649212837219\n",
      "Epoch 22: train loss: 0.5375046133995056\n",
      "Epoch 22: train loss: 0.5653984546661377\n",
      "Epoch 22: train loss: 0.6822806596755981\n",
      "Epoch 22: train loss: 0.44520118832588196\n",
      "Epoch 22: train loss: 0.4762278199195862\n",
      "Epoch 22: train loss: 0.6041244864463806\n",
      "Epoch 22: train loss: 0.611731767654419\n",
      "Epoch 22: train loss: 0.6374688744544983\n",
      "Epoch 22: train loss: 0.470705509185791\n",
      "Epoch 22: train loss: 0.5951293110847473\n",
      "Epoch 22: train loss: 0.5432403087615967\n",
      "Epoch 22: train loss: 0.5593356490135193\n",
      "Epoch 22: train loss: 0.3933449983596802\n",
      "Epoch 22: train loss: 0.4683915674686432\n",
      "Epoch 22: train loss: 0.5419736504554749\n",
      "Epoch 22: train loss: 0.49192580580711365\n",
      "Epoch 22: train loss: 0.6204041242599487\n",
      "Epoch 22: train loss: 0.533943772315979\n",
      "Epoch 22: train loss: 0.6171320676803589\n",
      "Epoch 22: train loss: 0.5653311014175415\n",
      "Epoch 22: train loss: 0.3184010684490204\n",
      "Epoch 22: train loss: 0.6583328247070312\n",
      "Epoch 22: train loss: 0.3852802813053131\n",
      "Epoch 22: train loss: 0.4433731138706207\n",
      "Epoch 22: train loss: 0.5182528495788574\n",
      "Epoch 22: train loss: 0.47779160737991333\n",
      "Epoch 22: train loss: 0.616036057472229\n",
      "Epoch 22: train loss: 0.48590388894081116\n",
      "Epoch 22: train loss: 0.46599143743515015\n",
      "Epoch 22: train loss: 0.628157377243042\n",
      "Epoch 22: train loss: 0.351827472448349\n",
      "Epoch 22: train loss: 0.5665615797042847\n",
      "Epoch 22: train loss: 0.585037887096405\n",
      "Epoch 22: train loss: 0.6283106207847595\n",
      "Epoch 22: train loss: 0.465505987405777\n",
      "Epoch 22: train loss: 0.5286648273468018\n",
      "Epoch 22: train loss: 0.47464340925216675\n",
      "Epoch 22: train loss: 0.6802289485931396\n",
      "Epoch 22: train loss: 0.5558723211288452\n",
      "Epoch 22: train loss: 0.48782801628112793\n",
      "Epoch 22: train loss: 0.6051310300827026\n",
      "Epoch 22: train loss: 0.5780498385429382\n",
      "Epoch 22: train loss: 0.5596288442611694\n",
      "Epoch 22: train loss: 0.6354905962944031\n",
      "Epoch 22: train loss: 0.529818594455719\n",
      "Epoch 22: train loss: 0.671051561832428\n",
      "Epoch 22: train loss: 0.598377525806427\n",
      "Epoch 22: train loss: 0.3474317193031311\n",
      "Epoch 23: train loss: 0.49042198061943054\n",
      "Epoch 23: train loss: 0.33306121826171875\n",
      "Epoch 23: train loss: 0.5058138966560364\n",
      "Epoch 23: train loss: 0.4975253939628601\n",
      "Epoch 23: train loss: 0.4766395688056946\n",
      "Epoch 23: train loss: 0.5700087547302246\n",
      "Epoch 23: train loss: 0.5287111401557922\n",
      "Epoch 23: train loss: 0.5896074175834656\n",
      "Epoch 23: train loss: 0.5986948013305664\n",
      "Epoch 23: train loss: 0.5797653794288635\n",
      "Epoch 23: train loss: 0.437224417924881\n",
      "Epoch 23: train loss: 0.4695364236831665\n",
      "Epoch 23: train loss: 0.5296393632888794\n",
      "Epoch 23: train loss: 0.5195596814155579\n",
      "Epoch 23: train loss: 0.5609307885169983\n",
      "Epoch 23: train loss: 0.582339346408844\n",
      "Epoch 23: train loss: 0.6373989582061768\n",
      "Epoch 23: train loss: 0.4171641170978546\n",
      "Epoch 23: train loss: 0.345643013715744\n",
      "Epoch 23: train loss: 0.5722270607948303\n",
      "Epoch 23: train loss: 0.5795068740844727\n",
      "Epoch 23: train loss: 0.6992344260215759\n",
      "Epoch 23: train loss: 0.44909045100212097\n",
      "Epoch 23: train loss: 0.5106384754180908\n",
      "Epoch 23: train loss: 0.40436282753944397\n",
      "Epoch 23: train loss: 0.5541996359825134\n",
      "Epoch 23: train loss: 0.5577983260154724\n",
      "Epoch 23: train loss: 0.7176048755645752\n",
      "Epoch 23: train loss: 0.3323943018913269\n",
      "Epoch 23: train loss: 0.5019303560256958\n",
      "Epoch 23: train loss: 0.5008239150047302\n",
      "Epoch 23: train loss: 0.5081071257591248\n",
      "Epoch 23: train loss: 0.4107823073863983\n",
      "Epoch 23: train loss: 0.516665518283844\n",
      "Epoch 23: train loss: 0.6790003776550293\n",
      "Epoch 23: train loss: 0.5083746314048767\n",
      "Epoch 23: train loss: 0.7185298204421997\n",
      "Epoch 23: train loss: 0.5491651296615601\n",
      "Epoch 23: train loss: 0.47983095049858093\n",
      "Epoch 23: train loss: 0.3653288781642914\n",
      "Epoch 23: train loss: 0.6699381470680237\n",
      "Epoch 23: train loss: 0.6563817858695984\n",
      "Epoch 23: train loss: 0.4905702471733093\n",
      "Epoch 23: train loss: 0.5234696269035339\n",
      "Epoch 23: train loss: 0.48484721779823303\n",
      "Epoch 23: train loss: 0.4924945831298828\n",
      "Epoch 23: train loss: 0.5749090909957886\n",
      "Epoch 23: train loss: 0.5756065249443054\n",
      "Epoch 23: train loss: 0.6898033022880554\n",
      "Epoch 23: train loss: 0.5877156853675842\n",
      "Epoch 23: train loss: 0.5447945594787598\n",
      "Epoch 23: train loss: 0.6012603044509888\n",
      "Epoch 23: train loss: 0.47472038865089417\n",
      "Epoch 23: train loss: 0.5148470997810364\n",
      "Epoch 23: train loss: 0.536085307598114\n",
      "Epoch 23: train loss: 0.6696527004241943\n",
      "Epoch 23: train loss: 0.43286657333374023\n",
      "Epoch 23: train loss: 0.6526759266853333\n",
      "Epoch 23: train loss: 0.4211515188217163\n",
      "Epoch 23: train loss: 0.6252003312110901\n",
      "Epoch 23: train loss: 0.47327542304992676\n",
      "Epoch 23: train loss: 0.4429931640625\n",
      "Epoch 23: train loss: 0.5336554646492004\n",
      "Epoch 23: train loss: 0.5991679430007935\n",
      "Epoch 23: train loss: 0.6112716794013977\n",
      "Epoch 23: train loss: 0.4833420217037201\n",
      "Epoch 23: train loss: 0.4080646336078644\n",
      "Epoch 23: train loss: 0.5660139918327332\n",
      "Epoch 23: train loss: 0.6125795841217041\n",
      "Epoch 23: train loss: 0.5056334733963013\n",
      "Epoch 23: train loss: 0.6350676417350769\n",
      "Epoch 23: train loss: 0.6909201741218567\n",
      "Epoch 23: train loss: 0.493330180644989\n",
      "Epoch 23: train loss: 0.6090182065963745\n",
      "Epoch 23: train loss: 0.4980034828186035\n",
      "Epoch 23: train loss: 0.40429607033729553\n",
      "Epoch 23: train loss: 0.42781129479408264\n",
      "Epoch 23: train loss: 0.5607744455337524\n",
      "Epoch 23: train loss: 0.5835381150245667\n",
      "Epoch 23: train loss: 0.6674373149871826\n",
      "Epoch 23: train loss: 0.6931283473968506\n",
      "Epoch 23: train loss: 0.4946090877056122\n",
      "Epoch 23: train loss: 0.6592822670936584\n",
      "Epoch 23: train loss: 0.46423450112342834\n",
      "Epoch 23: train loss: 0.5356912016868591\n",
      "Epoch 23: train loss: 0.587556779384613\n",
      "Epoch 23: train loss: 0.5166963934898376\n",
      "Epoch 23: train loss: 0.6044986248016357\n",
      "Epoch 23: train loss: 0.547073245048523\n",
      "Epoch 23: train loss: 0.5853427052497864\n",
      "Epoch 23: train loss: 0.503409206867218\n",
      "Epoch 23: train loss: 0.5826411247253418\n",
      "Epoch 23: train loss: 0.3953687250614166\n",
      "Epoch 23: train loss: 0.46917247772216797\n",
      "Epoch 23: train loss: 0.5310253500938416\n",
      "Epoch 23: train loss: 0.6308097243309021\n",
      "Epoch 23: train loss: 0.47576087713241577\n",
      "Epoch 23: train loss: 0.5859195590019226\n",
      "Epoch 23: train loss: 0.4834117591381073\n",
      "Epoch 23: train loss: 0.6941471695899963\n",
      "Epoch 23: train loss: 0.5702670812606812\n",
      "Epoch 23: train loss: 0.5176969170570374\n",
      "Epoch 23: train loss: 0.4830808639526367\n",
      "Epoch 23: train loss: 0.628998875617981\n",
      "Epoch 23: train loss: 0.5334389209747314\n",
      "Epoch 23: train loss: 0.42524757981300354\n",
      "Epoch 23: train loss: 0.6096855401992798\n",
      "Epoch 23: train loss: 0.42284294962882996\n",
      "Epoch 23: train loss: 0.5581923127174377\n",
      "Epoch 23: train loss: 0.4699123203754425\n",
      "Epoch 23: train loss: 0.4496687948703766\n",
      "Epoch 23: train loss: 0.5828229784965515\n",
      "Epoch 23: train loss: 0.5284275412559509\n",
      "Epoch 23: train loss: 0.4961538016796112\n",
      "Epoch 23: train loss: 0.5557717680931091\n",
      "Epoch 23: train loss: 0.5347941517829895\n",
      "Epoch 23: train loss: 0.49072739481925964\n",
      "Epoch 23: train loss: 0.6590517163276672\n",
      "Epoch 23: train loss: 0.43287572264671326\n",
      "Epoch 23: train loss: 0.5333970785140991\n",
      "Epoch 23: train loss: 0.5926144123077393\n",
      "Epoch 23: train loss: 0.5642625689506531\n",
      "Epoch 23: train loss: 0.5772662162780762\n",
      "Epoch 23: train loss: 0.7046162486076355\n",
      "Epoch 24: train loss: 0.5819389820098877\n",
      "Epoch 24: train loss: 0.6440665125846863\n",
      "Epoch 24: train loss: 0.4851856827735901\n",
      "Epoch 24: train loss: 0.5906596779823303\n",
      "Epoch 24: train loss: 0.5870692729949951\n",
      "Epoch 24: train loss: 0.6240550875663757\n",
      "Epoch 24: train loss: 0.5894233584403992\n",
      "Epoch 24: train loss: 0.5013720989227295\n",
      "Epoch 24: train loss: 0.6019152402877808\n",
      "Epoch 24: train loss: 0.5030651688575745\n",
      "Epoch 24: train loss: 0.5939919948577881\n",
      "Epoch 24: train loss: 0.5357269048690796\n",
      "Epoch 24: train loss: 0.553491473197937\n",
      "Epoch 24: train loss: 0.618216872215271\n",
      "Epoch 24: train loss: 0.4730738699436188\n",
      "Epoch 24: train loss: 0.42359673976898193\n",
      "Epoch 24: train loss: 0.4022272825241089\n",
      "Epoch 24: train loss: 0.647152304649353\n",
      "Epoch 24: train loss: 0.6169238090515137\n",
      "Epoch 24: train loss: 0.6043410897254944\n",
      "Epoch 24: train loss: 0.570233166217804\n",
      "Epoch 24: train loss: 0.5414609313011169\n",
      "Epoch 24: train loss: 0.4309707283973694\n",
      "Epoch 24: train loss: 0.5065951347351074\n",
      "Epoch 24: train loss: 0.5340630412101746\n",
      "Epoch 24: train loss: 0.5542051792144775\n",
      "Epoch 24: train loss: 0.5126184821128845\n",
      "Epoch 24: train loss: 0.4976876676082611\n",
      "Epoch 24: train loss: 0.6977651715278625\n",
      "Epoch 24: train loss: 0.4659045934677124\n",
      "Epoch 24: train loss: 0.5874997973442078\n",
      "Epoch 24: train loss: 0.6254763007164001\n",
      "Epoch 24: train loss: 0.46847397089004517\n",
      "Epoch 24: train loss: 0.6014058589935303\n",
      "Epoch 24: train loss: 0.43380847573280334\n",
      "Epoch 24: train loss: 0.4633522927761078\n",
      "Epoch 24: train loss: 0.602043628692627\n",
      "Epoch 24: train loss: 0.5509356260299683\n",
      "Epoch 24: train loss: 0.42644864320755005\n",
      "Epoch 24: train loss: 0.5485200881958008\n",
      "Epoch 24: train loss: 0.717494010925293\n",
      "Epoch 24: train loss: 0.4888553321361542\n",
      "Epoch 24: train loss: 0.4683813452720642\n",
      "Epoch 24: train loss: 0.568061351776123\n",
      "Epoch 24: train loss: 0.3980855643749237\n",
      "Epoch 24: train loss: 0.5142871737480164\n",
      "Epoch 24: train loss: 0.6062173247337341\n",
      "Epoch 24: train loss: 0.5905170440673828\n",
      "Epoch 24: train loss: 0.4892982244491577\n",
      "Epoch 24: train loss: 0.6017045974731445\n",
      "Epoch 24: train loss: 0.6456671953201294\n",
      "Epoch 24: train loss: 0.4572596549987793\n",
      "Epoch 24: train loss: 0.5880979895591736\n",
      "Epoch 24: train loss: 0.523124635219574\n",
      "Epoch 24: train loss: 0.5772596597671509\n",
      "Epoch 24: train loss: 0.49480804800987244\n",
      "Epoch 24: train loss: 0.40890318155288696\n",
      "Epoch 24: train loss: 0.4751724302768707\n",
      "Epoch 24: train loss: 0.5212662220001221\n",
      "Epoch 24: train loss: 0.8490625023841858\n",
      "Epoch 24: train loss: 0.4785470962524414\n",
      "Epoch 24: train loss: 0.5733070969581604\n",
      "Epoch 24: train loss: 0.4824731945991516\n",
      "Epoch 24: train loss: 0.5169038772583008\n",
      "Epoch 24: train loss: 0.4780718684196472\n",
      "Epoch 24: train loss: 0.6701537370681763\n",
      "Epoch 24: train loss: 0.45245271921157837\n",
      "Epoch 24: train loss: 0.5781320333480835\n",
      "Epoch 24: train loss: 0.35145071148872375\n",
      "Epoch 24: train loss: 0.9417340159416199\n",
      "Epoch 24: train loss: 0.5065434575080872\n",
      "Epoch 24: train loss: 0.5054244995117188\n",
      "Epoch 24: train loss: 0.7475588321685791\n",
      "Epoch 24: train loss: 0.46346497535705566\n",
      "Epoch 24: train loss: 0.4570513367652893\n",
      "Epoch 24: train loss: 0.4924330413341522\n",
      "Epoch 24: train loss: 0.5230763554573059\n",
      "Epoch 24: train loss: 0.4989164471626282\n",
      "Epoch 24: train loss: 0.49524006247520447\n",
      "Epoch 24: train loss: 0.5148204565048218\n",
      "Epoch 24: train loss: 0.43295860290527344\n",
      "Epoch 24: train loss: 0.42306870222091675\n",
      "Epoch 24: train loss: 0.3951338827610016\n",
      "Epoch 24: train loss: 0.5608206391334534\n",
      "Epoch 24: train loss: 0.49731236696243286\n",
      "Epoch 24: train loss: 0.5635967254638672\n",
      "Epoch 24: train loss: 0.4226997494697571\n",
      "Epoch 24: train loss: 0.5882217884063721\n",
      "Epoch 24: train loss: 0.5598135590553284\n",
      "Epoch 24: train loss: 0.3299356997013092\n",
      "Epoch 24: train loss: 0.5635331869125366\n",
      "Epoch 24: train loss: 0.4868148863315582\n",
      "Epoch 24: train loss: 0.49122709035873413\n",
      "Epoch 24: train loss: 0.5508268475532532\n",
      "Epoch 24: train loss: 0.513274610042572\n",
      "Epoch 24: train loss: 0.44263461232185364\n",
      "Epoch 24: train loss: 0.6540333032608032\n",
      "Epoch 24: train loss: 0.4057506024837494\n",
      "Epoch 24: train loss: 0.46455860137939453\n",
      "Epoch 24: train loss: 0.6377289891242981\n",
      "Epoch 24: train loss: 0.4787115752696991\n",
      "Epoch 24: train loss: 0.5973905920982361\n",
      "Epoch 24: train loss: 0.4277028441429138\n",
      "Epoch 24: train loss: 0.45306918025016785\n",
      "Epoch 24: train loss: 0.53388512134552\n",
      "Epoch 24: train loss: 0.4685932695865631\n",
      "Epoch 24: train loss: 0.5922975540161133\n",
      "Epoch 24: train loss: 0.4721616208553314\n",
      "Epoch 24: train loss: 0.4825209677219391\n",
      "Epoch 24: train loss: 0.7304620146751404\n",
      "Epoch 24: train loss: 0.6167188286781311\n",
      "Epoch 24: train loss: 0.5387927889823914\n",
      "Epoch 24: train loss: 0.6206852793693542\n",
      "Epoch 24: train loss: 0.3832930028438568\n",
      "Epoch 24: train loss: 0.6728227734565735\n",
      "Epoch 24: train loss: 0.5458882451057434\n",
      "Epoch 24: train loss: 0.535881757736206\n",
      "Epoch 24: train loss: 0.7301526069641113\n",
      "Epoch 24: train loss: 0.4986751675605774\n",
      "Epoch 24: train loss: 0.5530145764350891\n",
      "Epoch 24: train loss: 0.5468514561653137\n",
      "Epoch 24: train loss: 0.6603901982307434\n",
      "Epoch 24: train loss: 0.5185537934303284\n",
      "Epoch 24: train loss: 0.5966855883598328\n",
      "Epoch 25: train loss: 0.4843136668205261\n",
      "Epoch 25: train loss: 0.6107310056686401\n",
      "Epoch 25: train loss: 0.4776272475719452\n",
      "Epoch 25: train loss: 0.47935596108436584\n",
      "Epoch 25: train loss: 0.583049476146698\n",
      "Epoch 25: train loss: 0.6102821230888367\n",
      "Epoch 25: train loss: 0.6892825365066528\n",
      "Epoch 25: train loss: 0.5672780871391296\n",
      "Epoch 25: train loss: 0.5265634059906006\n",
      "Epoch 25: train loss: 0.63045334815979\n",
      "Epoch 25: train loss: 0.5705520510673523\n",
      "Epoch 25: train loss: 0.48278817534446716\n",
      "Epoch 25: train loss: 0.5180641412734985\n",
      "Epoch 25: train loss: 0.5768007636070251\n",
      "Epoch 25: train loss: 0.6307089924812317\n",
      "Epoch 25: train loss: 0.5856931805610657\n",
      "Epoch 25: train loss: 0.4876514673233032\n",
      "Epoch 25: train loss: 0.5723023414611816\n",
      "Epoch 25: train loss: 0.5125357508659363\n",
      "Epoch 25: train loss: 0.6015326976776123\n",
      "Epoch 25: train loss: 0.5156044363975525\n",
      "Epoch 25: train loss: 0.46829187870025635\n",
      "Epoch 25: train loss: 0.5035245418548584\n",
      "Epoch 25: train loss: 0.5665422677993774\n",
      "Epoch 25: train loss: 0.4572882354259491\n",
      "Epoch 25: train loss: 0.41071099042892456\n",
      "Epoch 25: train loss: 0.6291148662567139\n",
      "Epoch 25: train loss: 0.5467353463172913\n",
      "Epoch 25: train loss: 0.46792274713516235\n",
      "Epoch 25: train loss: 0.47891926765441895\n",
      "Epoch 25: train loss: 0.5142868757247925\n",
      "Epoch 25: train loss: 0.5619221925735474\n",
      "Epoch 25: train loss: 0.5246683359146118\n",
      "Epoch 25: train loss: 0.38199418783187866\n",
      "Epoch 25: train loss: 0.5791603922843933\n",
      "Epoch 25: train loss: 0.4238036572933197\n",
      "Epoch 25: train loss: 0.5662407875061035\n",
      "Epoch 25: train loss: 0.6998966336250305\n",
      "Epoch 25: train loss: 0.5344211459159851\n",
      "Epoch 25: train loss: 0.45914795994758606\n",
      "Epoch 25: train loss: 0.5659791827201843\n",
      "Epoch 25: train loss: 0.5391098260879517\n",
      "Epoch 25: train loss: 0.36143144965171814\n",
      "Epoch 25: train loss: 0.6626601219177246\n",
      "Epoch 25: train loss: 0.6661532521247864\n",
      "Epoch 25: train loss: 0.5556711554527283\n",
      "Epoch 25: train loss: 0.5251292586326599\n",
      "Epoch 25: train loss: 0.47269946336746216\n",
      "Epoch 25: train loss: 0.36746665835380554\n",
      "Epoch 25: train loss: 0.5691903233528137\n",
      "Epoch 25: train loss: 0.44796493649482727\n",
      "Epoch 25: train loss: 0.5087324380874634\n",
      "Epoch 25: train loss: 0.563105046749115\n",
      "Epoch 25: train loss: 0.5050603151321411\n",
      "Epoch 25: train loss: 0.5642932653427124\n",
      "Epoch 25: train loss: 0.4250350892543793\n",
      "Epoch 25: train loss: 0.42905983328819275\n",
      "Epoch 25: train loss: 0.5626512765884399\n",
      "Epoch 25: train loss: 0.37221208214759827\n",
      "Epoch 25: train loss: 0.42851173877716064\n",
      "Epoch 25: train loss: 0.45708706974983215\n",
      "Epoch 25: train loss: 0.48076415061950684\n",
      "Epoch 25: train loss: 0.6617677807807922\n",
      "Epoch 25: train loss: 0.38876476883888245\n",
      "Epoch 25: train loss: 0.5878432989120483\n",
      "Epoch 25: train loss: 0.37235313653945923\n",
      "Epoch 25: train loss: 0.7459793090820312\n",
      "Epoch 25: train loss: 0.43370696902275085\n",
      "Epoch 25: train loss: 0.4262811243534088\n",
      "Epoch 25: train loss: 0.5129875540733337\n",
      "Epoch 25: train loss: 0.7145505547523499\n",
      "Epoch 25: train loss: 0.5966776609420776\n",
      "Epoch 25: train loss: 0.5265681743621826\n",
      "Epoch 25: train loss: 0.4720143675804138\n",
      "Epoch 25: train loss: 0.4411657750606537\n",
      "Epoch 25: train loss: 0.5428584218025208\n",
      "Epoch 25: train loss: 0.5336353778839111\n",
      "Epoch 25: train loss: 0.7706981301307678\n",
      "Epoch 25: train loss: 0.5189138650894165\n",
      "Epoch 25: train loss: 0.516334593296051\n",
      "Epoch 25: train loss: 0.6677128672599792\n",
      "Epoch 25: train loss: 0.47019463777542114\n",
      "Epoch 25: train loss: 0.6710367202758789\n",
      "Epoch 25: train loss: 0.5878581404685974\n",
      "Epoch 25: train loss: 0.6552866101264954\n",
      "Epoch 25: train loss: 0.6346127986907959\n",
      "Epoch 25: train loss: 0.6113113164901733\n",
      "Epoch 25: train loss: 0.5425001382827759\n",
      "Epoch 25: train loss: 0.4927505552768707\n",
      "Epoch 25: train loss: 0.659276008605957\n",
      "Epoch 25: train loss: 0.4926430881023407\n",
      "Epoch 25: train loss: 0.5316904783248901\n",
      "Epoch 25: train loss: 0.5835290551185608\n",
      "Epoch 25: train loss: 0.5484038591384888\n",
      "Epoch 25: train loss: 0.42267611622810364\n",
      "Epoch 25: train loss: 0.6363121867179871\n",
      "Epoch 25: train loss: 0.5259970426559448\n",
      "Epoch 25: train loss: 0.4867062270641327\n",
      "Epoch 25: train loss: 0.48252439498901367\n",
      "Epoch 25: train loss: 0.5058053731918335\n",
      "Epoch 25: train loss: 0.6702801585197449\n",
      "Epoch 25: train loss: 0.5242486596107483\n",
      "Epoch 25: train loss: 0.5960379838943481\n",
      "Epoch 25: train loss: 0.6387493014335632\n",
      "Epoch 25: train loss: 0.4982771575450897\n",
      "Epoch 25: train loss: 0.4667235314846039\n",
      "Epoch 25: train loss: 0.6071107387542725\n",
      "Epoch 25: train loss: 0.48734694719314575\n",
      "Epoch 25: train loss: 0.5605313181877136\n",
      "Epoch 25: train loss: 0.6552255153656006\n",
      "Epoch 25: train loss: 0.5638724565505981\n",
      "Epoch 25: train loss: 0.5226575136184692\n",
      "Epoch 25: train loss: 0.5870375633239746\n",
      "Epoch 25: train loss: 0.6046371459960938\n",
      "Epoch 25: train loss: 0.6938990354537964\n",
      "Epoch 25: train loss: 0.5303119421005249\n",
      "Epoch 25: train loss: 0.551078736782074\n",
      "Epoch 25: train loss: 0.510058581829071\n",
      "Epoch 25: train loss: 0.46406811475753784\n",
      "Epoch 25: train loss: 0.5586981177330017\n",
      "Epoch 25: train loss: 0.4378906488418579\n",
      "Epoch 25: train loss: 0.43142661452293396\n",
      "Epoch 25: train loss: 0.550740122795105\n",
      "Epoch 25: train loss: 0.5047063827514648\n",
      "Epoch 26: train loss: 0.4280078113079071\n",
      "Epoch 26: train loss: 0.7531612515449524\n",
      "Epoch 26: train loss: 0.4015882909297943\n",
      "Epoch 26: train loss: 0.6011319756507874\n",
      "Epoch 26: train loss: 0.4242939352989197\n",
      "Epoch 26: train loss: 0.7130056023597717\n",
      "Epoch 26: train loss: 0.5947040915489197\n",
      "Epoch 26: train loss: 0.5679416060447693\n",
      "Epoch 26: train loss: 0.43777501583099365\n",
      "Epoch 26: train loss: 0.504112958908081\n",
      "Epoch 26: train loss: 0.5165640711784363\n",
      "Epoch 26: train loss: 0.4567592740058899\n",
      "Epoch 26: train loss: 0.41642284393310547\n",
      "Epoch 26: train loss: 0.5406411290168762\n",
      "Epoch 26: train loss: 0.4831879138946533\n",
      "Epoch 26: train loss: 0.5609433054924011\n",
      "Epoch 26: train loss: 0.7081127166748047\n",
      "Epoch 26: train loss: 0.4969250559806824\n",
      "Epoch 26: train loss: 0.6598350405693054\n",
      "Epoch 26: train loss: 0.468098908662796\n",
      "Epoch 26: train loss: 0.6362951397895813\n",
      "Epoch 26: train loss: 0.5672634840011597\n",
      "Epoch 26: train loss: 0.6293473243713379\n",
      "Epoch 26: train loss: 0.6442341208457947\n",
      "Epoch 26: train loss: 0.6953918933868408\n",
      "Epoch 26: train loss: 0.689961850643158\n",
      "Epoch 26: train loss: 0.4941401183605194\n",
      "Epoch 26: train loss: 0.49494966864585876\n",
      "Epoch 26: train loss: 0.4717547595500946\n",
      "Epoch 26: train loss: 0.6389720439910889\n",
      "Epoch 26: train loss: 0.5404804348945618\n",
      "Epoch 26: train loss: 0.4952991008758545\n",
      "Epoch 26: train loss: 0.5334925055503845\n",
      "Epoch 26: train loss: 0.5322005152702332\n",
      "Epoch 26: train loss: 0.529552161693573\n",
      "Epoch 26: train loss: 0.6799454689025879\n",
      "Epoch 26: train loss: 0.43511202931404114\n",
      "Epoch 26: train loss: 0.7548502087593079\n",
      "Epoch 26: train loss: 0.7088271379470825\n",
      "Epoch 26: train loss: 0.578788161277771\n",
      "Epoch 26: train loss: 0.5228093862533569\n",
      "Epoch 26: train loss: 0.5419273972511292\n",
      "Epoch 26: train loss: 0.6229897737503052\n",
      "Epoch 26: train loss: 0.5445154905319214\n",
      "Epoch 26: train loss: 0.5553699135780334\n",
      "Epoch 26: train loss: 0.4373500943183899\n",
      "Epoch 26: train loss: 0.6165363788604736\n",
      "Epoch 26: train loss: 0.41747432947158813\n",
      "Epoch 26: train loss: 0.5207687020301819\n",
      "Epoch 26: train loss: 0.4692830741405487\n",
      "Epoch 26: train loss: 0.3869715631008148\n",
      "Epoch 26: train loss: 0.5909222960472107\n",
      "Epoch 26: train loss: 0.4883800148963928\n",
      "Epoch 26: train loss: 0.5839265584945679\n",
      "Epoch 26: train loss: 0.6035833954811096\n",
      "Epoch 26: train loss: 0.3841586112976074\n",
      "Epoch 26: train loss: 0.607755184173584\n",
      "Epoch 26: train loss: 0.4601987600326538\n",
      "Epoch 26: train loss: 0.4478800892829895\n",
      "Epoch 26: train loss: 0.5263340473175049\n",
      "Epoch 26: train loss: 0.5012925863265991\n",
      "Epoch 26: train loss: 0.6525013446807861\n",
      "Epoch 26: train loss: 0.5669577717781067\n",
      "Epoch 26: train loss: 0.6385155320167542\n",
      "Epoch 26: train loss: 0.46547552943229675\n",
      "Epoch 26: train loss: 0.700778603553772\n",
      "Epoch 26: train loss: 0.4071510136127472\n",
      "Epoch 26: train loss: 0.7095328569412231\n",
      "Epoch 26: train loss: 0.47371724247932434\n",
      "Epoch 26: train loss: 0.5319787263870239\n",
      "Epoch 26: train loss: 0.5229108333587646\n",
      "Epoch 26: train loss: 0.5975831151008606\n",
      "Epoch 26: train loss: 0.5242978930473328\n",
      "Epoch 26: train loss: 0.6090296506881714\n",
      "Epoch 26: train loss: 0.5869782567024231\n",
      "Epoch 26: train loss: 0.4382663071155548\n",
      "Epoch 26: train loss: 0.495979368686676\n",
      "Epoch 26: train loss: 0.5703640580177307\n",
      "Epoch 26: train loss: 0.4908958673477173\n",
      "Epoch 26: train loss: 0.6060319542884827\n",
      "Epoch 26: train loss: 0.6464791893959045\n",
      "Epoch 26: train loss: 0.5201037526130676\n",
      "Epoch 26: train loss: 0.810057520866394\n",
      "Epoch 26: train loss: 0.5629825592041016\n",
      "Epoch 26: train loss: 0.7121617197990417\n",
      "Epoch 26: train loss: 0.4024915397167206\n",
      "Epoch 26: train loss: 0.6381300687789917\n",
      "Epoch 26: train loss: 0.4432395398616791\n",
      "Epoch 26: train loss: 0.34038519859313965\n",
      "Epoch 26: train loss: 0.5304540991783142\n",
      "Epoch 26: train loss: 0.8012235164642334\n",
      "Epoch 26: train loss: 0.7743626236915588\n",
      "Epoch 26: train loss: 0.5404133796691895\n",
      "Epoch 26: train loss: 0.6420447826385498\n",
      "Epoch 26: train loss: 0.5219177007675171\n",
      "Epoch 26: train loss: 0.5715373754501343\n",
      "Epoch 26: train loss: 0.6187681555747986\n",
      "Epoch 26: train loss: 0.4607810378074646\n",
      "Epoch 26: train loss: 0.4860600531101227\n",
      "Epoch 26: train loss: 0.45565977692604065\n",
      "Epoch 26: train loss: 0.7325295805931091\n",
      "Epoch 26: train loss: 0.5235314965248108\n",
      "Epoch 26: train loss: 0.4353265166282654\n",
      "Epoch 26: train loss: 0.6047240495681763\n",
      "Epoch 26: train loss: 0.44221219420433044\n",
      "Epoch 26: train loss: 0.5007916688919067\n",
      "Epoch 26: train loss: 0.5534196496009827\n",
      "Epoch 26: train loss: 0.4587669372558594\n",
      "Epoch 26: train loss: 0.48221758008003235\n",
      "Epoch 26: train loss: 0.6142618656158447\n",
      "Epoch 26: train loss: 0.46331602334976196\n",
      "Epoch 26: train loss: 0.5841119885444641\n",
      "Epoch 26: train loss: 0.401185542345047\n",
      "Epoch 26: train loss: 0.3717042803764343\n",
      "Epoch 26: train loss: 0.5305504202842712\n",
      "Epoch 26: train loss: 0.42031627893447876\n",
      "Epoch 26: train loss: 0.5412573218345642\n",
      "Epoch 26: train loss: 0.47581544518470764\n",
      "Epoch 26: train loss: 0.5045149326324463\n",
      "Epoch 26: train loss: 0.5996502041816711\n",
      "Epoch 26: train loss: 0.6976393461227417\n",
      "Epoch 26: train loss: 0.5309668779373169\n",
      "Epoch 26: train loss: 0.3996342420578003\n",
      "Epoch 26: train loss: 0.4259747564792633\n",
      "Epoch 27: train loss: 0.5184589624404907\n",
      "Epoch 27: train loss: 0.47572648525238037\n",
      "Epoch 27: train loss: 0.6066685318946838\n",
      "Epoch 27: train loss: 0.591259777545929\n",
      "Epoch 27: train loss: 0.5135451555252075\n",
      "Epoch 27: train loss: 0.635617196559906\n",
      "Epoch 27: train loss: 0.6917105317115784\n",
      "Epoch 27: train loss: 0.5012214779853821\n",
      "Epoch 27: train loss: 0.5093339085578918\n",
      "Epoch 27: train loss: 0.5380625128746033\n",
      "Epoch 27: train loss: 0.4267975389957428\n",
      "Epoch 27: train loss: 0.6034378409385681\n",
      "Epoch 27: train loss: 0.485960990190506\n",
      "Epoch 27: train loss: 0.41903913021087646\n",
      "Epoch 27: train loss: 0.4777895212173462\n",
      "Epoch 27: train loss: 0.5475641489028931\n",
      "Epoch 27: train loss: 0.6699535846710205\n",
      "Epoch 27: train loss: 0.478145033121109\n",
      "Epoch 27: train loss: 0.49116986989974976\n",
      "Epoch 27: train loss: 0.4909991919994354\n",
      "Epoch 27: train loss: 0.6426689028739929\n",
      "Epoch 27: train loss: 0.5538651943206787\n",
      "Epoch 27: train loss: 0.5249485373497009\n",
      "Epoch 27: train loss: 0.5902169942855835\n",
      "Epoch 27: train loss: 0.4768373966217041\n",
      "Epoch 27: train loss: 0.5802619457244873\n",
      "Epoch 27: train loss: 0.726542055606842\n",
      "Epoch 27: train loss: 0.6863130331039429\n",
      "Epoch 27: train loss: 0.43663734197616577\n",
      "Epoch 27: train loss: 0.45165467262268066\n",
      "Epoch 27: train loss: 0.5097388029098511\n",
      "Epoch 27: train loss: 0.6358222365379333\n",
      "Epoch 27: train loss: 0.6305549740791321\n",
      "Epoch 27: train loss: 0.3578384220600128\n",
      "Epoch 27: train loss: 0.5401245355606079\n",
      "Epoch 27: train loss: 0.6438249945640564\n",
      "Epoch 27: train loss: 0.4509701132774353\n",
      "Epoch 27: train loss: 0.5991640686988831\n",
      "Epoch 27: train loss: 0.41484013199806213\n",
      "Epoch 27: train loss: 0.6024782061576843\n",
      "Epoch 27: train loss: 0.3879922032356262\n",
      "Epoch 27: train loss: 0.5406880974769592\n",
      "Epoch 27: train loss: 0.5728217959403992\n",
      "Epoch 27: train loss: 0.5910422801971436\n",
      "Epoch 27: train loss: 0.5592230558395386\n",
      "Epoch 27: train loss: 0.5186824798583984\n",
      "Epoch 27: train loss: 0.5190589427947998\n",
      "Epoch 27: train loss: 0.7074026465415955\n",
      "Epoch 27: train loss: 0.5924457311630249\n",
      "Epoch 27: train loss: 0.5610532164573669\n",
      "Epoch 27: train loss: 0.6162391304969788\n",
      "Epoch 27: train loss: 0.5394425392150879\n",
      "Epoch 27: train loss: 0.5477079749107361\n",
      "Epoch 27: train loss: 0.4487389624118805\n",
      "Epoch 27: train loss: 0.45333361625671387\n",
      "Epoch 27: train loss: 0.6912633776664734\n",
      "Epoch 27: train loss: 0.5106635689735413\n",
      "Epoch 27: train loss: 0.38599804043769836\n",
      "Epoch 27: train loss: 0.535485565662384\n",
      "Epoch 27: train loss: 0.4924532175064087\n",
      "Epoch 27: train loss: 0.5516558289527893\n",
      "Epoch 27: train loss: 0.4231199324131012\n",
      "Epoch 27: train loss: 0.4150445759296417\n",
      "Epoch 27: train loss: 0.5258267521858215\n",
      "Epoch 27: train loss: 0.5206260681152344\n",
      "Epoch 27: train loss: 0.5136106014251709\n",
      "Epoch 27: train loss: 0.5896314382553101\n",
      "Epoch 27: train loss: 0.50473552942276\n",
      "Epoch 27: train loss: 0.3903236985206604\n",
      "Epoch 27: train loss: 0.4976028800010681\n",
      "Epoch 27: train loss: 0.5222434997558594\n",
      "Epoch 27: train loss: 0.5223258137702942\n",
      "Epoch 27: train loss: 0.3416976034641266\n",
      "Epoch 27: train loss: 0.5115882158279419\n",
      "Epoch 27: train loss: 0.46598559617996216\n",
      "Epoch 27: train loss: 0.6464444994926453\n",
      "Epoch 27: train loss: 0.5048772096633911\n",
      "Epoch 27: train loss: 0.49313628673553467\n",
      "Epoch 27: train loss: 0.4235072433948517\n",
      "Epoch 27: train loss: 0.5770029425621033\n",
      "Epoch 27: train loss: 0.7654731869697571\n",
      "Epoch 27: train loss: 0.5493016242980957\n",
      "Epoch 27: train loss: 0.4766772985458374\n",
      "Epoch 27: train loss: 0.5812361836433411\n",
      "Epoch 27: train loss: 0.355867475271225\n",
      "Epoch 27: train loss: 0.4841458797454834\n",
      "Epoch 27: train loss: 0.5354900360107422\n",
      "Epoch 27: train loss: 0.5056689381599426\n",
      "Epoch 27: train loss: 0.6014015078544617\n",
      "Epoch 27: train loss: 0.4324091672897339\n",
      "Epoch 27: train loss: 0.33237332105636597\n",
      "Epoch 27: train loss: 0.6741809248924255\n",
      "Epoch 27: train loss: 0.5592310428619385\n",
      "Epoch 27: train loss: 0.6323261260986328\n",
      "Epoch 27: train loss: 0.5694596767425537\n",
      "Epoch 27: train loss: 0.47047507762908936\n",
      "Epoch 27: train loss: 0.41877010464668274\n",
      "Epoch 27: train loss: 0.6300521492958069\n",
      "Epoch 27: train loss: 0.5762917399406433\n",
      "Epoch 27: train loss: 0.586769163608551\n",
      "Epoch 27: train loss: 0.525123119354248\n",
      "Epoch 27: train loss: 0.5203074216842651\n",
      "Epoch 27: train loss: 0.6779519319534302\n",
      "Epoch 27: train loss: 0.49612754583358765\n",
      "Epoch 27: train loss: 0.5618355870246887\n",
      "Epoch 27: train loss: 0.4849124848842621\n",
      "Epoch 27: train loss: 0.5555891394615173\n",
      "Epoch 27: train loss: 0.5678492784500122\n",
      "Epoch 27: train loss: 0.5704039931297302\n",
      "Epoch 27: train loss: 0.4356996417045593\n",
      "Epoch 27: train loss: 0.5506629943847656\n",
      "Epoch 27: train loss: 0.6128018498420715\n",
      "Epoch 27: train loss: 0.5764894485473633\n",
      "Epoch 27: train loss: 0.571815550327301\n",
      "Epoch 27: train loss: 0.5292943716049194\n",
      "Epoch 27: train loss: 0.4716142416000366\n",
      "Epoch 27: train loss: 0.5741668939590454\n",
      "Epoch 27: train loss: 0.546513557434082\n",
      "Epoch 27: train loss: 0.7095246315002441\n",
      "Epoch 27: train loss: 0.6041412353515625\n",
      "Epoch 27: train loss: 0.534075915813446\n",
      "Epoch 27: train loss: 0.5251767039299011\n",
      "Epoch 27: train loss: 0.6549990773200989\n",
      "Epoch 27: train loss: 0.29959771037101746\n",
      "Epoch 28: train loss: 0.45751163363456726\n",
      "Epoch 28: train loss: 0.46725043654441833\n",
      "Epoch 28: train loss: 0.6078073382377625\n",
      "Epoch 28: train loss: 0.45627087354660034\n",
      "Epoch 28: train loss: 0.5305511355400085\n",
      "Epoch 28: train loss: 0.5596462488174438\n",
      "Epoch 28: train loss: 0.3541526198387146\n",
      "Epoch 28: train loss: 0.5936155319213867\n",
      "Epoch 28: train loss: 0.48955413699150085\n",
      "Epoch 28: train loss: 0.4633465111255646\n",
      "Epoch 28: train loss: 0.47061222791671753\n",
      "Epoch 28: train loss: 0.3910509943962097\n",
      "Epoch 28: train loss: 0.4844544529914856\n",
      "Epoch 28: train loss: 0.7711359262466431\n",
      "Epoch 28: train loss: 0.6094622611999512\n",
      "Epoch 28: train loss: 0.34508806467056274\n",
      "Epoch 28: train loss: 0.49895575642585754\n",
      "Epoch 28: train loss: 0.712770938873291\n",
      "Epoch 28: train loss: 0.6899299025535583\n",
      "Epoch 28: train loss: 0.4028235971927643\n",
      "Epoch 28: train loss: 0.6808399558067322\n",
      "Epoch 28: train loss: 0.5360081791877747\n",
      "Epoch 28: train loss: 0.4792790710926056\n",
      "Epoch 28: train loss: 0.5539209842681885\n",
      "Epoch 28: train loss: 0.6721788644790649\n",
      "Epoch 28: train loss: 0.5618799328804016\n",
      "Epoch 28: train loss: 0.3924024701118469\n",
      "Epoch 28: train loss: 0.5104051232337952\n",
      "Epoch 28: train loss: 0.596183180809021\n",
      "Epoch 28: train loss: 0.6303018927574158\n",
      "Epoch 28: train loss: 0.4657655358314514\n",
      "Epoch 28: train loss: 0.5887503623962402\n",
      "Epoch 28: train loss: 0.48993027210235596\n",
      "Epoch 28: train loss: 0.6453327536582947\n",
      "Epoch 28: train loss: 0.6040239930152893\n",
      "Epoch 28: train loss: 0.5299098491668701\n",
      "Epoch 28: train loss: 0.5030732750892639\n",
      "Epoch 28: train loss: 0.37909892201423645\n",
      "Epoch 28: train loss: 0.6050016283988953\n",
      "Epoch 28: train loss: 0.5309826135635376\n",
      "Epoch 28: train loss: 0.5757167339324951\n",
      "Epoch 28: train loss: 0.5462115406990051\n",
      "Epoch 28: train loss: 0.6269662976264954\n",
      "Epoch 28: train loss: 0.5130235552787781\n",
      "Epoch 28: train loss: 0.6473162174224854\n",
      "Epoch 28: train loss: 0.4489284157752991\n",
      "Epoch 28: train loss: 0.5215731263160706\n",
      "Epoch 28: train loss: 0.599484384059906\n",
      "Epoch 28: train loss: 0.5987719297409058\n",
      "Epoch 28: train loss: 0.5987477898597717\n",
      "Epoch 28: train loss: 0.5128639340400696\n",
      "Epoch 28: train loss: 0.5218181014060974\n",
      "Epoch 28: train loss: 0.5769850015640259\n",
      "Epoch 28: train loss: 0.600878119468689\n",
      "Epoch 28: train loss: 0.5390329360961914\n",
      "Epoch 28: train loss: 0.5693767666816711\n",
      "Epoch 28: train loss: 0.7458605766296387\n",
      "Epoch 28: train loss: 0.5281683802604675\n",
      "Epoch 28: train loss: 0.5565479397773743\n",
      "Epoch 28: train loss: 0.5183679461479187\n",
      "Epoch 28: train loss: 0.36946815252304077\n",
      "Epoch 28: train loss: 0.4831700325012207\n",
      "Epoch 28: train loss: 0.550641655921936\n",
      "Epoch 28: train loss: 0.4832994043827057\n",
      "Epoch 28: train loss: 0.4749543070793152\n",
      "Epoch 28: train loss: 0.48659560084342957\n",
      "Epoch 28: train loss: 0.5120563507080078\n",
      "Epoch 28: train loss: 0.49606505036354065\n",
      "Epoch 28: train loss: 0.5390595197677612\n",
      "Epoch 28: train loss: 0.48858290910720825\n",
      "Epoch 28: train loss: 0.6219776272773743\n",
      "Epoch 28: train loss: 0.4414091110229492\n",
      "Epoch 28: train loss: 0.5784227252006531\n",
      "Epoch 28: train loss: 0.532620370388031\n",
      "Epoch 28: train loss: 0.4131905436515808\n",
      "Epoch 28: train loss: 0.42921820282936096\n",
      "Epoch 28: train loss: 0.5989795327186584\n",
      "Epoch 28: train loss: 0.6640313863754272\n",
      "Epoch 28: train loss: 0.6076708436012268\n",
      "Epoch 28: train loss: 0.4979570209980011\n",
      "Epoch 28: train loss: 0.7292507886886597\n",
      "Epoch 28: train loss: 0.6676890850067139\n",
      "Epoch 28: train loss: 0.521333634853363\n",
      "Epoch 28: train loss: 0.5724356174468994\n",
      "Epoch 28: train loss: 0.6326658129692078\n",
      "Epoch 28: train loss: 0.5369526743888855\n",
      "Epoch 28: train loss: 0.6941611766815186\n",
      "Epoch 28: train loss: 0.6902377605438232\n",
      "Epoch 28: train loss: 0.5991716980934143\n",
      "Epoch 28: train loss: 0.5132337808609009\n",
      "Epoch 28: train loss: 0.6624891757965088\n",
      "Epoch 28: train loss: 0.543588399887085\n",
      "Epoch 28: train loss: 0.5154236555099487\n",
      "Epoch 28: train loss: 0.44670307636260986\n",
      "Epoch 28: train loss: 0.5855047702789307\n",
      "Epoch 28: train loss: 0.507757306098938\n",
      "Epoch 28: train loss: 0.5768627524375916\n",
      "Epoch 28: train loss: 0.5645161271095276\n",
      "Epoch 28: train loss: 0.5463293790817261\n",
      "Epoch 28: train loss: 0.5641160011291504\n",
      "Epoch 28: train loss: 0.45657166838645935\n",
      "Epoch 28: train loss: 0.4871099293231964\n",
      "Epoch 28: train loss: 0.6127721667289734\n",
      "Epoch 28: train loss: 0.578795850276947\n",
      "Epoch 28: train loss: 0.5564631223678589\n",
      "Epoch 28: train loss: 0.6792109608650208\n",
      "Epoch 28: train loss: 0.49167943000793457\n",
      "Epoch 28: train loss: 0.3477899730205536\n",
      "Epoch 28: train loss: 0.546907901763916\n",
      "Epoch 28: train loss: 0.5341557264328003\n",
      "Epoch 28: train loss: 0.5022923946380615\n",
      "Epoch 28: train loss: 0.5916153788566589\n",
      "Epoch 28: train loss: 0.502295970916748\n",
      "Epoch 28: train loss: 0.5877976417541504\n",
      "Epoch 28: train loss: 0.4930306077003479\n",
      "Epoch 28: train loss: 0.5214684009552002\n",
      "Epoch 28: train loss: 0.562220573425293\n",
      "Epoch 28: train loss: 0.6426077485084534\n",
      "Epoch 28: train loss: 0.44119736552238464\n",
      "Epoch 28: train loss: 0.4809649884700775\n",
      "Epoch 28: train loss: 0.4895515441894531\n",
      "Epoch 28: train loss: 0.5320019721984863\n",
      "Epoch 28: train loss: 0.4635486304759979\n",
      "Epoch 28: train loss: 0.7394921779632568\n",
      "Epoch 29: train loss: 0.5369670987129211\n",
      "Epoch 29: train loss: 0.40905824303627014\n",
      "Epoch 29: train loss: 0.45018771290779114\n",
      "Epoch 29: train loss: 0.5329428315162659\n",
      "Epoch 29: train loss: 0.4217827320098877\n",
      "Epoch 29: train loss: 0.6033921241760254\n",
      "Epoch 29: train loss: 0.503026008605957\n",
      "Epoch 29: train loss: 0.6300919651985168\n",
      "Epoch 29: train loss: 0.5122283697128296\n",
      "Epoch 29: train loss: 0.49177777767181396\n",
      "Epoch 29: train loss: 0.7385096549987793\n",
      "Epoch 29: train loss: 0.6036038994789124\n",
      "Epoch 29: train loss: 0.539476215839386\n",
      "Epoch 29: train loss: 0.5996684432029724\n",
      "Epoch 29: train loss: 0.5740787982940674\n",
      "Epoch 29: train loss: 0.4991450905799866\n",
      "Epoch 29: train loss: 0.5586246848106384\n",
      "Epoch 29: train loss: 0.6266743540763855\n",
      "Epoch 29: train loss: 0.6200607419013977\n",
      "Epoch 29: train loss: 0.5809183716773987\n",
      "Epoch 29: train loss: 0.4813367426395416\n",
      "Epoch 29: train loss: 0.5562360286712646\n",
      "Epoch 29: train loss: 0.5289939045906067\n",
      "Epoch 29: train loss: 0.5984971523284912\n",
      "Epoch 29: train loss: 0.5830596089363098\n",
      "Epoch 29: train loss: 0.5188217759132385\n",
      "Epoch 29: train loss: 0.6688518524169922\n",
      "Epoch 29: train loss: 0.6744065880775452\n",
      "Epoch 29: train loss: 0.6792269349098206\n",
      "Epoch 29: train loss: 0.5065619945526123\n",
      "Epoch 29: train loss: 0.4298122525215149\n",
      "Epoch 29: train loss: 0.5579133629798889\n",
      "Epoch 29: train loss: 0.5392845869064331\n",
      "Epoch 29: train loss: 0.5124102234840393\n",
      "Epoch 29: train loss: 0.6097791194915771\n",
      "Epoch 29: train loss: 0.537142813205719\n",
      "Epoch 29: train loss: 0.49707552790641785\n",
      "Epoch 29: train loss: 0.533562958240509\n",
      "Epoch 29: train loss: 0.4487474858760834\n",
      "Epoch 29: train loss: 0.5659394860267639\n",
      "Epoch 29: train loss: 0.56388920545578\n",
      "Epoch 29: train loss: 0.5828047394752502\n",
      "Epoch 29: train loss: 0.5647497177124023\n",
      "Epoch 29: train loss: 0.6337741613388062\n",
      "Epoch 29: train loss: 0.5738511085510254\n",
      "Epoch 29: train loss: 0.552756667137146\n",
      "Epoch 29: train loss: 0.4581069052219391\n",
      "Epoch 29: train loss: 0.4936193823814392\n",
      "Epoch 29: train loss: 0.5561971664428711\n",
      "Epoch 29: train loss: 0.46116623282432556\n",
      "Epoch 29: train loss: 0.4875405728816986\n",
      "Epoch 29: train loss: 0.5527272820472717\n",
      "Epoch 29: train loss: 0.536946177482605\n",
      "Epoch 29: train loss: 0.5849546194076538\n",
      "Epoch 29: train loss: 0.5506072044372559\n",
      "Epoch 29: train loss: 0.6774953603744507\n",
      "Epoch 29: train loss: 0.5819843411445618\n",
      "Epoch 29: train loss: 0.5805156826972961\n",
      "Epoch 29: train loss: 0.5071396231651306\n",
      "Epoch 29: train loss: 0.5162277817726135\n",
      "Epoch 29: train loss: 0.5031638741493225\n",
      "Epoch 29: train loss: 0.5080782175064087\n",
      "Epoch 29: train loss: 0.546683669090271\n",
      "Epoch 29: train loss: 0.5072774887084961\n",
      "Epoch 29: train loss: 0.55253666639328\n",
      "Epoch 29: train loss: 0.6037700772285461\n",
      "Epoch 29: train loss: 0.4280807673931122\n",
      "Epoch 29: train loss: 0.5159634351730347\n",
      "Epoch 29: train loss: 0.6075557470321655\n",
      "Epoch 29: train loss: 0.45301973819732666\n",
      "Epoch 29: train loss: 0.4144382178783417\n",
      "Epoch 29: train loss: 0.6057838797569275\n",
      "Epoch 29: train loss: 0.54007488489151\n",
      "Epoch 29: train loss: 0.537013053894043\n",
      "Epoch 29: train loss: 0.6667770147323608\n",
      "Epoch 29: train loss: 0.3548496961593628\n",
      "Epoch 29: train loss: 0.5992903113365173\n",
      "Epoch 29: train loss: 0.64085453748703\n",
      "Epoch 29: train loss: 0.46992358565330505\n",
      "Epoch 29: train loss: 0.48032164573669434\n",
      "Epoch 29: train loss: 0.370374470949173\n",
      "Epoch 29: train loss: 0.6338981986045837\n",
      "Epoch 29: train loss: 0.4249819219112396\n",
      "Epoch 29: train loss: 0.6032269597053528\n",
      "Epoch 29: train loss: 0.5387588143348694\n",
      "Epoch 29: train loss: 0.541145384311676\n",
      "Epoch 29: train loss: 0.5604333281517029\n",
      "Epoch 29: train loss: 0.47792020440101624\n",
      "Epoch 29: train loss: 0.7122465372085571\n",
      "Epoch 29: train loss: 0.6107032299041748\n",
      "Epoch 29: train loss: 0.5114919543266296\n",
      "Epoch 29: train loss: 0.43327024579048157\n",
      "Epoch 29: train loss: 0.52818763256073\n",
      "Epoch 29: train loss: 0.5032236576080322\n",
      "Epoch 29: train loss: 0.707697331905365\n",
      "Epoch 29: train loss: 0.44716891646385193\n",
      "Epoch 29: train loss: 0.5681660175323486\n",
      "Epoch 29: train loss: 0.6007034778594971\n",
      "Epoch 29: train loss: 0.5386481881141663\n",
      "Epoch 29: train loss: 0.3749644458293915\n",
      "Epoch 29: train loss: 0.52955162525177\n",
      "Epoch 29: train loss: 0.5197593569755554\n",
      "Epoch 29: train loss: 0.573714554309845\n",
      "Epoch 29: train loss: 0.4601893424987793\n",
      "Epoch 29: train loss: 0.658168375492096\n",
      "Epoch 29: train loss: 0.5363827347755432\n",
      "Epoch 29: train loss: 0.6784600615501404\n",
      "Epoch 29: train loss: 0.4091208875179291\n",
      "Epoch 29: train loss: 0.548988938331604\n",
      "Epoch 29: train loss: 0.6315036416053772\n",
      "Epoch 29: train loss: 0.4277351200580597\n",
      "Epoch 29: train loss: 0.5109022855758667\n",
      "Epoch 29: train loss: 0.5097859501838684\n",
      "Epoch 29: train loss: 0.44957464933395386\n",
      "Epoch 29: train loss: 0.4325316548347473\n",
      "Epoch 29: train loss: 0.46556952595710754\n",
      "Epoch 29: train loss: 0.6315409541130066\n",
      "Epoch 29: train loss: 0.48372310400009155\n",
      "Epoch 29: train loss: 0.507392168045044\n",
      "Epoch 29: train loss: 0.43759122490882874\n",
      "Epoch 29: train loss: 0.5072186589241028\n",
      "Epoch 29: train loss: 0.5714397430419922\n",
      "Epoch 29: train loss: 0.5012177228927612\n",
      "Epoch 29: train loss: 0.4094448983669281\n",
      "Epoch 30: train loss: 0.5331401824951172\n",
      "Epoch 30: train loss: 0.5040744543075562\n",
      "Epoch 30: train loss: 0.5239941477775574\n",
      "Epoch 30: train loss: 0.5549629926681519\n",
      "Epoch 30: train loss: 0.5129606127738953\n",
      "Epoch 30: train loss: 0.7370766401290894\n",
      "Epoch 30: train loss: 0.7203608751296997\n",
      "Epoch 30: train loss: 0.5776506662368774\n",
      "Epoch 30: train loss: 0.6291734576225281\n",
      "Epoch 30: train loss: 0.4751605987548828\n",
      "Epoch 30: train loss: 0.5744998455047607\n",
      "Epoch 30: train loss: 0.35023584961891174\n",
      "Epoch 30: train loss: 0.5596453547477722\n",
      "Epoch 30: train loss: 0.42855003476142883\n",
      "Epoch 30: train loss: 0.43512609601020813\n",
      "Epoch 30: train loss: 0.47974830865859985\n",
      "Epoch 30: train loss: 0.47262170910835266\n",
      "Epoch 30: train loss: 0.4039977192878723\n",
      "Epoch 30: train loss: 0.5118119716644287\n",
      "Epoch 30: train loss: 0.43340834975242615\n",
      "Epoch 30: train loss: 0.5767804384231567\n",
      "Epoch 30: train loss: 0.6154967546463013\n",
      "Epoch 30: train loss: 0.44312578439712524\n",
      "Epoch 30: train loss: 0.5238207578659058\n",
      "Epoch 30: train loss: 0.5381660461425781\n",
      "Epoch 30: train loss: 0.5296988487243652\n",
      "Epoch 30: train loss: 0.4745239019393921\n",
      "Epoch 30: train loss: 0.5142676830291748\n",
      "Epoch 30: train loss: 0.5565682649612427\n",
      "Epoch 30: train loss: 0.486498087644577\n",
      "Epoch 30: train loss: 0.49529147148132324\n",
      "Epoch 30: train loss: 0.42466917634010315\n",
      "Epoch 30: train loss: 0.4206313192844391\n",
      "Epoch 30: train loss: 0.5447231531143188\n",
      "Epoch 30: train loss: 0.7290655970573425\n",
      "Epoch 30: train loss: 0.44441697001457214\n",
      "Epoch 30: train loss: 0.6453968286514282\n",
      "Epoch 30: train loss: 0.5837370157241821\n",
      "Epoch 30: train loss: 0.5090500116348267\n",
      "Epoch 30: train loss: 0.6376219391822815\n",
      "Epoch 30: train loss: 0.4670170843601227\n",
      "Epoch 30: train loss: 0.7972463965415955\n",
      "Epoch 30: train loss: 0.5063527226448059\n",
      "Epoch 30: train loss: 0.6427171230316162\n",
      "Epoch 30: train loss: 0.4826625883579254\n",
      "Epoch 30: train loss: 0.5738511681556702\n",
      "Epoch 30: train loss: 0.6429299712181091\n",
      "Epoch 30: train loss: 0.49442240595817566\n",
      "Epoch 30: train loss: 0.5535168647766113\n",
      "Epoch 30: train loss: 0.40727686882019043\n",
      "Epoch 30: train loss: 0.43074578046798706\n",
      "Epoch 30: train loss: 0.4497993290424347\n",
      "Epoch 30: train loss: 0.6582320928573608\n",
      "Epoch 30: train loss: 0.49756956100463867\n",
      "Epoch 30: train loss: 0.4547387659549713\n",
      "Epoch 30: train loss: 0.8009330630302429\n",
      "Epoch 30: train loss: 0.5344147682189941\n",
      "Epoch 30: train loss: 0.6853894591331482\n",
      "Epoch 30: train loss: 0.4463375508785248\n",
      "Epoch 30: train loss: 0.553085207939148\n",
      "Epoch 30: train loss: 0.5219385027885437\n",
      "Epoch 30: train loss: 0.5490958094596863\n",
      "Epoch 30: train loss: 0.54259192943573\n",
      "Epoch 30: train loss: 0.546158492565155\n",
      "Epoch 30: train loss: 0.6209078431129456\n",
      "Epoch 30: train loss: 0.547100841999054\n",
      "Epoch 30: train loss: 0.5213971138000488\n",
      "Epoch 30: train loss: 0.5027502179145813\n",
      "Epoch 30: train loss: 0.37631943821907043\n",
      "Epoch 30: train loss: 0.5218998789787292\n",
      "Epoch 30: train loss: 0.6202358603477478\n",
      "Epoch 30: train loss: 0.541893482208252\n",
      "Epoch 30: train loss: 0.5507520437240601\n",
      "Epoch 30: train loss: 0.6779131293296814\n",
      "Epoch 30: train loss: 0.6458487510681152\n",
      "Epoch 30: train loss: 0.4670904278755188\n",
      "Epoch 30: train loss: 0.5763874053955078\n",
      "Epoch 30: train loss: 0.4785633683204651\n",
      "Epoch 30: train loss: 0.5682233572006226\n",
      "Epoch 30: train loss: 0.5707138180732727\n",
      "Epoch 30: train loss: 0.4327331781387329\n",
      "Epoch 30: train loss: 0.5145483613014221\n",
      "Epoch 30: train loss: 0.5618638396263123\n",
      "Epoch 30: train loss: 0.4591720402240753\n",
      "Epoch 30: train loss: 0.472211629152298\n",
      "Epoch 30: train loss: 0.6079120635986328\n",
      "Epoch 30: train loss: 0.4783579707145691\n",
      "Epoch 30: train loss: 0.5084639191627502\n",
      "Epoch 30: train loss: 0.662115752696991\n",
      "Epoch 30: train loss: 0.5158609747886658\n",
      "Epoch 30: train loss: 0.5332246422767639\n",
      "Epoch 30: train loss: 0.5181368589401245\n",
      "Epoch 30: train loss: 0.5360061526298523\n",
      "Epoch 30: train loss: 0.4817376732826233\n",
      "Epoch 30: train loss: 0.3903628885746002\n",
      "Epoch 30: train loss: 0.4720832407474518\n",
      "Epoch 30: train loss: 0.6494482755661011\n",
      "Epoch 30: train loss: 0.3163719177246094\n",
      "Epoch 30: train loss: 0.5230529308319092\n",
      "Epoch 30: train loss: 0.5908877849578857\n",
      "Epoch 30: train loss: 0.4791494309902191\n",
      "Epoch 30: train loss: 0.5348511338233948\n",
      "Epoch 30: train loss: 0.6049106121063232\n",
      "Epoch 30: train loss: 0.6989706158638\n",
      "Epoch 30: train loss: 0.5130915641784668\n",
      "Epoch 30: train loss: 0.5445259809494019\n",
      "Epoch 30: train loss: 0.45129191875457764\n",
      "Epoch 30: train loss: 0.36449873447418213\n",
      "Epoch 30: train loss: 0.5912562608718872\n",
      "Epoch 30: train loss: 0.5312291383743286\n",
      "Epoch 30: train loss: 0.524679958820343\n",
      "Epoch 30: train loss: 0.6806215643882751\n",
      "Epoch 30: train loss: 0.6065206527709961\n",
      "Epoch 30: train loss: 0.5358760952949524\n",
      "Epoch 30: train loss: 0.5814210176467896\n",
      "Epoch 30: train loss: 0.5796865224838257\n",
      "Epoch 30: train loss: 0.491322785615921\n",
      "Epoch 30: train loss: 0.5056667923927307\n",
      "Epoch 30: train loss: 0.45277929306030273\n",
      "Epoch 30: train loss: 0.6253842711448669\n",
      "Epoch 30: train loss: 0.4646148979663849\n",
      "Epoch 30: train loss: 0.4432569742202759\n",
      "Epoch 30: train loss: 0.6336308717727661\n",
      "Epoch 30: train loss: 0.7367016077041626\n",
      "Epoch 31: train loss: 0.5386779308319092\n",
      "Epoch 31: train loss: 0.38533779978752136\n",
      "Epoch 31: train loss: 0.5441755652427673\n",
      "Epoch 31: train loss: 0.4739364683628082\n",
      "Epoch 31: train loss: 0.42923346161842346\n",
      "Epoch 31: train loss: 0.6549630165100098\n",
      "Epoch 31: train loss: 0.4740090072154999\n",
      "Epoch 31: train loss: 0.6434508562088013\n",
      "Epoch 31: train loss: 0.48589861392974854\n",
      "Epoch 31: train loss: 0.5548222064971924\n",
      "Epoch 31: train loss: 0.5701383352279663\n",
      "Epoch 31: train loss: 0.5780777931213379\n",
      "Epoch 31: train loss: 0.5762320756912231\n",
      "Epoch 31: train loss: 0.48233845829963684\n",
      "Epoch 31: train loss: 0.6156073212623596\n",
      "Epoch 31: train loss: 0.4206980764865875\n",
      "Epoch 31: train loss: 0.574522852897644\n",
      "Epoch 31: train loss: 0.40493983030319214\n",
      "Epoch 31: train loss: 0.508208155632019\n",
      "Epoch 31: train loss: 0.37912052869796753\n",
      "Epoch 31: train loss: 0.40220433473587036\n",
      "Epoch 31: train loss: 0.4672194719314575\n",
      "Epoch 31: train loss: 0.5922753214836121\n",
      "Epoch 31: train loss: 0.568824827671051\n",
      "Epoch 31: train loss: 0.7062429785728455\n",
      "Epoch 31: train loss: 0.6173824071884155\n",
      "Epoch 31: train loss: 0.5700749158859253\n",
      "Epoch 31: train loss: 0.5046994090080261\n",
      "Epoch 31: train loss: 0.44921034574508667\n",
      "Epoch 31: train loss: 0.44369593262672424\n",
      "Epoch 31: train loss: 0.5536959767341614\n",
      "Epoch 31: train loss: 0.5340695381164551\n",
      "Epoch 31: train loss: 0.5792791843414307\n",
      "Epoch 31: train loss: 0.5109015703201294\n",
      "Epoch 31: train loss: 0.695692777633667\n",
      "Epoch 31: train loss: 0.4814881384372711\n",
      "Epoch 31: train loss: 0.4797179400920868\n",
      "Epoch 31: train loss: 0.49430471658706665\n",
      "Epoch 31: train loss: 0.5399743318557739\n",
      "Epoch 31: train loss: 0.5419623851776123\n",
      "Epoch 31: train loss: 0.45788630843162537\n",
      "Epoch 31: train loss: 0.49450379610061646\n",
      "Epoch 31: train loss: 0.42116084694862366\n",
      "Epoch 31: train loss: 0.5190993547439575\n",
      "Epoch 31: train loss: 0.43377548456192017\n",
      "Epoch 31: train loss: 0.6971688270568848\n",
      "Epoch 31: train loss: 0.4948764741420746\n",
      "Epoch 31: train loss: 0.40066057443618774\n",
      "Epoch 31: train loss: 0.6046781539916992\n",
      "Epoch 31: train loss: 0.45332807302474976\n",
      "Epoch 31: train loss: 0.546257734298706\n",
      "Epoch 31: train loss: 0.6298210024833679\n",
      "Epoch 31: train loss: 0.4027442932128906\n",
      "Epoch 31: train loss: 0.5878073573112488\n",
      "Epoch 31: train loss: 0.4578820765018463\n",
      "Epoch 31: train loss: 0.5712123513221741\n",
      "Epoch 31: train loss: 0.41295313835144043\n",
      "Epoch 31: train loss: 0.5470714569091797\n",
      "Epoch 31: train loss: 0.5077390074729919\n",
      "Epoch 31: train loss: 0.4428938627243042\n",
      "Epoch 31: train loss: 0.4197373688220978\n",
      "Epoch 31: train loss: 0.7827165722846985\n",
      "Epoch 31: train loss: 0.5807521939277649\n",
      "Epoch 31: train loss: 0.6510238647460938\n",
      "Epoch 31: train loss: 0.5126660466194153\n",
      "Epoch 31: train loss: 0.3796939253807068\n",
      "Epoch 31: train loss: 0.5199050307273865\n",
      "Epoch 31: train loss: 0.5489121675491333\n",
      "Epoch 31: train loss: 0.6075365543365479\n",
      "Epoch 31: train loss: 0.3788129985332489\n",
      "Epoch 31: train loss: 0.5875511765480042\n",
      "Epoch 31: train loss: 0.52451092004776\n",
      "Epoch 31: train loss: 0.5264058113098145\n",
      "Epoch 31: train loss: 0.4930097460746765\n",
      "Epoch 31: train loss: 0.6383606791496277\n",
      "Epoch 31: train loss: 0.5548827648162842\n",
      "Epoch 31: train loss: 0.5854771733283997\n",
      "Epoch 31: train loss: 0.4907134771347046\n",
      "Epoch 31: train loss: 0.5097067952156067\n",
      "Epoch 31: train loss: 0.6389603614807129\n",
      "Epoch 31: train loss: 0.6096875071525574\n",
      "Epoch 31: train loss: 0.6560513973236084\n",
      "Epoch 31: train loss: 0.5125536918640137\n",
      "Epoch 31: train loss: 0.5286087989807129\n",
      "Epoch 31: train loss: 0.5556284189224243\n",
      "Epoch 31: train loss: 0.542332112789154\n",
      "Epoch 31: train loss: 0.37222999334335327\n",
      "Epoch 31: train loss: 0.6032300591468811\n",
      "Epoch 31: train loss: 0.635874330997467\n",
      "Epoch 31: train loss: 0.5435618758201599\n",
      "Epoch 31: train loss: 0.4165731370449066\n",
      "Epoch 31: train loss: 0.549634575843811\n",
      "Epoch 31: train loss: 0.5142549872398376\n",
      "Epoch 31: train loss: 0.5734304785728455\n",
      "Epoch 31: train loss: 0.7698935270309448\n",
      "Epoch 31: train loss: 0.5864861011505127\n",
      "Epoch 31: train loss: 0.5537929534912109\n",
      "Epoch 31: train loss: 0.48128506541252136\n",
      "Epoch 31: train loss: 0.5499692559242249\n",
      "Epoch 31: train loss: 0.6543882489204407\n",
      "Epoch 31: train loss: 0.4475742280483246\n",
      "Epoch 31: train loss: 0.5452677011489868\n",
      "Epoch 31: train loss: 0.5281038880348206\n",
      "Epoch 31: train loss: 0.6159118413925171\n",
      "Epoch 31: train loss: 0.5570272207260132\n",
      "Epoch 31: train loss: 0.5456262826919556\n",
      "Epoch 31: train loss: 0.48665258288383484\n",
      "Epoch 31: train loss: 0.4809640645980835\n",
      "Epoch 31: train loss: 0.6492626667022705\n",
      "Epoch 31: train loss: 0.5168132781982422\n",
      "Epoch 31: train loss: 0.5567491054534912\n",
      "Epoch 31: train loss: 0.5366167426109314\n",
      "Epoch 31: train loss: 0.6487998366355896\n",
      "Epoch 31: train loss: 0.5917248725891113\n",
      "Epoch 31: train loss: 0.6685497164726257\n",
      "Epoch 31: train loss: 0.7362004518508911\n",
      "Epoch 31: train loss: 0.4693894684314728\n",
      "Epoch 31: train loss: 0.5075963735580444\n",
      "Epoch 31: train loss: 0.5899942517280579\n",
      "Epoch 31: train loss: 0.6345022916793823\n",
      "Epoch 31: train loss: 0.4935508370399475\n",
      "Epoch 31: train loss: 0.539515495300293\n",
      "Epoch 31: train loss: 0.49523353576660156\n",
      "Epoch 31: train loss: 0.6094565391540527\n",
      "Epoch 32: train loss: 0.5082190036773682\n",
      "Epoch 32: train loss: 0.5850937366485596\n",
      "Epoch 32: train loss: 0.6265444755554199\n",
      "Epoch 32: train loss: 0.6543822884559631\n",
      "Epoch 32: train loss: 0.4465707540512085\n",
      "Epoch 32: train loss: 0.4105607867240906\n",
      "Epoch 32: train loss: 0.5062873959541321\n",
      "Epoch 32: train loss: 0.5052821636199951\n",
      "Epoch 32: train loss: 0.7530245184898376\n",
      "Epoch 32: train loss: 0.4195728600025177\n",
      "Epoch 32: train loss: 0.5822076797485352\n",
      "Epoch 32: train loss: 0.4902321696281433\n",
      "Epoch 32: train loss: 0.656436026096344\n",
      "Epoch 32: train loss: 0.50045245885849\n",
      "Epoch 32: train loss: 0.6402965188026428\n",
      "Epoch 32: train loss: 0.6272508502006531\n",
      "Epoch 32: train loss: 0.436208575963974\n",
      "Epoch 32: train loss: 0.47754788398742676\n",
      "Epoch 32: train loss: 0.59139484167099\n",
      "Epoch 32: train loss: 0.5672544240951538\n",
      "Epoch 32: train loss: 0.37924277782440186\n",
      "Epoch 32: train loss: 0.5876622200012207\n",
      "Epoch 32: train loss: 0.522257924079895\n",
      "Epoch 32: train loss: 0.4831201434135437\n",
      "Epoch 32: train loss: 0.4293726682662964\n",
      "Epoch 32: train loss: 0.7066181302070618\n",
      "Epoch 32: train loss: 0.40370383858680725\n",
      "Epoch 32: train loss: 0.5332896709442139\n",
      "Epoch 32: train loss: 0.46215125918388367\n",
      "Epoch 32: train loss: 0.507291853427887\n",
      "Epoch 32: train loss: 0.41721203923225403\n",
      "Epoch 32: train loss: 0.5597097277641296\n",
      "Epoch 32: train loss: 0.5493453145027161\n",
      "Epoch 32: train loss: 0.6630167365074158\n",
      "Epoch 32: train loss: 0.604531466960907\n",
      "Epoch 32: train loss: 0.5194470286369324\n",
      "Epoch 32: train loss: 0.550449788570404\n",
      "Epoch 32: train loss: 0.539434552192688\n",
      "Epoch 32: train loss: 0.571697473526001\n",
      "Epoch 32: train loss: 0.5030452609062195\n",
      "Epoch 32: train loss: 0.4767548441886902\n",
      "Epoch 32: train loss: 0.5280847549438477\n",
      "Epoch 32: train loss: 0.44490426778793335\n",
      "Epoch 32: train loss: 0.6262540817260742\n",
      "Epoch 32: train loss: 0.3780699074268341\n",
      "Epoch 32: train loss: 0.6199122071266174\n",
      "Epoch 32: train loss: 0.44892603158950806\n",
      "Epoch 32: train loss: 0.5984516739845276\n",
      "Epoch 32: train loss: 0.5563799142837524\n",
      "Epoch 32: train loss: 0.4519472122192383\n",
      "Epoch 32: train loss: 0.5809462666511536\n",
      "Epoch 32: train loss: 0.49647676944732666\n",
      "Epoch 32: train loss: 0.6640347242355347\n",
      "Epoch 32: train loss: 0.5312824249267578\n",
      "Epoch 32: train loss: 0.5701478719711304\n",
      "Epoch 32: train loss: 0.44240447878837585\n",
      "Epoch 32: train loss: 0.4580386281013489\n",
      "Epoch 32: train loss: 0.5599849820137024\n",
      "Epoch 32: train loss: 0.504649817943573\n",
      "Epoch 32: train loss: 0.58168625831604\n",
      "Epoch 32: train loss: 0.5821704268455505\n",
      "Epoch 32: train loss: 0.5020446181297302\n",
      "Epoch 32: train loss: 0.5431097745895386\n",
      "Epoch 32: train loss: 0.5300402045249939\n",
      "Epoch 32: train loss: 0.4580196738243103\n",
      "Epoch 32: train loss: 0.5828000903129578\n",
      "Epoch 32: train loss: 0.48249661922454834\n",
      "Epoch 32: train loss: 0.46187418699264526\n",
      "Epoch 32: train loss: 0.4998539388179779\n",
      "Epoch 32: train loss: 0.5588474869728088\n",
      "Epoch 32: train loss: 0.4816950261592865\n",
      "Epoch 32: train loss: 0.4406633675098419\n",
      "Epoch 32: train loss: 0.6345034837722778\n",
      "Epoch 32: train loss: 0.45327359437942505\n",
      "Epoch 32: train loss: 0.5569978356361389\n",
      "Epoch 32: train loss: 0.41611355543136597\n",
      "Epoch 32: train loss: 0.480007141828537\n",
      "Epoch 32: train loss: 0.7018496990203857\n",
      "Epoch 32: train loss: 0.6229192018508911\n",
      "Epoch 32: train loss: 0.5196518301963806\n",
      "Epoch 32: train loss: 0.5899431705474854\n",
      "Epoch 32: train loss: 0.7676081657409668\n",
      "Epoch 32: train loss: 0.6256741881370544\n",
      "Epoch 32: train loss: 0.38097864389419556\n",
      "Epoch 32: train loss: 0.5118915438652039\n",
      "Epoch 32: train loss: 0.5447928309440613\n",
      "Epoch 32: train loss: 0.6242672204971313\n",
      "Epoch 32: train loss: 0.5836468935012817\n",
      "Epoch 32: train loss: 0.6057387590408325\n",
      "Epoch 32: train loss: 0.3773626387119293\n",
      "Epoch 32: train loss: 0.6329748630523682\n",
      "Epoch 32: train loss: 0.46984657645225525\n",
      "Epoch 32: train loss: 0.4727015793323517\n",
      "Epoch 32: train loss: 0.5957891345024109\n",
      "Epoch 32: train loss: 0.5951491594314575\n",
      "Epoch 32: train loss: 0.6027373671531677\n",
      "Epoch 32: train loss: 0.6749975085258484\n",
      "Epoch 32: train loss: 0.507454514503479\n",
      "Epoch 32: train loss: 0.3847426772117615\n",
      "Epoch 32: train loss: 0.6035056710243225\n",
      "Epoch 32: train loss: 0.6029692888259888\n",
      "Epoch 32: train loss: 0.5770987868309021\n",
      "Epoch 32: train loss: 0.5024499297142029\n",
      "Epoch 32: train loss: 0.5593641996383667\n",
      "Epoch 32: train loss: 0.5245434045791626\n",
      "Epoch 32: train loss: 0.5761812925338745\n",
      "Epoch 32: train loss: 0.5888866782188416\n",
      "Epoch 32: train loss: 0.3705287575721741\n",
      "Epoch 32: train loss: 0.5921403765678406\n",
      "Epoch 32: train loss: 0.5180488228797913\n",
      "Epoch 32: train loss: 0.6095431447029114\n",
      "Epoch 32: train loss: 0.5183684825897217\n",
      "Epoch 32: train loss: 0.5367133617401123\n",
      "Epoch 32: train loss: 0.5394901633262634\n",
      "Epoch 32: train loss: 0.3392302989959717\n",
      "Epoch 32: train loss: 0.6252678036689758\n",
      "Epoch 32: train loss: 0.7209914922714233\n",
      "Epoch 32: train loss: 0.6382671594619751\n",
      "Epoch 32: train loss: 0.5263208746910095\n",
      "Epoch 32: train loss: 0.49600765109062195\n",
      "Epoch 32: train loss: 0.5531951785087585\n",
      "Epoch 32: train loss: 0.38947594165802\n",
      "Epoch 32: train loss: 0.48976999521255493\n",
      "Epoch 32: train loss: 0.4715842306613922\n",
      "Epoch 33: train loss: 0.49561193585395813\n",
      "Epoch 33: train loss: 0.5192686319351196\n",
      "Epoch 33: train loss: 0.631626546382904\n",
      "Epoch 33: train loss: 0.4790302813053131\n",
      "Epoch 33: train loss: 0.42650502920150757\n",
      "Epoch 33: train loss: 0.4312344491481781\n",
      "Epoch 33: train loss: 0.5128830075263977\n",
      "Epoch 33: train loss: 0.5517165660858154\n",
      "Epoch 33: train loss: 0.48959261178970337\n",
      "Epoch 33: train loss: 0.48366716504096985\n",
      "Epoch 33: train loss: 0.4622802138328552\n",
      "Epoch 33: train loss: 0.5864148139953613\n",
      "Epoch 33: train loss: 0.6031957268714905\n",
      "Epoch 33: train loss: 0.5906113982200623\n",
      "Epoch 33: train loss: 0.49372729659080505\n",
      "Epoch 33: train loss: 0.6814716458320618\n",
      "Epoch 33: train loss: 0.5953493118286133\n",
      "Epoch 33: train loss: 0.6285722851753235\n",
      "Epoch 33: train loss: 0.46387332677841187\n",
      "Epoch 33: train loss: 0.4214901626110077\n",
      "Epoch 33: train loss: 0.6155954003334045\n",
      "Epoch 33: train loss: 0.4929066598415375\n",
      "Epoch 33: train loss: 0.634097695350647\n",
      "Epoch 33: train loss: 0.5049665570259094\n",
      "Epoch 33: train loss: 0.4564068913459778\n",
      "Epoch 33: train loss: 0.701128363609314\n",
      "Epoch 33: train loss: 0.642725944519043\n",
      "Epoch 33: train loss: 0.5457639098167419\n",
      "Epoch 33: train loss: 0.5757843852043152\n",
      "Epoch 33: train loss: 0.6113260388374329\n",
      "Epoch 33: train loss: 0.45307421684265137\n",
      "Epoch 33: train loss: 0.43923795223236084\n",
      "Epoch 33: train loss: 0.5229360461235046\n",
      "Epoch 33: train loss: 0.7083185315132141\n",
      "Epoch 33: train loss: 0.486875981092453\n",
      "Epoch 33: train loss: 0.466691255569458\n",
      "Epoch 33: train loss: 0.5348147749900818\n",
      "Epoch 33: train loss: 0.5051165223121643\n",
      "Epoch 33: train loss: 0.6761738061904907\n",
      "Epoch 33: train loss: 0.4308532774448395\n",
      "Epoch 33: train loss: 0.5073806047439575\n",
      "Epoch 33: train loss: 0.6076353788375854\n",
      "Epoch 33: train loss: 0.6097666025161743\n",
      "Epoch 33: train loss: 0.6598289012908936\n",
      "Epoch 33: train loss: 0.41239774227142334\n",
      "Epoch 33: train loss: 0.46295464038848877\n",
      "Epoch 33: train loss: 0.5533435344696045\n",
      "Epoch 33: train loss: 0.6240185499191284\n",
      "Epoch 33: train loss: 0.4182010293006897\n",
      "Epoch 33: train loss: 0.5656994581222534\n",
      "Epoch 33: train loss: 0.47451627254486084\n",
      "Epoch 33: train loss: 0.5229986906051636\n",
      "Epoch 33: train loss: 0.5849679708480835\n",
      "Epoch 33: train loss: 0.6485258936882019\n",
      "Epoch 33: train loss: 0.4381248950958252\n",
      "Epoch 33: train loss: 0.6378254294395447\n",
      "Epoch 33: train loss: 0.5591743588447571\n",
      "Epoch 33: train loss: 0.6981508135795593\n",
      "Epoch 33: train loss: 0.6851257681846619\n",
      "Epoch 33: train loss: 0.5798560976982117\n",
      "Epoch 33: train loss: 0.6525866389274597\n",
      "Epoch 33: train loss: 0.4560055434703827\n",
      "Epoch 33: train loss: 0.6579500436782837\n",
      "Epoch 33: train loss: 0.4026033282279968\n",
      "Epoch 33: train loss: 0.482118159532547\n",
      "Epoch 33: train loss: 0.5698961615562439\n",
      "Epoch 33: train loss: 0.5553284287452698\n",
      "Epoch 33: train loss: 0.4551956355571747\n",
      "Epoch 33: train loss: 0.6123502254486084\n",
      "Epoch 33: train loss: 0.49691200256347656\n",
      "Epoch 33: train loss: 0.38118013739585876\n",
      "Epoch 33: train loss: 0.4571370780467987\n",
      "Epoch 33: train loss: 0.6978238821029663\n",
      "Epoch 33: train loss: 0.430247962474823\n",
      "Epoch 33: train loss: 0.48694607615470886\n",
      "Epoch 33: train loss: 0.4792594015598297\n",
      "Epoch 33: train loss: 0.5367871522903442\n",
      "Epoch 33: train loss: 0.5726761221885681\n",
      "Epoch 33: train loss: 0.4238227307796478\n",
      "Epoch 33: train loss: 0.6184173822402954\n",
      "Epoch 33: train loss: 0.631005048751831\n",
      "Epoch 33: train loss: 0.5208854675292969\n",
      "Epoch 33: train loss: 0.41945651173591614\n",
      "Epoch 33: train loss: 0.45439574122428894\n",
      "Epoch 33: train loss: 0.32841891050338745\n",
      "Epoch 33: train loss: 0.5230116844177246\n",
      "Epoch 33: train loss: 0.525528073310852\n",
      "Epoch 33: train loss: 0.4471074342727661\n",
      "Epoch 33: train loss: 0.5708519816398621\n",
      "Epoch 33: train loss: 0.5081803202629089\n",
      "Epoch 33: train loss: 0.45977285504341125\n",
      "Epoch 33: train loss: 0.5168445110321045\n",
      "Epoch 33: train loss: 0.33883827924728394\n",
      "Epoch 33: train loss: 0.5048288702964783\n",
      "Epoch 33: train loss: 0.5394111275672913\n",
      "Epoch 33: train loss: 0.5934980511665344\n",
      "Epoch 33: train loss: 0.4447874426841736\n",
      "Epoch 33: train loss: 0.574555516242981\n",
      "Epoch 33: train loss: 0.645595133304596\n",
      "Epoch 33: train loss: 0.4755440652370453\n",
      "Epoch 33: train loss: 0.8321164846420288\n",
      "Epoch 33: train loss: 0.5380969643592834\n",
      "Epoch 33: train loss: 0.5208434462547302\n",
      "Epoch 33: train loss: 0.6869391798973083\n",
      "Epoch 33: train loss: 0.5386972427368164\n",
      "Epoch 33: train loss: 0.5452152490615845\n",
      "Epoch 33: train loss: 0.4653429090976715\n",
      "Epoch 33: train loss: 0.4931866526603699\n",
      "Epoch 33: train loss: 0.42621108889579773\n",
      "Epoch 33: train loss: 0.6014854311943054\n",
      "Epoch 33: train loss: 0.49796345829963684\n",
      "Epoch 33: train loss: 0.7500246167182922\n",
      "Epoch 33: train loss: 0.42968592047691345\n",
      "Epoch 33: train loss: 0.41752269864082336\n",
      "Epoch 33: train loss: 0.48796284198760986\n",
      "Epoch 33: train loss: 0.40669670701026917\n",
      "Epoch 33: train loss: 0.5688921809196472\n",
      "Epoch 33: train loss: 0.5499177575111389\n",
      "Epoch 33: train loss: 0.7958923578262329\n",
      "Epoch 33: train loss: 0.4403000473976135\n",
      "Epoch 33: train loss: 0.5038450956344604\n",
      "Epoch 33: train loss: 0.5380286574363708\n",
      "Epoch 33: train loss: 0.6243317127227783\n",
      "Epoch 33: train loss: 0.6199755072593689\n",
      "Epoch 34: train loss: 0.5416970252990723\n",
      "Epoch 34: train loss: 0.6198587417602539\n",
      "Epoch 34: train loss: 0.6526572704315186\n",
      "Epoch 34: train loss: 0.5765765905380249\n",
      "Epoch 34: train loss: 0.5120944380760193\n",
      "Epoch 34: train loss: 0.5349888205528259\n",
      "Epoch 34: train loss: 0.4916990101337433\n",
      "Epoch 34: train loss: 0.498594731092453\n",
      "Epoch 34: train loss: 0.509480893611908\n",
      "Epoch 34: train loss: 0.4887341558933258\n",
      "Epoch 34: train loss: 0.6488584280014038\n",
      "Epoch 34: train loss: 0.648757815361023\n",
      "Epoch 34: train loss: 0.6860397458076477\n",
      "Epoch 34: train loss: 0.7741163969039917\n",
      "Epoch 34: train loss: 0.5073405504226685\n",
      "Epoch 34: train loss: 0.4641774892807007\n",
      "Epoch 34: train loss: 0.5385791063308716\n",
      "Epoch 34: train loss: 0.5577093958854675\n",
      "Epoch 34: train loss: 0.5421593189239502\n",
      "Epoch 34: train loss: 0.6335930824279785\n",
      "Epoch 34: train loss: 0.4155070185661316\n",
      "Epoch 34: train loss: 0.5037022829055786\n",
      "Epoch 34: train loss: 0.6052752137184143\n",
      "Epoch 34: train loss: 0.48561620712280273\n",
      "Epoch 34: train loss: 0.5239176750183105\n",
      "Epoch 34: train loss: 0.4483723044395447\n",
      "Epoch 34: train loss: 0.5746682286262512\n",
      "Epoch 34: train loss: 0.49708840250968933\n",
      "Epoch 34: train loss: 0.48961955308914185\n",
      "Epoch 34: train loss: 0.6319558620452881\n",
      "Epoch 34: train loss: 0.5507539510726929\n",
      "Epoch 34: train loss: 0.5167793035507202\n",
      "Epoch 34: train loss: 0.6075423359870911\n",
      "Epoch 34: train loss: 0.5227947235107422\n",
      "Epoch 34: train loss: 0.5225825309753418\n",
      "Epoch 34: train loss: 0.5052849650382996\n",
      "Epoch 34: train loss: 0.4745228588581085\n",
      "Epoch 34: train loss: 0.7942498922348022\n",
      "Epoch 34: train loss: 0.5635634064674377\n",
      "Epoch 34: train loss: 0.5453474521636963\n",
      "Epoch 34: train loss: 0.5855798721313477\n",
      "Epoch 34: train loss: 0.7424589395523071\n",
      "Epoch 34: train loss: 0.4617823362350464\n",
      "Epoch 34: train loss: 0.4653489291667938\n",
      "Epoch 34: train loss: 0.5783507227897644\n",
      "Epoch 34: train loss: 0.4784373641014099\n",
      "Epoch 34: train loss: 0.29138192534446716\n",
      "Epoch 34: train loss: 0.47897714376449585\n",
      "Epoch 34: train loss: 0.4582795202732086\n",
      "Epoch 34: train loss: 0.48746082186698914\n",
      "Epoch 34: train loss: 0.5803290009498596\n",
      "Epoch 34: train loss: 0.45062702894210815\n",
      "Epoch 34: train loss: 0.45631396770477295\n",
      "Epoch 34: train loss: 0.5905603170394897\n",
      "Epoch 34: train loss: 0.6466222405433655\n",
      "Epoch 34: train loss: 0.6500409245491028\n",
      "Epoch 34: train loss: 0.5835026502609253\n",
      "Epoch 34: train loss: 0.5929067134857178\n",
      "Epoch 34: train loss: 0.4627252221107483\n",
      "Epoch 34: train loss: 0.4295456111431122\n",
      "Epoch 34: train loss: 0.518914520740509\n",
      "Epoch 34: train loss: 0.4273705780506134\n",
      "Epoch 34: train loss: 0.6517819762229919\n",
      "Epoch 34: train loss: 0.3637101352214813\n",
      "Epoch 34: train loss: 0.534571647644043\n",
      "Epoch 34: train loss: 0.48507893085479736\n",
      "Epoch 34: train loss: 0.6780055165290833\n",
      "Epoch 34: train loss: 0.7333676815032959\n",
      "Epoch 34: train loss: 0.46173012256622314\n",
      "Epoch 34: train loss: 0.5628225207328796\n",
      "Epoch 34: train loss: 0.4944742023944855\n",
      "Epoch 34: train loss: 0.5020972490310669\n",
      "Epoch 34: train loss: 0.5631316304206848\n",
      "Epoch 34: train loss: 0.5038086771965027\n",
      "Epoch 34: train loss: 0.44273239374160767\n",
      "Epoch 34: train loss: 0.49109745025634766\n",
      "Epoch 34: train loss: 0.8450403809547424\n",
      "Epoch 34: train loss: 0.672760546207428\n",
      "Epoch 34: train loss: 0.6136542558670044\n",
      "Epoch 34: train loss: 0.6302224397659302\n",
      "Epoch 34: train loss: 0.5960665941238403\n",
      "Epoch 34: train loss: 0.5308407545089722\n",
      "Epoch 34: train loss: 0.6248825788497925\n",
      "Epoch 34: train loss: 0.4068151116371155\n",
      "Epoch 34: train loss: 0.5758981704711914\n",
      "Epoch 34: train loss: 0.5300260186195374\n",
      "Epoch 34: train loss: 0.5953296422958374\n",
      "Epoch 34: train loss: 0.6206007599830627\n",
      "Epoch 34: train loss: 0.5113381743431091\n",
      "Epoch 34: train loss: 0.6090647578239441\n",
      "Epoch 34: train loss: 0.4097523093223572\n",
      "Epoch 34: train loss: 0.5470703840255737\n",
      "Epoch 34: train loss: 0.55314701795578\n",
      "Epoch 34: train loss: 0.617855966091156\n",
      "Epoch 34: train loss: 0.47010910511016846\n",
      "Epoch 34: train loss: 0.5835294127464294\n",
      "Epoch 34: train loss: 0.5006309747695923\n",
      "Epoch 34: train loss: 0.547683835029602\n",
      "Epoch 34: train loss: 0.48043420910835266\n",
      "Epoch 34: train loss: 0.4817151725292206\n",
      "Epoch 34: train loss: 0.5130716562271118\n",
      "Epoch 34: train loss: 0.49045175313949585\n",
      "Epoch 34: train loss: 0.3907114267349243\n",
      "Epoch 34: train loss: 0.47577476501464844\n",
      "Epoch 34: train loss: 0.5431092381477356\n",
      "Epoch 34: train loss: 0.5979467034339905\n",
      "Epoch 34: train loss: 0.4871729612350464\n",
      "Epoch 34: train loss: 0.509657084941864\n",
      "Epoch 34: train loss: 0.6033504009246826\n",
      "Epoch 34: train loss: 0.425143837928772\n",
      "Epoch 34: train loss: 0.40575581789016724\n",
      "Epoch 34: train loss: 0.4231838285923004\n",
      "Epoch 34: train loss: 0.39819249510765076\n",
      "Epoch 34: train loss: 0.5318476557731628\n",
      "Epoch 34: train loss: 0.5133681297302246\n",
      "Epoch 34: train loss: 0.48446160554885864\n",
      "Epoch 34: train loss: 0.6131709218025208\n",
      "Epoch 34: train loss: 0.5617811679840088\n",
      "Epoch 34: train loss: 0.51976078748703\n",
      "Epoch 34: train loss: 0.5685970783233643\n",
      "Epoch 34: train loss: 0.668671190738678\n",
      "Epoch 34: train loss: 0.4610930383205414\n",
      "Epoch 34: train loss: 0.2716887295246124\n",
      "Epoch 34: train loss: 0.6574569344520569\n",
      "Epoch 35: train loss: 0.52909255027771\n",
      "Epoch 35: train loss: 0.6290976405143738\n",
      "Epoch 35: train loss: 0.48380371928215027\n",
      "Epoch 35: train loss: 0.7188940048217773\n",
      "Epoch 35: train loss: 0.47486627101898193\n",
      "Epoch 35: train loss: 0.4769567549228668\n",
      "Epoch 35: train loss: 0.5895550847053528\n",
      "Epoch 35: train loss: 0.5685048699378967\n",
      "Epoch 35: train loss: 0.5876739025115967\n",
      "Epoch 35: train loss: 0.5998446345329285\n",
      "Epoch 35: train loss: 0.4946455657482147\n",
      "Epoch 35: train loss: 0.5523122549057007\n",
      "Epoch 35: train loss: 0.6322826743125916\n",
      "Epoch 35: train loss: 0.41295188665390015\n",
      "Epoch 35: train loss: 0.6607009172439575\n",
      "Epoch 35: train loss: 0.47185030579566956\n",
      "Epoch 35: train loss: 0.48180729150772095\n",
      "Epoch 35: train loss: 0.592869758605957\n",
      "Epoch 35: train loss: 0.5580074191093445\n",
      "Epoch 35: train loss: 0.60942143201828\n",
      "Epoch 35: train loss: 0.5117040872573853\n",
      "Epoch 35: train loss: 0.5535730719566345\n",
      "Epoch 35: train loss: 0.4262884259223938\n",
      "Epoch 35: train loss: 0.4829622507095337\n",
      "Epoch 35: train loss: 0.5798302292823792\n",
      "Epoch 35: train loss: 0.6230855584144592\n",
      "Epoch 35: train loss: 0.5091202259063721\n",
      "Epoch 35: train loss: 0.45706990361213684\n",
      "Epoch 35: train loss: 0.6137030720710754\n",
      "Epoch 35: train loss: 0.6213226914405823\n",
      "Epoch 35: train loss: 0.6727294921875\n",
      "Epoch 35: train loss: 0.5510534644126892\n",
      "Epoch 35: train loss: 0.43856632709503174\n",
      "Epoch 35: train loss: 0.4880886971950531\n",
      "Epoch 35: train loss: 0.4759591519832611\n",
      "Epoch 35: train loss: 0.4981505572795868\n",
      "Epoch 35: train loss: 0.5580730438232422\n",
      "Epoch 35: train loss: 0.5667787790298462\n",
      "Epoch 35: train loss: 0.529387891292572\n",
      "Epoch 35: train loss: 0.5026900172233582\n",
      "Epoch 35: train loss: 0.46304062008857727\n",
      "Epoch 35: train loss: 0.3806068003177643\n",
      "Epoch 35: train loss: 0.673993706703186\n",
      "Epoch 35: train loss: 0.4237956702709198\n",
      "Epoch 35: train loss: 0.5668732523918152\n",
      "Epoch 35: train loss: 0.5084092617034912\n",
      "Epoch 35: train loss: 0.5354886651039124\n",
      "Epoch 35: train loss: 0.4736596345901489\n",
      "Epoch 35: train loss: 0.4848364591598511\n",
      "Epoch 35: train loss: 0.4768281877040863\n",
      "Epoch 35: train loss: 0.43000465631484985\n",
      "Epoch 35: train loss: 0.5614603161811829\n",
      "Epoch 35: train loss: 0.5946716666221619\n",
      "Epoch 35: train loss: 0.7254123687744141\n",
      "Epoch 35: train loss: 0.39229127764701843\n",
      "Epoch 35: train loss: 0.3861480951309204\n",
      "Epoch 35: train loss: 0.5491753816604614\n",
      "Epoch 35: train loss: 0.41555625200271606\n",
      "Epoch 35: train loss: 0.5552046298980713\n",
      "Epoch 35: train loss: 0.47994470596313477\n",
      "Epoch 35: train loss: 0.5592947006225586\n",
      "Epoch 35: train loss: 0.5053704380989075\n",
      "Epoch 35: train loss: 0.4674653708934784\n",
      "Epoch 35: train loss: 0.756924569606781\n",
      "Epoch 35: train loss: 0.6248301267623901\n",
      "Epoch 35: train loss: 0.7676696181297302\n",
      "Epoch 35: train loss: 0.45294585824012756\n",
      "Epoch 35: train loss: 0.5258575677871704\n",
      "Epoch 35: train loss: 0.7150139808654785\n",
      "Epoch 35: train loss: 0.6846426725387573\n",
      "Epoch 35: train loss: 0.39129289984703064\n",
      "Epoch 35: train loss: 0.7115051746368408\n",
      "Epoch 35: train loss: 0.4979096055030823\n",
      "Epoch 35: train loss: 0.3722064197063446\n",
      "Epoch 35: train loss: 0.45278310775756836\n",
      "Epoch 35: train loss: 0.60231614112854\n",
      "Epoch 35: train loss: 0.4619600772857666\n",
      "Epoch 35: train loss: 0.3989463150501251\n",
      "Epoch 35: train loss: 0.5585982799530029\n",
      "Epoch 35: train loss: 0.5636603236198425\n",
      "Epoch 35: train loss: 0.6664710640907288\n",
      "Epoch 35: train loss: 0.5694941878318787\n",
      "Epoch 35: train loss: 0.4677542448043823\n",
      "Epoch 35: train loss: 0.5868975520133972\n",
      "Epoch 35: train loss: 0.7200132012367249\n",
      "Epoch 35: train loss: 0.46908125281333923\n",
      "Epoch 35: train loss: 0.7770158648490906\n",
      "Epoch 35: train loss: 0.6394429206848145\n",
      "Epoch 35: train loss: 0.38072076439857483\n",
      "Epoch 35: train loss: 0.4727313816547394\n",
      "Epoch 35: train loss: 0.6087847352027893\n",
      "Epoch 35: train loss: 0.48960819840431213\n",
      "Epoch 35: train loss: 0.49608755111694336\n",
      "Epoch 35: train loss: 0.7292449474334717\n",
      "Epoch 35: train loss: 0.6314916610717773\n",
      "Epoch 35: train loss: 0.4848940968513489\n",
      "Epoch 35: train loss: 0.5556639432907104\n",
      "Epoch 35: train loss: 0.5526286959648132\n",
      "Epoch 35: train loss: 0.565434455871582\n",
      "Epoch 35: train loss: 0.5529104471206665\n",
      "Epoch 35: train loss: 0.5629529356956482\n",
      "Epoch 35: train loss: 0.6078632473945618\n",
      "Epoch 35: train loss: 0.5667875409126282\n",
      "Epoch 35: train loss: 0.5420299172401428\n",
      "Epoch 35: train loss: 0.5449361205101013\n",
      "Epoch 35: train loss: 0.6029552221298218\n",
      "Epoch 35: train loss: 0.44351884722709656\n",
      "Epoch 35: train loss: 0.6329166293144226\n",
      "Epoch 35: train loss: 0.5848530530929565\n",
      "Epoch 35: train loss: 0.5067092180252075\n",
      "Epoch 35: train loss: 0.5644974112510681\n",
      "Epoch 35: train loss: 0.667854905128479\n",
      "Epoch 35: train loss: 0.492849737405777\n",
      "Epoch 35: train loss: 0.5998783707618713\n",
      "Epoch 35: train loss: 0.4915655255317688\n",
      "Epoch 35: train loss: 0.5069180727005005\n",
      "Epoch 35: train loss: 0.44266408681869507\n",
      "Epoch 35: train loss: 0.419055700302124\n",
      "Epoch 35: train loss: 0.5214186906814575\n",
      "Epoch 35: train loss: 0.4967145323753357\n",
      "Epoch 35: train loss: 0.4600732624530792\n",
      "Epoch 35: train loss: 0.4374181628227234\n",
      "Epoch 35: train loss: 0.6201911568641663\n",
      "Epoch 35: train loss: 0.32929813861846924\n",
      "Epoch 36: train loss: 0.4633951783180237\n",
      "Epoch 36: train loss: 0.46952661871910095\n",
      "Epoch 36: train loss: 0.6377921104431152\n",
      "Epoch 36: train loss: 0.651526927947998\n",
      "Epoch 36: train loss: 0.5553937554359436\n",
      "Epoch 36: train loss: 0.6911734938621521\n",
      "Epoch 36: train loss: 0.5406508445739746\n",
      "Epoch 36: train loss: 0.567460298538208\n",
      "Epoch 36: train loss: 0.4071497619152069\n",
      "Epoch 36: train loss: 0.5038163661956787\n",
      "Epoch 36: train loss: 0.43445366621017456\n",
      "Epoch 36: train loss: 0.3926643133163452\n",
      "Epoch 36: train loss: 0.3855072557926178\n",
      "Epoch 36: train loss: 0.4864601790904999\n",
      "Epoch 36: train loss: 0.6696634888648987\n",
      "Epoch 36: train loss: 0.5264144539833069\n",
      "Epoch 36: train loss: 0.4603723883628845\n",
      "Epoch 36: train loss: 0.5693272352218628\n",
      "Epoch 36: train loss: 0.5723724961280823\n",
      "Epoch 36: train loss: 0.40593886375427246\n",
      "Epoch 36: train loss: 0.5901626348495483\n",
      "Epoch 36: train loss: 0.4997848570346832\n",
      "Epoch 36: train loss: 0.5422980189323425\n",
      "Epoch 36: train loss: 0.5761939287185669\n",
      "Epoch 36: train loss: 0.4330979585647583\n",
      "Epoch 36: train loss: 0.4946388900279999\n",
      "Epoch 36: train loss: 0.3623723089694977\n",
      "Epoch 36: train loss: 0.719758152961731\n",
      "Epoch 36: train loss: 0.42275938391685486\n",
      "Epoch 36: train loss: 0.5678662657737732\n",
      "Epoch 36: train loss: 0.5402935743331909\n",
      "Epoch 36: train loss: 0.49791786074638367\n",
      "Epoch 36: train loss: 0.5201286673545837\n",
      "Epoch 36: train loss: 0.616058886051178\n",
      "Epoch 36: train loss: 0.6636056303977966\n",
      "Epoch 36: train loss: 0.5817899703979492\n",
      "Epoch 36: train loss: 0.5931533575057983\n",
      "Epoch 36: train loss: 0.5391241312026978\n",
      "Epoch 36: train loss: 0.4838407337665558\n",
      "Epoch 36: train loss: 0.4442348778247833\n",
      "Epoch 36: train loss: 0.5682056546211243\n",
      "Epoch 36: train loss: 0.6443248987197876\n",
      "Epoch 36: train loss: 0.6730018258094788\n",
      "Epoch 36: train loss: 0.4275965988636017\n",
      "Epoch 36: train loss: 0.6030672788619995\n",
      "Epoch 36: train loss: 0.3598868250846863\n",
      "Epoch 36: train loss: 0.4408430755138397\n",
      "Epoch 36: train loss: 0.5421858429908752\n",
      "Epoch 36: train loss: 0.5407650470733643\n",
      "Epoch 36: train loss: 0.7528274655342102\n",
      "Epoch 36: train loss: 0.45342719554901123\n",
      "Epoch 36: train loss: 0.36640769243240356\n",
      "Epoch 36: train loss: 0.5911190509796143\n",
      "Epoch 36: train loss: 0.5323277711868286\n",
      "Epoch 36: train loss: 0.6333383321762085\n",
      "Epoch 36: train loss: 0.5994139313697815\n",
      "Epoch 36: train loss: 0.4632100760936737\n",
      "Epoch 36: train loss: 0.5796446204185486\n",
      "Epoch 36: train loss: 0.5883654952049255\n",
      "Epoch 36: train loss: 0.5838748216629028\n",
      "Epoch 36: train loss: 0.5964648723602295\n",
      "Epoch 36: train loss: 0.46486514806747437\n",
      "Epoch 36: train loss: 0.49012085795402527\n",
      "Epoch 36: train loss: 0.5901838541030884\n",
      "Epoch 36: train loss: 0.5362970232963562\n",
      "Epoch 36: train loss: 0.6439161896705627\n",
      "Epoch 36: train loss: 0.5189278721809387\n",
      "Epoch 36: train loss: 0.5580006241798401\n",
      "Epoch 36: train loss: 0.3658369481563568\n",
      "Epoch 36: train loss: 0.46465837955474854\n",
      "Epoch 36: train loss: 0.584182620048523\n",
      "Epoch 36: train loss: 0.6716906428337097\n",
      "Epoch 36: train loss: 0.4774005115032196\n",
      "Epoch 36: train loss: 0.6541621088981628\n",
      "Epoch 36: train loss: 0.5711957216262817\n",
      "Epoch 36: train loss: 0.5898907780647278\n",
      "Epoch 36: train loss: 0.5328068137168884\n",
      "Epoch 36: train loss: 0.6213701367378235\n",
      "Epoch 36: train loss: 0.6078803539276123\n",
      "Epoch 36: train loss: 0.49207955598831177\n",
      "Epoch 36: train loss: 0.4451110064983368\n",
      "Epoch 36: train loss: 0.5600619912147522\n",
      "Epoch 36: train loss: 0.5650045275688171\n",
      "Epoch 36: train loss: 0.4862402677536011\n",
      "Epoch 36: train loss: 0.41125091910362244\n",
      "Epoch 36: train loss: 0.6022079586982727\n",
      "Epoch 36: train loss: 0.737847626209259\n",
      "Epoch 36: train loss: 0.3954940140247345\n",
      "Epoch 36: train loss: 0.5080264210700989\n",
      "Epoch 36: train loss: 0.5159826874732971\n",
      "Epoch 36: train loss: 0.5384240746498108\n",
      "Epoch 36: train loss: 0.4843669831752777\n",
      "Epoch 36: train loss: 0.6573176383972168\n",
      "Epoch 36: train loss: 0.47397875785827637\n",
      "Epoch 36: train loss: 0.6330115795135498\n",
      "Epoch 36: train loss: 0.6317117214202881\n",
      "Epoch 36: train loss: 0.4246138632297516\n",
      "Epoch 36: train loss: 0.5681978464126587\n",
      "Epoch 36: train loss: 0.60749751329422\n",
      "Epoch 36: train loss: 0.5174662470817566\n",
      "Epoch 36: train loss: 0.5339984893798828\n",
      "Epoch 36: train loss: 0.5283015966415405\n",
      "Epoch 36: train loss: 0.540682315826416\n",
      "Epoch 36: train loss: 0.4789906442165375\n",
      "Epoch 36: train loss: 0.6574233174324036\n",
      "Epoch 36: train loss: 0.5654582977294922\n",
      "Epoch 36: train loss: 0.5758781433105469\n",
      "Epoch 36: train loss: 0.41189855337142944\n",
      "Epoch 36: train loss: 0.5149306058883667\n",
      "Epoch 36: train loss: 0.5289512872695923\n",
      "Epoch 36: train loss: 0.4858192205429077\n",
      "Epoch 36: train loss: 0.5069427490234375\n",
      "Epoch 36: train loss: 0.5862969160079956\n",
      "Epoch 36: train loss: 0.5257875919342041\n",
      "Epoch 36: train loss: 0.5037182569503784\n",
      "Epoch 36: train loss: 0.47891297936439514\n",
      "Epoch 36: train loss: 0.49639618396759033\n",
      "Epoch 36: train loss: 0.560354471206665\n",
      "Epoch 36: train loss: 0.5486502051353455\n",
      "Epoch 36: train loss: 0.5126715898513794\n",
      "Epoch 36: train loss: 0.5770638585090637\n",
      "Epoch 36: train loss: 0.5435011982917786\n",
      "Epoch 36: train loss: 0.5646419525146484\n",
      "Epoch 36: train loss: 0.4054780900478363\n",
      "Epoch 37: train loss: 0.7060550451278687\n",
      "Epoch 37: train loss: 0.6981398463249207\n",
      "Epoch 37: train loss: 0.48463910818099976\n",
      "Epoch 37: train loss: 0.5819187760353088\n",
      "Epoch 37: train loss: 0.5922132730484009\n",
      "Epoch 37: train loss: 0.5231660008430481\n",
      "Epoch 37: train loss: 0.5565029978752136\n",
      "Epoch 37: train loss: 0.5949273705482483\n",
      "Epoch 37: train loss: 0.4994092285633087\n",
      "Epoch 37: train loss: 0.4731404483318329\n",
      "Epoch 37: train loss: 0.6649190783500671\n",
      "Epoch 37: train loss: 0.5721396803855896\n",
      "Epoch 37: train loss: 0.47572988271713257\n",
      "Epoch 37: train loss: 0.43728208541870117\n",
      "Epoch 37: train loss: 0.59168541431427\n",
      "Epoch 37: train loss: 0.48115667700767517\n",
      "Epoch 37: train loss: 0.6310313940048218\n",
      "Epoch 37: train loss: 0.6352326273918152\n",
      "Epoch 37: train loss: 0.4548587203025818\n",
      "Epoch 37: train loss: 0.43901264667510986\n",
      "Epoch 37: train loss: 0.4979287087917328\n",
      "Epoch 37: train loss: 0.5388075709342957\n",
      "Epoch 37: train loss: 0.5113174319267273\n",
      "Epoch 37: train loss: 0.5078107714653015\n",
      "Epoch 37: train loss: 0.4868212342262268\n",
      "Epoch 37: train loss: 0.33524736762046814\n",
      "Epoch 37: train loss: 0.4910643398761749\n",
      "Epoch 37: train loss: 0.5303751826286316\n",
      "Epoch 37: train loss: 0.5939412713050842\n",
      "Epoch 37: train loss: 0.4344511032104492\n",
      "Epoch 37: train loss: 0.41987547278404236\n",
      "Epoch 37: train loss: 0.6373071074485779\n",
      "Epoch 37: train loss: 0.548206627368927\n",
      "Epoch 37: train loss: 0.5694969296455383\n",
      "Epoch 37: train loss: 0.44734466075897217\n",
      "Epoch 37: train loss: 0.5744767785072327\n",
      "Epoch 37: train loss: 0.491224080324173\n",
      "Epoch 37: train loss: 0.3916599750518799\n",
      "Epoch 37: train loss: 0.6047751307487488\n",
      "Epoch 37: train loss: 0.40220656991004944\n",
      "Epoch 37: train loss: 0.5012246370315552\n",
      "Epoch 37: train loss: 0.461208313703537\n",
      "Epoch 37: train loss: 0.6184425950050354\n",
      "Epoch 37: train loss: 0.5039942860603333\n",
      "Epoch 37: train loss: 0.4449142813682556\n",
      "Epoch 37: train loss: 0.404494047164917\n",
      "Epoch 37: train loss: 0.3345337510108948\n",
      "Epoch 37: train loss: 0.606798529624939\n",
      "Epoch 37: train loss: 0.5307568907737732\n",
      "Epoch 37: train loss: 0.7631250023841858\n",
      "Epoch 37: train loss: 0.6907307505607605\n",
      "Epoch 37: train loss: 0.5120112895965576\n",
      "Epoch 37: train loss: 0.6806865334510803\n",
      "Epoch 37: train loss: 0.5837621092796326\n",
      "Epoch 37: train loss: 0.5438716411590576\n",
      "Epoch 37: train loss: 0.4342302083969116\n",
      "Epoch 37: train loss: 0.5675174593925476\n",
      "Epoch 37: train loss: 0.6257007122039795\n",
      "Epoch 37: train loss: 0.4014728367328644\n",
      "Epoch 37: train loss: 0.48171231150627136\n",
      "Epoch 37: train loss: 0.5128886699676514\n",
      "Epoch 37: train loss: 0.4598936140537262\n",
      "Epoch 37: train loss: 0.7235016226768494\n",
      "Epoch 37: train loss: 0.516575038433075\n",
      "Epoch 37: train loss: 0.6072438955307007\n",
      "Epoch 37: train loss: 0.3866541087627411\n",
      "Epoch 37: train loss: 0.41409802436828613\n",
      "Epoch 37: train loss: 0.5555901527404785\n",
      "Epoch 37: train loss: 0.5524132251739502\n",
      "Epoch 37: train loss: 0.48691731691360474\n",
      "Epoch 37: train loss: 0.47625598311424255\n",
      "Epoch 37: train loss: 0.5656313896179199\n",
      "Epoch 37: train loss: 0.4484342336654663\n",
      "Epoch 37: train loss: 0.6520976424217224\n",
      "Epoch 37: train loss: 0.6879809498786926\n",
      "Epoch 37: train loss: 0.568081796169281\n",
      "Epoch 37: train loss: 0.5411264896392822\n",
      "Epoch 37: train loss: 0.4857676029205322\n",
      "Epoch 37: train loss: 0.4957793354988098\n",
      "Epoch 37: train loss: 0.4915175139904022\n",
      "Epoch 37: train loss: 0.49331724643707275\n",
      "Epoch 37: train loss: 0.6607828736305237\n",
      "Epoch 37: train loss: 0.6052854061126709\n",
      "Epoch 37: train loss: 0.587310254573822\n",
      "Epoch 37: train loss: 0.6503598093986511\n",
      "Epoch 37: train loss: 0.5236596465110779\n",
      "Epoch 37: train loss: 0.6443818211555481\n",
      "Epoch 37: train loss: 0.5263489484786987\n",
      "Epoch 37: train loss: 0.33317434787750244\n",
      "Epoch 37: train loss: 0.5677072405815125\n",
      "Epoch 37: train loss: 0.43552538752555847\n",
      "Epoch 37: train loss: 0.4742880165576935\n",
      "Epoch 37: train loss: 0.4790034890174866\n",
      "Epoch 37: train loss: 0.47081056237220764\n",
      "Epoch 37: train loss: 0.5428285002708435\n",
      "Epoch 37: train loss: 0.520097553730011\n",
      "Epoch 37: train loss: 0.639336347579956\n",
      "Epoch 37: train loss: 0.38945436477661133\n",
      "Epoch 37: train loss: 0.3945886492729187\n",
      "Epoch 37: train loss: 0.6133604645729065\n",
      "Epoch 37: train loss: 0.5111604332923889\n",
      "Epoch 37: train loss: 0.5835079550743103\n",
      "Epoch 37: train loss: 0.486260324716568\n",
      "Epoch 37: train loss: 0.6344621181488037\n",
      "Epoch 37: train loss: 0.4379842281341553\n",
      "Epoch 37: train loss: 0.6231344938278198\n",
      "Epoch 37: train loss: 0.458337664604187\n",
      "Epoch 37: train loss: 0.539583146572113\n",
      "Epoch 37: train loss: 0.48988693952560425\n",
      "Epoch 37: train loss: 0.49793314933776855\n",
      "Epoch 37: train loss: 0.5415725111961365\n",
      "Epoch 37: train loss: 0.42341142892837524\n",
      "Epoch 37: train loss: 0.7443631887435913\n",
      "Epoch 37: train loss: 0.6617472767829895\n",
      "Epoch 37: train loss: 0.41531091928482056\n",
      "Epoch 37: train loss: 0.5901210904121399\n",
      "Epoch 37: train loss: 0.7482823729515076\n",
      "Epoch 37: train loss: 0.47744059562683105\n",
      "Epoch 37: train loss: 0.8020610213279724\n",
      "Epoch 37: train loss: 0.365488201379776\n",
      "Epoch 37: train loss: 0.6843461990356445\n",
      "Epoch 37: train loss: 0.5977206826210022\n",
      "Epoch 37: train loss: 0.721100389957428\n",
      "Epoch 37: train loss: 0.5900377631187439\n",
      "Epoch 38: train loss: 0.4867246747016907\n",
      "Epoch 38: train loss: 0.5854677557945251\n",
      "Epoch 38: train loss: 0.547410249710083\n",
      "Epoch 38: train loss: 0.6178151965141296\n",
      "Epoch 38: train loss: 0.5100212097167969\n",
      "Epoch 38: train loss: 0.45621657371520996\n",
      "Epoch 38: train loss: 0.4372797906398773\n",
      "Epoch 38: train loss: 0.5169016718864441\n",
      "Epoch 38: train loss: 0.4287925362586975\n",
      "Epoch 38: train loss: 0.4271954298019409\n",
      "Epoch 38: train loss: 0.549082338809967\n",
      "Epoch 38: train loss: 0.7192427515983582\n",
      "Epoch 38: train loss: 0.36080169677734375\n",
      "Epoch 38: train loss: 0.4389055669307709\n",
      "Epoch 38: train loss: 0.47974106669425964\n",
      "Epoch 38: train loss: 0.5718391537666321\n",
      "Epoch 38: train loss: 0.43535545468330383\n",
      "Epoch 38: train loss: 0.4830176830291748\n",
      "Epoch 38: train loss: 0.5795937180519104\n",
      "Epoch 38: train loss: 0.4749888777732849\n",
      "Epoch 38: train loss: 0.5442050695419312\n",
      "Epoch 38: train loss: 0.5462765693664551\n",
      "Epoch 38: train loss: 0.5677119493484497\n",
      "Epoch 38: train loss: 0.45821571350097656\n",
      "Epoch 38: train loss: 0.5867376923561096\n",
      "Epoch 38: train loss: 0.7546178698539734\n",
      "Epoch 38: train loss: 0.7241068482398987\n",
      "Epoch 38: train loss: 0.429185688495636\n",
      "Epoch 38: train loss: 0.6033609509468079\n",
      "Epoch 38: train loss: 0.5662484765052795\n",
      "Epoch 38: train loss: 0.43462035059928894\n",
      "Epoch 38: train loss: 0.41070884466171265\n",
      "Epoch 38: train loss: 0.48964637517929077\n",
      "Epoch 38: train loss: 0.5180987119674683\n",
      "Epoch 38: train loss: 0.603421688079834\n",
      "Epoch 38: train loss: 0.5945490002632141\n",
      "Epoch 38: train loss: 0.5122045874595642\n",
      "Epoch 38: train loss: 0.551507830619812\n",
      "Epoch 38: train loss: 0.5599119663238525\n",
      "Epoch 38: train loss: 0.42313534021377563\n",
      "Epoch 38: train loss: 0.5427279472351074\n",
      "Epoch 38: train loss: 0.5321612358093262\n",
      "Epoch 38: train loss: 0.7110076546669006\n",
      "Epoch 38: train loss: 0.394217312335968\n",
      "Epoch 38: train loss: 0.5056090950965881\n",
      "Epoch 38: train loss: 0.5137027502059937\n",
      "Epoch 38: train loss: 0.6247685551643372\n",
      "Epoch 38: train loss: 0.40964481234550476\n",
      "Epoch 38: train loss: 0.5777906179428101\n",
      "Epoch 38: train loss: 0.4081610441207886\n",
      "Epoch 38: train loss: 0.7014509439468384\n",
      "Epoch 38: train loss: 0.6048641800880432\n",
      "Epoch 38: train loss: 0.5775848031044006\n",
      "Epoch 38: train loss: 0.5461549162864685\n",
      "Epoch 38: train loss: 0.5875346660614014\n",
      "Epoch 38: train loss: 0.4903066158294678\n",
      "Epoch 38: train loss: 0.6107924580574036\n",
      "Epoch 38: train loss: 0.7046069502830505\n",
      "Epoch 38: train loss: 0.4076271057128906\n",
      "Epoch 38: train loss: 0.46935832500457764\n",
      "Epoch 38: train loss: 0.6906856894493103\n",
      "Epoch 38: train loss: 0.6235185861587524\n",
      "Epoch 38: train loss: 0.5503916144371033\n",
      "Epoch 38: train loss: 0.5279725193977356\n",
      "Epoch 38: train loss: 0.6334719061851501\n",
      "Epoch 38: train loss: 0.4315533936023712\n",
      "Epoch 38: train loss: 0.6347804069519043\n",
      "Epoch 38: train loss: 0.5405098795890808\n",
      "Epoch 38: train loss: 0.4967988133430481\n",
      "Epoch 38: train loss: 0.4671877920627594\n",
      "Epoch 38: train loss: 0.6425051689147949\n",
      "Epoch 38: train loss: 0.4689418375492096\n",
      "Epoch 38: train loss: 0.46211451292037964\n",
      "Epoch 38: train loss: 0.6415982842445374\n",
      "Epoch 38: train loss: 0.7551862597465515\n",
      "Epoch 38: train loss: 0.549602746963501\n",
      "Epoch 38: train loss: 0.6305803060531616\n",
      "Epoch 38: train loss: 0.5761662125587463\n",
      "Epoch 38: train loss: 0.6344435811042786\n",
      "Epoch 38: train loss: 0.5497601628303528\n",
      "Epoch 38: train loss: 0.5575779676437378\n",
      "Epoch 38: train loss: 0.636816680431366\n",
      "Epoch 38: train loss: 0.5628737211227417\n",
      "Epoch 38: train loss: 0.5793560147285461\n",
      "Epoch 38: train loss: 0.5088759660720825\n",
      "Epoch 38: train loss: 0.3780604898929596\n",
      "Epoch 38: train loss: 0.5267500281333923\n",
      "Epoch 38: train loss: 0.6121242046356201\n",
      "Epoch 38: train loss: 0.6471560597419739\n",
      "Epoch 38: train loss: 0.5357344746589661\n",
      "Epoch 38: train loss: 0.7179927825927734\n",
      "Epoch 38: train loss: 0.448447048664093\n",
      "Epoch 38: train loss: 0.5449208617210388\n",
      "Epoch 38: train loss: 0.509007453918457\n",
      "Epoch 38: train loss: 0.6807421445846558\n",
      "Epoch 38: train loss: 0.5036189556121826\n",
      "Epoch 38: train loss: 0.48253333568573\n",
      "Epoch 38: train loss: 0.6251883506774902\n",
      "Epoch 38: train loss: 0.5676717162132263\n",
      "Epoch 38: train loss: 0.44642919301986694\n",
      "Epoch 38: train loss: 0.49409183859825134\n",
      "Epoch 38: train loss: 0.4296589493751526\n",
      "Epoch 38: train loss: 0.4729274809360504\n",
      "Epoch 38: train loss: 0.3927146792411804\n",
      "Epoch 38: train loss: 0.3613017499446869\n",
      "Epoch 38: train loss: 0.46413904428482056\n",
      "Epoch 38: train loss: 0.6422861814498901\n",
      "Epoch 38: train loss: 0.3282371759414673\n",
      "Epoch 38: train loss: 0.527134120464325\n",
      "Epoch 38: train loss: 0.34878218173980713\n",
      "Epoch 38: train loss: 0.49195754528045654\n",
      "Epoch 38: train loss: 0.47197794914245605\n",
      "Epoch 38: train loss: 0.45860785245895386\n",
      "Epoch 38: train loss: 0.5904025435447693\n",
      "Epoch 38: train loss: 0.46995803713798523\n",
      "Epoch 38: train loss: 0.41261279582977295\n",
      "Epoch 38: train loss: 0.6778053641319275\n",
      "Epoch 38: train loss: 0.8243795037269592\n",
      "Epoch 38: train loss: 0.6507173180580139\n",
      "Epoch 38: train loss: 0.6092061400413513\n",
      "Epoch 38: train loss: 0.4809940457344055\n",
      "Epoch 38: train loss: 0.5717714428901672\n",
      "Epoch 38: train loss: 0.29278451204299927\n",
      "Epoch 38: train loss: 0.4218616187572479\n",
      "Epoch 39: train loss: 0.7121464610099792\n",
      "Epoch 39: train loss: 0.5756158828735352\n",
      "Epoch 39: train loss: 0.5726528763771057\n",
      "Epoch 39: train loss: 0.4047020673751831\n",
      "Epoch 39: train loss: 0.6840307116508484\n",
      "Epoch 39: train loss: 0.6128008365631104\n",
      "Epoch 39: train loss: 0.5220710039138794\n",
      "Epoch 39: train loss: 0.640487015247345\n",
      "Epoch 39: train loss: 0.3898654282093048\n",
      "Epoch 39: train loss: 0.5368492007255554\n",
      "Epoch 39: train loss: 0.5890321731567383\n",
      "Epoch 39: train loss: 0.5173129439353943\n",
      "Epoch 39: train loss: 0.45427703857421875\n",
      "Epoch 39: train loss: 0.5858388543128967\n",
      "Epoch 39: train loss: 0.605358362197876\n",
      "Epoch 39: train loss: 0.4794183671474457\n",
      "Epoch 39: train loss: 0.40691766142845154\n",
      "Epoch 39: train loss: 0.47373151779174805\n",
      "Epoch 39: train loss: 0.46831023693084717\n",
      "Epoch 39: train loss: 0.3923441469669342\n",
      "Epoch 39: train loss: 0.504535436630249\n",
      "Epoch 39: train loss: 0.4826752245426178\n",
      "Epoch 39: train loss: 0.5444397330284119\n",
      "Epoch 39: train loss: 0.47672924399375916\n",
      "Epoch 39: train loss: 0.4165761172771454\n",
      "Epoch 39: train loss: 0.4923394024372101\n",
      "Epoch 39: train loss: 0.7220370769500732\n",
      "Epoch 39: train loss: 0.5099707841873169\n",
      "Epoch 39: train loss: 0.5574985146522522\n",
      "Epoch 39: train loss: 0.5821979641914368\n",
      "Epoch 39: train loss: 0.45487362146377563\n",
      "Epoch 39: train loss: 0.4599340260028839\n",
      "Epoch 39: train loss: 0.6184931397438049\n",
      "Epoch 39: train loss: 0.5131962299346924\n",
      "Epoch 39: train loss: 0.6107722520828247\n",
      "Epoch 39: train loss: 0.5796021223068237\n",
      "Epoch 39: train loss: 0.5444653034210205\n",
      "Epoch 39: train loss: 0.7032715082168579\n",
      "Epoch 39: train loss: 0.44485795497894287\n",
      "Epoch 39: train loss: 0.5213465690612793\n",
      "Epoch 39: train loss: 0.6202694177627563\n",
      "Epoch 39: train loss: 0.521884560585022\n",
      "Epoch 39: train loss: 0.5986480712890625\n",
      "Epoch 39: train loss: 0.5102351307868958\n",
      "Epoch 39: train loss: 0.583755612373352\n",
      "Epoch 39: train loss: 0.5128384828567505\n",
      "Epoch 39: train loss: 0.6001365184783936\n",
      "Epoch 39: train loss: 0.456302285194397\n",
      "Epoch 39: train loss: 0.5315731763839722\n",
      "Epoch 39: train loss: 0.4873526990413666\n",
      "Epoch 39: train loss: 0.5405977964401245\n",
      "Epoch 39: train loss: 0.5141068696975708\n",
      "Epoch 39: train loss: 0.7308826446533203\n",
      "Epoch 39: train loss: 0.6165255308151245\n",
      "Epoch 39: train loss: 0.44738152623176575\n",
      "Epoch 39: train loss: 0.46635347604751587\n",
      "Epoch 39: train loss: 0.39564546942710876\n",
      "Epoch 39: train loss: 0.6163417100906372\n",
      "Epoch 39: train loss: 0.5974274277687073\n",
      "Epoch 39: train loss: 0.5594344139099121\n",
      "Epoch 39: train loss: 0.47976547479629517\n",
      "Epoch 39: train loss: 0.42493462562561035\n",
      "Epoch 39: train loss: 0.49440452456474304\n",
      "Epoch 39: train loss: 0.4771292209625244\n",
      "Epoch 39: train loss: 0.5636933445930481\n",
      "Epoch 39: train loss: 0.4099639058113098\n",
      "Epoch 39: train loss: 0.7834364175796509\n",
      "Epoch 39: train loss: 0.4816420078277588\n",
      "Epoch 39: train loss: 0.5816808342933655\n",
      "Epoch 39: train loss: 0.5328646302223206\n",
      "Epoch 39: train loss: 0.5919424891471863\n",
      "Epoch 39: train loss: 0.552710771560669\n",
      "Epoch 39: train loss: 0.5142495632171631\n",
      "Epoch 39: train loss: 0.617659866809845\n",
      "Epoch 39: train loss: 0.3476371765136719\n",
      "Epoch 39: train loss: 0.5782912969589233\n",
      "Epoch 39: train loss: 0.5215029120445251\n",
      "Epoch 39: train loss: 0.6156316995620728\n",
      "Epoch 39: train loss: 0.6814680099487305\n",
      "Epoch 39: train loss: 0.5582901835441589\n",
      "Epoch 39: train loss: 0.5327613353729248\n",
      "Epoch 39: train loss: 0.5117061138153076\n",
      "Epoch 39: train loss: 0.4289094805717468\n",
      "Epoch 39: train loss: 0.4791543781757355\n",
      "Epoch 39: train loss: 0.5131582021713257\n",
      "Epoch 39: train loss: 0.32451680302619934\n",
      "Epoch 39: train loss: 0.6281558871269226\n",
      "Epoch 39: train loss: 0.6412281394004822\n",
      "Epoch 39: train loss: 0.5998090505599976\n",
      "Epoch 39: train loss: 0.544185996055603\n",
      "Epoch 39: train loss: 0.6036965250968933\n",
      "Epoch 39: train loss: 0.4650229215621948\n",
      "Epoch 39: train loss: 0.6295021772384644\n",
      "Epoch 39: train loss: 0.4766102135181427\n",
      "Epoch 39: train loss: 0.4222428500652313\n",
      "Epoch 39: train loss: 0.3880378007888794\n",
      "Epoch 39: train loss: 0.5790148973464966\n",
      "Epoch 39: train loss: 0.5241268277168274\n",
      "Epoch 39: train loss: 0.3947770297527313\n",
      "Epoch 39: train loss: 0.540716290473938\n",
      "Epoch 39: train loss: 0.6094793677330017\n",
      "Epoch 39: train loss: 0.46804243326187134\n",
      "Epoch 39: train loss: 0.4794049561023712\n",
      "Epoch 39: train loss: 0.5795935988426208\n",
      "Epoch 39: train loss: 0.4512026011943817\n",
      "Epoch 39: train loss: 0.6629056930541992\n",
      "Epoch 39: train loss: 0.46790826320648193\n",
      "Epoch 39: train loss: 0.5228284597396851\n",
      "Epoch 39: train loss: 0.5317182540893555\n",
      "Epoch 39: train loss: 0.5244226455688477\n",
      "Epoch 39: train loss: 0.733631432056427\n",
      "Epoch 39: train loss: 0.6450636386871338\n",
      "Epoch 39: train loss: 0.49824783205986023\n",
      "Epoch 39: train loss: 0.48154041171073914\n",
      "Epoch 39: train loss: 0.6259424090385437\n",
      "Epoch 39: train loss: 0.5275742411613464\n",
      "Epoch 39: train loss: 0.6677018404006958\n",
      "Epoch 39: train loss: 0.4978490173816681\n",
      "Epoch 39: train loss: 0.48715800046920776\n",
      "Epoch 39: train loss: 0.3452332615852356\n",
      "Epoch 39: train loss: 0.6373202204704285\n",
      "Epoch 39: train loss: 0.4486195147037506\n",
      "Epoch 39: train loss: 0.48046571016311646\n",
      "Epoch 39: train loss: 0.6177992224693298\n",
      "Epoch 40: train loss: 0.7317941188812256\n",
      "Epoch 40: train loss: 0.5627520084381104\n",
      "Epoch 40: train loss: 0.5626938939094543\n",
      "Epoch 40: train loss: 0.5593451261520386\n",
      "Epoch 40: train loss: 0.366393506526947\n",
      "Epoch 40: train loss: 0.49088141322135925\n",
      "Epoch 40: train loss: 0.6058328151702881\n",
      "Epoch 40: train loss: 0.6649821996688843\n",
      "Epoch 40: train loss: 0.5873305797576904\n",
      "Epoch 40: train loss: 0.5075458884239197\n",
      "Epoch 40: train loss: 0.4218480885028839\n",
      "Epoch 40: train loss: 0.5037110447883606\n",
      "Epoch 40: train loss: 0.5242201089859009\n",
      "Epoch 40: train loss: 0.6109582185745239\n",
      "Epoch 40: train loss: 0.5354340076446533\n",
      "Epoch 40: train loss: 0.47226014733314514\n",
      "Epoch 40: train loss: 0.6331197023391724\n",
      "Epoch 40: train loss: 0.4907727837562561\n",
      "Epoch 40: train loss: 0.47438278794288635\n",
      "Epoch 40: train loss: 0.5896081328392029\n",
      "Epoch 40: train loss: 0.6180915832519531\n",
      "Epoch 40: train loss: 0.4598900377750397\n",
      "Epoch 40: train loss: 0.5281043648719788\n",
      "Epoch 40: train loss: 0.5188645720481873\n",
      "Epoch 40: train loss: 0.43369078636169434\n",
      "Epoch 40: train loss: 0.6194323301315308\n",
      "Epoch 40: train loss: 0.5713478922843933\n",
      "Epoch 40: train loss: 0.7205637097358704\n",
      "Epoch 40: train loss: 0.46903544664382935\n",
      "Epoch 40: train loss: 0.6449801921844482\n",
      "Epoch 40: train loss: 0.6185837984085083\n",
      "Epoch 40: train loss: 0.5480287075042725\n",
      "Epoch 40: train loss: 0.6164427399635315\n",
      "Epoch 40: train loss: 0.5637061595916748\n",
      "Epoch 40: train loss: 0.43503135442733765\n",
      "Epoch 40: train loss: 0.5082059502601624\n",
      "Epoch 40: train loss: 0.43921661376953125\n",
      "Epoch 40: train loss: 0.40148451924324036\n",
      "Epoch 40: train loss: 0.6654149889945984\n",
      "Epoch 40: train loss: 0.49623534083366394\n",
      "Epoch 40: train loss: 0.5773605704307556\n",
      "Epoch 40: train loss: 0.5687552690505981\n",
      "Epoch 40: train loss: 0.4182412028312683\n",
      "Epoch 40: train loss: 0.6060206294059753\n",
      "Epoch 40: train loss: 0.5701778531074524\n",
      "Epoch 40: train loss: 0.4873987138271332\n",
      "Epoch 40: train loss: 0.48981910943984985\n",
      "Epoch 40: train loss: 0.5692719221115112\n",
      "Epoch 40: train loss: 0.5836038589477539\n",
      "Epoch 40: train loss: 0.6030766367912292\n",
      "Epoch 40: train loss: 0.6996952891349792\n",
      "Epoch 40: train loss: 0.5263949632644653\n",
      "Epoch 40: train loss: 0.5387460589408875\n",
      "Epoch 40: train loss: 0.6566751003265381\n",
      "Epoch 40: train loss: 0.4553024470806122\n",
      "Epoch 40: train loss: 0.5062147974967957\n",
      "Epoch 40: train loss: 0.5807929039001465\n",
      "Epoch 40: train loss: 0.4504140317440033\n",
      "Epoch 40: train loss: 0.5209765434265137\n",
      "Epoch 40: train loss: 0.7072231769561768\n",
      "Epoch 40: train loss: 0.5001283288002014\n",
      "Epoch 40: train loss: 0.5914539694786072\n",
      "Epoch 40: train loss: 0.4903782904148102\n",
      "Epoch 40: train loss: 0.3698805868625641\n",
      "Epoch 40: train loss: 0.42197415232658386\n",
      "Epoch 40: train loss: 0.5599768757820129\n",
      "Epoch 40: train loss: 0.5700721740722656\n",
      "Epoch 40: train loss: 0.4803202450275421\n",
      "Epoch 40: train loss: 0.4806675612926483\n",
      "Epoch 40: train loss: 0.5603679418563843\n",
      "Epoch 40: train loss: 0.5981504917144775\n",
      "Epoch 40: train loss: 0.46653950214385986\n",
      "Epoch 40: train loss: 0.4056052267551422\n",
      "Epoch 40: train loss: 0.46249139308929443\n",
      "Epoch 40: train loss: 0.418281614780426\n",
      "Epoch 40: train loss: 0.6686580181121826\n",
      "Epoch 40: train loss: 0.4887899160385132\n",
      "Epoch 40: train loss: 0.50365149974823\n",
      "Epoch 40: train loss: 0.5662804245948792\n",
      "Epoch 40: train loss: 0.48658978939056396\n",
      "Epoch 40: train loss: 0.4811617434024811\n",
      "Epoch 40: train loss: 0.41815683245658875\n",
      "Epoch 40: train loss: 0.5898606777191162\n",
      "Epoch 40: train loss: 0.40579521656036377\n",
      "Epoch 40: train loss: 0.5254088044166565\n",
      "Epoch 40: train loss: 0.6340631246566772\n",
      "Epoch 40: train loss: 0.5396316051483154\n",
      "Epoch 40: train loss: 0.6353063583374023\n",
      "Epoch 40: train loss: 0.49908867478370667\n",
      "Epoch 40: train loss: 0.39306876063346863\n",
      "Epoch 40: train loss: 0.5652630925178528\n",
      "Epoch 40: train loss: 0.6317691802978516\n",
      "Epoch 40: train loss: 0.5745946168899536\n",
      "Epoch 40: train loss: 0.44069549441337585\n",
      "Epoch 40: train loss: 0.39437296986579895\n",
      "Epoch 40: train loss: 0.6537432670593262\n",
      "Epoch 40: train loss: 0.5786163806915283\n",
      "Epoch 40: train loss: 0.4056711196899414\n",
      "Epoch 40: train loss: 0.4547158181667328\n",
      "Epoch 40: train loss: 0.5853587985038757\n",
      "Epoch 40: train loss: 0.5303236246109009\n",
      "Epoch 40: train loss: 0.565570592880249\n",
      "Epoch 40: train loss: 0.5797971487045288\n",
      "Epoch 40: train loss: 0.6286702752113342\n",
      "Epoch 40: train loss: 0.37298473715782166\n",
      "Epoch 40: train loss: 0.6221603751182556\n",
      "Epoch 40: train loss: 0.5260506272315979\n",
      "Epoch 40: train loss: 0.5759523510932922\n",
      "Epoch 40: train loss: 0.6912313103675842\n",
      "Epoch 40: train loss: 0.46173912286758423\n",
      "Epoch 40: train loss: 0.5294221639633179\n",
      "Epoch 40: train loss: 0.6162242889404297\n",
      "Epoch 40: train loss: 0.5115818381309509\n",
      "Epoch 40: train loss: 0.4797830581665039\n",
      "Epoch 40: train loss: 0.4536111354827881\n",
      "Epoch 40: train loss: 0.5528804063796997\n",
      "Epoch 40: train loss: 0.5316746830940247\n",
      "Epoch 40: train loss: 0.4882376790046692\n",
      "Epoch 40: train loss: 0.588455319404602\n",
      "Epoch 40: train loss: 0.40643152594566345\n",
      "Epoch 40: train loss: 0.532305121421814\n",
      "Epoch 40: train loss: 0.5852646827697754\n",
      "Epoch 40: train loss: 0.40522509813308716\n",
      "Epoch 40: train loss: 0.574454665184021\n",
      "Epoch 41: train loss: 0.5173224210739136\n",
      "Epoch 41: train loss: 0.7195338606834412\n",
      "Epoch 41: train loss: 0.5411205291748047\n",
      "Epoch 41: train loss: 0.45228487253189087\n",
      "Epoch 41: train loss: 0.5035830736160278\n",
      "Epoch 41: train loss: 0.6025394797325134\n",
      "Epoch 41: train loss: 0.5956488847732544\n",
      "Epoch 41: train loss: 0.44222909212112427\n",
      "Epoch 41: train loss: 0.5813003182411194\n",
      "Epoch 41: train loss: 0.5391085147857666\n",
      "Epoch 41: train loss: 0.542820930480957\n",
      "Epoch 41: train loss: 0.5233691930770874\n",
      "Epoch 41: train loss: 0.5168285369873047\n",
      "Epoch 41: train loss: 0.42678698897361755\n",
      "Epoch 41: train loss: 0.4775736629962921\n",
      "Epoch 41: train loss: 0.5391867160797119\n",
      "Epoch 41: train loss: 0.5890327095985413\n",
      "Epoch 41: train loss: 0.32003873586654663\n",
      "Epoch 41: train loss: 0.48081955313682556\n",
      "Epoch 41: train loss: 0.6042501926422119\n",
      "Epoch 41: train loss: 0.7342973947525024\n",
      "Epoch 41: train loss: 0.4768781065940857\n",
      "Epoch 41: train loss: 0.5117245316505432\n",
      "Epoch 41: train loss: 0.5563534498214722\n",
      "Epoch 41: train loss: 0.6602991819381714\n",
      "Epoch 41: train loss: 0.4042346775531769\n",
      "Epoch 41: train loss: 0.5445857644081116\n",
      "Epoch 41: train loss: 0.5507468581199646\n",
      "Epoch 41: train loss: 0.5175909996032715\n",
      "Epoch 41: train loss: 0.48981401324272156\n",
      "Epoch 41: train loss: 0.8148643374443054\n",
      "Epoch 41: train loss: 0.42353928089141846\n",
      "Epoch 41: train loss: 0.4263947308063507\n",
      "Epoch 41: train loss: 0.43724751472473145\n",
      "Epoch 41: train loss: 0.49861618876457214\n",
      "Epoch 41: train loss: 0.48126474022865295\n",
      "Epoch 41: train loss: 0.49361300468444824\n",
      "Epoch 41: train loss: 0.5497943162918091\n",
      "Epoch 41: train loss: 0.3676992654800415\n",
      "Epoch 41: train loss: 0.5619753003120422\n",
      "Epoch 41: train loss: 0.5661696195602417\n",
      "Epoch 41: train loss: 0.376027375459671\n",
      "Epoch 41: train loss: 0.4731072187423706\n",
      "Epoch 41: train loss: 0.7713315486907959\n",
      "Epoch 41: train loss: 0.616044282913208\n",
      "Epoch 41: train loss: 0.6271661520004272\n",
      "Epoch 41: train loss: 0.5508100986480713\n",
      "Epoch 41: train loss: 0.5214136242866516\n",
      "Epoch 41: train loss: 0.5515154600143433\n",
      "Epoch 41: train loss: 0.5335718393325806\n",
      "Epoch 41: train loss: 0.6331169009208679\n",
      "Epoch 41: train loss: 0.5957631468772888\n",
      "Epoch 41: train loss: 0.566582977771759\n",
      "Epoch 41: train loss: 0.4013563394546509\n",
      "Epoch 41: train loss: 0.5971822142601013\n",
      "Epoch 41: train loss: 0.4572561979293823\n",
      "Epoch 41: train loss: 0.5737411379814148\n",
      "Epoch 41: train loss: 0.5704826712608337\n",
      "Epoch 41: train loss: 0.512630820274353\n",
      "Epoch 41: train loss: 0.544807493686676\n",
      "Epoch 41: train loss: 0.49429720640182495\n",
      "Epoch 41: train loss: 0.4684255123138428\n",
      "Epoch 41: train loss: 0.5158059597015381\n",
      "Epoch 41: train loss: 0.43745818734169006\n",
      "Epoch 41: train loss: 0.4738926887512207\n",
      "Epoch 41: train loss: 0.5381656885147095\n",
      "Epoch 41: train loss: 0.5933459401130676\n",
      "Epoch 41: train loss: 0.44091665744781494\n",
      "Epoch 41: train loss: 0.5755918622016907\n",
      "Epoch 41: train loss: 0.5308916568756104\n",
      "Epoch 41: train loss: 0.5654016137123108\n",
      "Epoch 41: train loss: 0.6628623008728027\n",
      "Epoch 41: train loss: 0.31119275093078613\n",
      "Epoch 41: train loss: 0.6910817623138428\n",
      "Epoch 41: train loss: 0.48830094933509827\n",
      "Epoch 41: train loss: 0.5924450159072876\n",
      "Epoch 41: train loss: 0.646161675453186\n",
      "Epoch 41: train loss: 0.573451817035675\n",
      "Epoch 41: train loss: 0.47986942529678345\n",
      "Epoch 41: train loss: 0.5302462577819824\n",
      "Epoch 41: train loss: 0.5157811641693115\n",
      "Epoch 41: train loss: 0.4308249056339264\n",
      "Epoch 41: train loss: 0.5143505334854126\n",
      "Epoch 41: train loss: 0.5597409605979919\n",
      "Epoch 41: train loss: 0.6542843580245972\n",
      "Epoch 41: train loss: 0.6950950026512146\n",
      "Epoch 41: train loss: 0.47436949610710144\n",
      "Epoch 41: train loss: 0.5155342221260071\n",
      "Epoch 41: train loss: 0.6209715008735657\n",
      "Epoch 41: train loss: 0.5418820381164551\n",
      "Epoch 41: train loss: 0.4968114495277405\n",
      "Epoch 41: train loss: 0.45968544483184814\n",
      "Epoch 41: train loss: 0.6158642768859863\n",
      "Epoch 41: train loss: 0.42011356353759766\n",
      "Epoch 41: train loss: 0.6053033471107483\n",
      "Epoch 41: train loss: 0.5316922664642334\n",
      "Epoch 41: train loss: 0.6259313821792603\n",
      "Epoch 41: train loss: 0.4980846643447876\n",
      "Epoch 41: train loss: 0.45856624841690063\n",
      "Epoch 41: train loss: 0.5224679112434387\n",
      "Epoch 41: train loss: 0.39764317870140076\n",
      "Epoch 41: train loss: 0.5153889060020447\n",
      "Epoch 41: train loss: 0.6580821871757507\n",
      "Epoch 41: train loss: 0.5671196579933167\n",
      "Epoch 41: train loss: 0.6372761130332947\n",
      "Epoch 41: train loss: 0.5847139954566956\n",
      "Epoch 41: train loss: 0.5072405338287354\n",
      "Epoch 41: train loss: 0.5666947364807129\n",
      "Epoch 41: train loss: 0.47808724641799927\n",
      "Epoch 41: train loss: 0.5685319304466248\n",
      "Epoch 41: train loss: 0.40926769375801086\n",
      "Epoch 41: train loss: 0.47662121057510376\n",
      "Epoch 41: train loss: 0.38891199231147766\n",
      "Epoch 41: train loss: 0.598111093044281\n",
      "Epoch 41: train loss: 0.4062800109386444\n",
      "Epoch 41: train loss: 0.7375962138175964\n",
      "Epoch 41: train loss: 0.5826528668403625\n",
      "Epoch 41: train loss: 0.33237993717193604\n",
      "Epoch 41: train loss: 0.5159383416175842\n",
      "Epoch 41: train loss: 0.536421537399292\n",
      "Epoch 41: train loss: 0.7755690813064575\n",
      "Epoch 41: train loss: 0.3844258785247803\n",
      "Epoch 41: train loss: 0.5113309621810913\n",
      "Epoch 41: train loss: 0.6113331913948059\n",
      "Epoch 42: train loss: 0.6483948230743408\n",
      "Epoch 42: train loss: 0.4734978973865509\n",
      "Epoch 42: train loss: 0.5211707949638367\n",
      "Epoch 42: train loss: 0.7492324709892273\n",
      "Epoch 42: train loss: 0.47031280398368835\n",
      "Epoch 42: train loss: 0.49538058042526245\n",
      "Epoch 42: train loss: 0.5107384324073792\n",
      "Epoch 42: train loss: 0.5763407349586487\n",
      "Epoch 42: train loss: 0.6030738353729248\n",
      "Epoch 42: train loss: 0.6002379059791565\n",
      "Epoch 42: train loss: 0.4292810261249542\n",
      "Epoch 42: train loss: 0.5963027477264404\n",
      "Epoch 42: train loss: 0.4639439284801483\n",
      "Epoch 42: train loss: 0.5773594975471497\n",
      "Epoch 42: train loss: 0.6361722946166992\n",
      "Epoch 42: train loss: 0.4845722019672394\n",
      "Epoch 42: train loss: 0.49508050084114075\n",
      "Epoch 42: train loss: 0.5685362815856934\n",
      "Epoch 42: train loss: 0.612223207950592\n",
      "Epoch 42: train loss: 0.42057421803474426\n",
      "Epoch 42: train loss: 0.43038633465766907\n",
      "Epoch 42: train loss: 0.5157883763313293\n",
      "Epoch 42: train loss: 0.5424538850784302\n",
      "Epoch 42: train loss: 0.5277278423309326\n",
      "Epoch 42: train loss: 0.5764686465263367\n",
      "Epoch 42: train loss: 0.5106668472290039\n",
      "Epoch 42: train loss: 0.5149520635604858\n",
      "Epoch 42: train loss: 0.6410223841667175\n",
      "Epoch 42: train loss: 0.4850080907344818\n",
      "Epoch 42: train loss: 0.6657792329788208\n",
      "Epoch 42: train loss: 0.7147206664085388\n",
      "Epoch 42: train loss: 0.4825786352157593\n",
      "Epoch 42: train loss: 0.45761311054229736\n",
      "Epoch 42: train loss: 0.6473597288131714\n",
      "Epoch 42: train loss: 0.5693150162696838\n",
      "Epoch 42: train loss: 0.5002425909042358\n",
      "Epoch 42: train loss: 0.5063850283622742\n",
      "Epoch 42: train loss: 0.6628177165985107\n",
      "Epoch 42: train loss: 0.6395021080970764\n",
      "Epoch 42: train loss: 0.6157785654067993\n",
      "Epoch 42: train loss: 0.6073777079582214\n",
      "Epoch 42: train loss: 0.6913766264915466\n",
      "Epoch 42: train loss: 0.6163747310638428\n",
      "Epoch 42: train loss: 0.49200519919395447\n",
      "Epoch 42: train loss: 0.4710799753665924\n",
      "Epoch 42: train loss: 0.4540778696537018\n",
      "Epoch 42: train loss: 0.5843316316604614\n",
      "Epoch 42: train loss: 0.6230369210243225\n",
      "Epoch 42: train loss: 0.5134698152542114\n",
      "Epoch 42: train loss: 0.46261104941368103\n",
      "Epoch 42: train loss: 0.5345917344093323\n",
      "Epoch 42: train loss: 0.5660665035247803\n",
      "Epoch 42: train loss: 0.4866148829460144\n",
      "Epoch 42: train loss: 0.45072025060653687\n",
      "Epoch 42: train loss: 0.5527211427688599\n",
      "Epoch 42: train loss: 0.46129342913627625\n",
      "Epoch 42: train loss: 0.45581313967704773\n",
      "Epoch 42: train loss: 0.5675240159034729\n",
      "Epoch 42: train loss: 0.5126903653144836\n",
      "Epoch 42: train loss: 0.4942868947982788\n",
      "Epoch 42: train loss: 0.5836014151573181\n",
      "Epoch 42: train loss: 0.7103326320648193\n",
      "Epoch 42: train loss: 0.5148663520812988\n",
      "Epoch 42: train loss: 0.48040762543678284\n",
      "Epoch 42: train loss: 0.5811828374862671\n",
      "Epoch 42: train loss: 0.6179449558258057\n",
      "Epoch 42: train loss: 0.6245081424713135\n",
      "Epoch 42: train loss: 0.4806317687034607\n",
      "Epoch 42: train loss: 0.4807961881160736\n",
      "Epoch 42: train loss: 0.5012580752372742\n",
      "Epoch 42: train loss: 0.5871497988700867\n",
      "Epoch 42: train loss: 0.5683765411376953\n",
      "Epoch 42: train loss: 0.607539713382721\n",
      "Epoch 42: train loss: 0.4679672420024872\n",
      "Epoch 42: train loss: 0.34688031673431396\n",
      "Epoch 42: train loss: 0.6129266619682312\n",
      "Epoch 42: train loss: 0.6501409411430359\n",
      "Epoch 42: train loss: 0.4383509159088135\n",
      "Epoch 42: train loss: 0.6313937306404114\n",
      "Epoch 42: train loss: 0.46404922008514404\n",
      "Epoch 42: train loss: 0.34173011779785156\n",
      "Epoch 42: train loss: 0.706141471862793\n",
      "Epoch 42: train loss: 0.44370386004447937\n",
      "Epoch 42: train loss: 0.5102659463882446\n",
      "Epoch 42: train loss: 0.33122679591178894\n",
      "Epoch 42: train loss: 0.36257967352867126\n",
      "Epoch 42: train loss: 0.5009450912475586\n",
      "Epoch 42: train loss: 0.5294584631919861\n",
      "Epoch 42: train loss: 0.5182880759239197\n",
      "Epoch 42: train loss: 0.627321183681488\n",
      "Epoch 42: train loss: 0.5026200413703918\n",
      "Epoch 42: train loss: 0.6309047937393188\n",
      "Epoch 42: train loss: 0.6019120216369629\n",
      "Epoch 42: train loss: 0.5018227100372314\n",
      "Epoch 42: train loss: 0.535696268081665\n",
      "Epoch 42: train loss: 0.4309099018573761\n",
      "Epoch 42: train loss: 0.6790772676467896\n",
      "Epoch 42: train loss: 0.5352970957756042\n",
      "Epoch 42: train loss: 0.4088858366012573\n",
      "Epoch 42: train loss: 0.4111228585243225\n",
      "Epoch 42: train loss: 0.5098689794540405\n",
      "Epoch 42: train loss: 0.5683226585388184\n",
      "Epoch 42: train loss: 0.5472618341445923\n",
      "Epoch 42: train loss: 0.5726308226585388\n",
      "Epoch 42: train loss: 0.45605969429016113\n",
      "Epoch 42: train loss: 0.4406156539916992\n",
      "Epoch 42: train loss: 0.3124716877937317\n",
      "Epoch 42: train loss: 0.5918036699295044\n",
      "Epoch 42: train loss: 0.5106300115585327\n",
      "Epoch 42: train loss: 0.41070523858070374\n",
      "Epoch 42: train loss: 0.610801637172699\n",
      "Epoch 42: train loss: 0.7460169196128845\n",
      "Epoch 42: train loss: 0.49924200773239136\n",
      "Epoch 42: train loss: 0.3748130202293396\n",
      "Epoch 42: train loss: 0.47814643383026123\n",
      "Epoch 42: train loss: 0.6262024641036987\n",
      "Epoch 42: train loss: 0.5770983099937439\n",
      "Epoch 42: train loss: 0.48235151171684265\n",
      "Epoch 42: train loss: 0.509087085723877\n",
      "Epoch 42: train loss: 0.49850133061408997\n",
      "Epoch 42: train loss: 0.5145986080169678\n",
      "Epoch 42: train loss: 0.6183938384056091\n",
      "Epoch 42: train loss: 0.5217218995094299\n",
      "Epoch 42: train loss: 0.5576159954071045\n",
      "Epoch 43: train loss: 0.4401423931121826\n",
      "Epoch 43: train loss: 0.7122915983200073\n",
      "Epoch 43: train loss: 0.5464574694633484\n",
      "Epoch 43: train loss: 0.569489061832428\n",
      "Epoch 43: train loss: 0.5252243876457214\n",
      "Epoch 43: train loss: 0.41316860914230347\n",
      "Epoch 43: train loss: 0.47789886593818665\n",
      "Epoch 43: train loss: 0.530491828918457\n",
      "Epoch 43: train loss: 0.5292133092880249\n",
      "Epoch 43: train loss: 0.4822272062301636\n",
      "Epoch 43: train loss: 0.5472648739814758\n",
      "Epoch 43: train loss: 0.3826833963394165\n",
      "Epoch 43: train loss: 0.6330971717834473\n",
      "Epoch 43: train loss: 0.49471667408943176\n",
      "Epoch 43: train loss: 0.5290461182594299\n",
      "Epoch 43: train loss: 0.4795059263706207\n",
      "Epoch 43: train loss: 0.6790825724601746\n",
      "Epoch 43: train loss: 0.5499337315559387\n",
      "Epoch 43: train loss: 0.5494484901428223\n",
      "Epoch 43: train loss: 0.610120415687561\n",
      "Epoch 43: train loss: 0.6304154992103577\n",
      "Epoch 43: train loss: 0.48050323128700256\n",
      "Epoch 43: train loss: 0.5305554866790771\n",
      "Epoch 43: train loss: 0.5882510542869568\n",
      "Epoch 43: train loss: 0.39580896496772766\n",
      "Epoch 43: train loss: 0.535002589225769\n",
      "Epoch 43: train loss: 0.5329117774963379\n",
      "Epoch 43: train loss: 0.6900335550308228\n",
      "Epoch 43: train loss: 0.6471585631370544\n",
      "Epoch 43: train loss: 0.4784587621688843\n",
      "Epoch 43: train loss: 0.4403158128261566\n",
      "Epoch 43: train loss: 0.6105340123176575\n",
      "Epoch 43: train loss: 0.452721506357193\n",
      "Epoch 43: train loss: 0.6007561683654785\n",
      "Epoch 43: train loss: 0.5326511859893799\n",
      "Epoch 43: train loss: 0.484145849943161\n",
      "Epoch 43: train loss: 0.7519007921218872\n",
      "Epoch 43: train loss: 0.5049595832824707\n",
      "Epoch 43: train loss: 0.406042218208313\n",
      "Epoch 43: train loss: 0.47026655077934265\n",
      "Epoch 43: train loss: 0.5793573260307312\n",
      "Epoch 43: train loss: 0.5876805782318115\n",
      "Epoch 43: train loss: 0.4697437584400177\n",
      "Epoch 43: train loss: 0.5531471967697144\n",
      "Epoch 43: train loss: 0.440896213054657\n",
      "Epoch 43: train loss: 0.5845833420753479\n",
      "Epoch 43: train loss: 0.6286145448684692\n",
      "Epoch 43: train loss: 0.6197142601013184\n",
      "Epoch 43: train loss: 0.43440619111061096\n",
      "Epoch 43: train loss: 0.45080843567848206\n",
      "Epoch 43: train loss: 0.45620882511138916\n",
      "Epoch 43: train loss: 0.5186946392059326\n",
      "Epoch 43: train loss: 0.6346522569656372\n",
      "Epoch 43: train loss: 0.44540733098983765\n",
      "Epoch 43: train loss: 0.5458800792694092\n",
      "Epoch 43: train loss: 0.7278727889060974\n",
      "Epoch 43: train loss: 0.531711995601654\n",
      "Epoch 43: train loss: 0.611370861530304\n",
      "Epoch 43: train loss: 0.5526132583618164\n",
      "Epoch 43: train loss: 0.3287717401981354\n",
      "Epoch 43: train loss: 0.5945319533348083\n",
      "Epoch 43: train loss: 0.5134446620941162\n",
      "Epoch 43: train loss: 0.5815486311912537\n",
      "Epoch 43: train loss: 0.5221410989761353\n",
      "Epoch 43: train loss: 0.5014429688453674\n",
      "Epoch 43: train loss: 0.589340090751648\n",
      "Epoch 43: train loss: 0.6803088784217834\n",
      "Epoch 43: train loss: 0.3202913999557495\n",
      "Epoch 43: train loss: 0.5045512914657593\n",
      "Epoch 43: train loss: 0.5597062706947327\n",
      "Epoch 43: train loss: 0.4376582205295563\n",
      "Epoch 43: train loss: 0.4471561014652252\n",
      "Epoch 43: train loss: 0.4652019739151001\n",
      "Epoch 43: train loss: 0.4082832932472229\n",
      "Epoch 43: train loss: 0.5245609283447266\n",
      "Epoch 43: train loss: 0.5276833772659302\n",
      "Epoch 43: train loss: 0.42894867062568665\n",
      "Epoch 43: train loss: 0.4295054078102112\n",
      "Epoch 43: train loss: 0.4693269431591034\n",
      "Epoch 43: train loss: 0.4497537612915039\n",
      "Epoch 43: train loss: 0.3851929008960724\n",
      "Epoch 43: train loss: 0.6132538914680481\n",
      "Epoch 43: train loss: 0.6616095304489136\n",
      "Epoch 43: train loss: 0.42576584219932556\n",
      "Epoch 43: train loss: 0.7064477205276489\n",
      "Epoch 43: train loss: 0.7113311290740967\n",
      "Epoch 43: train loss: 0.3574295938014984\n",
      "Epoch 43: train loss: 0.4660134017467499\n",
      "Epoch 43: train loss: 0.6714805364608765\n",
      "Epoch 43: train loss: 0.7507103681564331\n",
      "Epoch 43: train loss: 0.7992873787879944\n",
      "Epoch 43: train loss: 0.4757750332355499\n",
      "Epoch 43: train loss: 0.5033995509147644\n",
      "Epoch 43: train loss: 0.3989863693714142\n",
      "Epoch 43: train loss: 0.5271516442298889\n",
      "Epoch 43: train loss: 0.6797902584075928\n",
      "Epoch 43: train loss: 0.5829095840454102\n",
      "Epoch 43: train loss: 0.535413384437561\n",
      "Epoch 43: train loss: 0.6167834401130676\n",
      "Epoch 43: train loss: 0.6058783531188965\n",
      "Epoch 43: train loss: 0.47912007570266724\n",
      "Epoch 43: train loss: 0.6319668889045715\n",
      "Epoch 43: train loss: 0.6793656349182129\n",
      "Epoch 43: train loss: 0.4687660038471222\n",
      "Epoch 43: train loss: 0.5815293192863464\n",
      "Epoch 43: train loss: 0.5539457201957703\n",
      "Epoch 43: train loss: 0.6682108640670776\n",
      "Epoch 43: train loss: 0.48085445165634155\n",
      "Epoch 43: train loss: 0.5592820644378662\n",
      "Epoch 43: train loss: 0.4540480375289917\n",
      "Epoch 43: train loss: 0.5621901750564575\n",
      "Epoch 43: train loss: 0.5281495451927185\n",
      "Epoch 43: train loss: 0.5119647979736328\n",
      "Epoch 43: train loss: 0.5469298362731934\n",
      "Epoch 43: train loss: 0.5123543739318848\n",
      "Epoch 43: train loss: 0.5029572248458862\n",
      "Epoch 43: train loss: 0.5015382170677185\n",
      "Epoch 43: train loss: 0.709113597869873\n",
      "Epoch 43: train loss: 0.5796855092048645\n",
      "Epoch 43: train loss: 0.42544588446617126\n",
      "Epoch 43: train loss: 0.5532462000846863\n",
      "Epoch 43: train loss: 0.45737671852111816\n",
      "Epoch 43: train loss: 0.5376476049423218\n",
      "Epoch 43: train loss: 0.3967129588127136\n",
      "Epoch 44: train loss: 0.5280699133872986\n",
      "Epoch 44: train loss: 0.38037580251693726\n",
      "Epoch 44: train loss: 0.6624045372009277\n",
      "Epoch 44: train loss: 0.668991208076477\n",
      "Epoch 44: train loss: 0.7562392950057983\n",
      "Epoch 44: train loss: 0.6027117371559143\n",
      "Epoch 44: train loss: 0.7448042631149292\n",
      "Epoch 44: train loss: 0.5787894129753113\n",
      "Epoch 44: train loss: 0.40573200583457947\n",
      "Epoch 44: train loss: 0.6797949075698853\n",
      "Epoch 44: train loss: 0.4935666024684906\n",
      "Epoch 44: train loss: 0.5664399862289429\n",
      "Epoch 44: train loss: 0.4611852169036865\n",
      "Epoch 44: train loss: 0.6876537203788757\n",
      "Epoch 44: train loss: 0.38691046833992004\n",
      "Epoch 44: train loss: 0.43353521823883057\n",
      "Epoch 44: train loss: 0.4676920473575592\n",
      "Epoch 44: train loss: 0.5412746071815491\n",
      "Epoch 44: train loss: 0.558975100517273\n",
      "Epoch 44: train loss: 0.5367785096168518\n",
      "Epoch 44: train loss: 0.5377961993217468\n",
      "Epoch 44: train loss: 0.4174550771713257\n",
      "Epoch 44: train loss: 0.5053294897079468\n",
      "Epoch 44: train loss: 0.5820915102958679\n",
      "Epoch 44: train loss: 0.6966702938079834\n",
      "Epoch 44: train loss: 0.47359809279441833\n",
      "Epoch 44: train loss: 0.48743224143981934\n",
      "Epoch 44: train loss: 0.5421187877655029\n",
      "Epoch 44: train loss: 0.5729170441627502\n",
      "Epoch 44: train loss: 0.6743766069412231\n",
      "Epoch 44: train loss: 0.5803773403167725\n",
      "Epoch 44: train loss: 0.45948392152786255\n",
      "Epoch 44: train loss: 0.5773208737373352\n",
      "Epoch 44: train loss: 0.5793216824531555\n",
      "Epoch 44: train loss: 0.5664968490600586\n",
      "Epoch 44: train loss: 0.4992657005786896\n",
      "Epoch 44: train loss: 0.5809631943702698\n",
      "Epoch 44: train loss: 0.5801215767860413\n",
      "Epoch 44: train loss: 0.7105181813240051\n",
      "Epoch 44: train loss: 0.499021977186203\n",
      "Epoch 44: train loss: 0.48209524154663086\n",
      "Epoch 44: train loss: 0.5086498856544495\n",
      "Epoch 44: train loss: 0.6738531589508057\n",
      "Epoch 44: train loss: 0.35765358805656433\n",
      "Epoch 44: train loss: 0.5320786833763123\n",
      "Epoch 44: train loss: 0.6077029705047607\n",
      "Epoch 44: train loss: 0.4291628897190094\n",
      "Epoch 44: train loss: 0.5889856219291687\n",
      "Epoch 44: train loss: 0.4989326298236847\n",
      "Epoch 44: train loss: 0.42149412631988525\n",
      "Epoch 44: train loss: 0.617375910282135\n",
      "Epoch 44: train loss: 0.6384031176567078\n",
      "Epoch 44: train loss: 0.419251412153244\n",
      "Epoch 44: train loss: 0.5907083749771118\n",
      "Epoch 44: train loss: 0.5390438437461853\n",
      "Epoch 44: train loss: 0.6468587517738342\n",
      "Epoch 44: train loss: 0.6625182032585144\n",
      "Epoch 44: train loss: 0.3971063196659088\n",
      "Epoch 44: train loss: 0.40720134973526\n",
      "Epoch 44: train loss: 0.5219225883483887\n",
      "Epoch 44: train loss: 0.5846789479255676\n",
      "Epoch 44: train loss: 0.5779390335083008\n",
      "Epoch 44: train loss: 0.6163515448570251\n",
      "Epoch 44: train loss: 0.4624864161014557\n",
      "Epoch 44: train loss: 0.6306363344192505\n",
      "Epoch 44: train loss: 0.4108213186264038\n",
      "Epoch 44: train loss: 0.4317684769630432\n",
      "Epoch 44: train loss: 0.4870986342430115\n",
      "Epoch 44: train loss: 0.4996519684791565\n",
      "Epoch 44: train loss: 0.4659002423286438\n",
      "Epoch 44: train loss: 0.5110273361206055\n",
      "Epoch 44: train loss: 0.6723847389221191\n",
      "Epoch 44: train loss: 0.5708823204040527\n",
      "Epoch 44: train loss: 0.5885329842567444\n",
      "Epoch 44: train loss: 0.34654974937438965\n",
      "Epoch 44: train loss: 0.4877649247646332\n",
      "Epoch 44: train loss: 0.6482514142990112\n",
      "Epoch 44: train loss: 0.5449226498603821\n",
      "Epoch 44: train loss: 0.5058438181877136\n",
      "Epoch 44: train loss: 0.43949517607688904\n",
      "Epoch 44: train loss: 0.5601347088813782\n",
      "Epoch 44: train loss: 0.4723677635192871\n",
      "Epoch 44: train loss: 0.48958632349967957\n",
      "Epoch 44: train loss: 0.4833156168460846\n",
      "Epoch 44: train loss: 0.5392183065414429\n",
      "Epoch 44: train loss: 0.5602169632911682\n",
      "Epoch 44: train loss: 0.4794118106365204\n",
      "Epoch 44: train loss: 0.5790406465530396\n",
      "Epoch 44: train loss: 0.6759116649627686\n",
      "Epoch 44: train loss: 0.4060728847980499\n",
      "Epoch 44: train loss: 0.460904985666275\n",
      "Epoch 44: train loss: 0.5473898649215698\n",
      "Epoch 44: train loss: 0.5685023069381714\n",
      "Epoch 44: train loss: 0.8691583275794983\n",
      "Epoch 44: train loss: 0.6045874357223511\n",
      "Epoch 44: train loss: 0.3820372521877289\n",
      "Epoch 44: train loss: 0.39821305871009827\n",
      "Epoch 44: train loss: 0.5377175807952881\n",
      "Epoch 44: train loss: 0.5611521601676941\n",
      "Epoch 44: train loss: 0.4808814823627472\n",
      "Epoch 44: train loss: 0.5043535232543945\n",
      "Epoch 44: train loss: 0.6161003708839417\n",
      "Epoch 44: train loss: 0.435335248708725\n",
      "Epoch 44: train loss: 0.47318899631500244\n",
      "Epoch 44: train loss: 0.42073559761047363\n",
      "Epoch 44: train loss: 0.6101776957511902\n",
      "Epoch 44: train loss: 0.5444834232330322\n",
      "Epoch 44: train loss: 0.49189305305480957\n",
      "Epoch 44: train loss: 0.45763128995895386\n",
      "Epoch 44: train loss: 0.7748427987098694\n",
      "Epoch 44: train loss: 0.5010830163955688\n",
      "Epoch 44: train loss: 0.46758389472961426\n",
      "Epoch 44: train loss: 0.5815467238426208\n",
      "Epoch 44: train loss: 0.4330262839794159\n",
      "Epoch 44: train loss: 0.5805814862251282\n",
      "Epoch 44: train loss: 0.659081220626831\n",
      "Epoch 44: train loss: 0.47148391604423523\n",
      "Epoch 44: train loss: 0.5638136267662048\n",
      "Epoch 44: train loss: 0.34652289748191833\n",
      "Epoch 44: train loss: 0.5253646969795227\n",
      "Epoch 44: train loss: 0.4420108497142792\n",
      "Epoch 44: train loss: 0.5102131962776184\n",
      "Epoch 44: train loss: 0.5339094400405884\n",
      "Epoch 44: train loss: 0.6908372640609741\n",
      "Epoch 45: train loss: 0.49924349784851074\n",
      "Epoch 45: train loss: 0.518426239490509\n",
      "Epoch 45: train loss: 0.472786545753479\n",
      "Epoch 45: train loss: 0.5322197675704956\n",
      "Epoch 45: train loss: 0.43065646290779114\n",
      "Epoch 45: train loss: 0.6629409790039062\n",
      "Epoch 45: train loss: 0.4658108055591583\n",
      "Epoch 45: train loss: 0.4876793324947357\n",
      "Epoch 45: train loss: 0.4771910607814789\n",
      "Epoch 45: train loss: 0.5644371509552002\n",
      "Epoch 45: train loss: 0.5227310061454773\n",
      "Epoch 45: train loss: 0.45775938034057617\n",
      "Epoch 45: train loss: 0.5714922547340393\n",
      "Epoch 45: train loss: 0.3943852484226227\n",
      "Epoch 45: train loss: 0.6450262665748596\n",
      "Epoch 45: train loss: 0.5648771524429321\n",
      "Epoch 45: train loss: 0.5142462253570557\n",
      "Epoch 45: train loss: 0.7526374459266663\n",
      "Epoch 45: train loss: 0.5309410691261292\n",
      "Epoch 45: train loss: 0.6037726402282715\n",
      "Epoch 45: train loss: 0.42333295941352844\n",
      "Epoch 45: train loss: 0.5345107913017273\n",
      "Epoch 45: train loss: 0.5382784605026245\n",
      "Epoch 45: train loss: 0.5580685138702393\n",
      "Epoch 45: train loss: 0.5903463363647461\n",
      "Epoch 45: train loss: 0.4076082110404968\n",
      "Epoch 45: train loss: 0.5860981345176697\n",
      "Epoch 45: train loss: 0.4979408085346222\n",
      "Epoch 45: train loss: 0.642084002494812\n",
      "Epoch 45: train loss: 0.47930046916007996\n",
      "Epoch 45: train loss: 0.4593140482902527\n",
      "Epoch 45: train loss: 0.5158436894416809\n",
      "Epoch 45: train loss: 0.5422477126121521\n",
      "Epoch 45: train loss: 0.4478001892566681\n",
      "Epoch 45: train loss: 0.525749921798706\n",
      "Epoch 45: train loss: 0.5309320688247681\n",
      "Epoch 45: train loss: 0.5055851340293884\n",
      "Epoch 45: train loss: 0.47380003333091736\n",
      "Epoch 45: train loss: 0.5597672462463379\n",
      "Epoch 45: train loss: 0.6843165755271912\n",
      "Epoch 45: train loss: 0.5484992861747742\n",
      "Epoch 45: train loss: 0.6179645657539368\n",
      "Epoch 45: train loss: 0.383667528629303\n",
      "Epoch 45: train loss: 0.6593501567840576\n",
      "Epoch 45: train loss: 0.43878424167633057\n",
      "Epoch 45: train loss: 0.4612245559692383\n",
      "Epoch 45: train loss: 0.5092948079109192\n",
      "Epoch 45: train loss: 0.6988512277603149\n",
      "Epoch 45: train loss: 0.56104975938797\n",
      "Epoch 45: train loss: 0.4663223922252655\n",
      "Epoch 45: train loss: 0.6844934225082397\n",
      "Epoch 45: train loss: 0.5328992009162903\n",
      "Epoch 45: train loss: 0.5134576559066772\n",
      "Epoch 45: train loss: 0.6304108500480652\n",
      "Epoch 45: train loss: 0.5924243330955505\n",
      "Epoch 45: train loss: 0.3386915922164917\n",
      "Epoch 45: train loss: 0.621525228023529\n",
      "Epoch 45: train loss: 0.5126895904541016\n",
      "Epoch 45: train loss: 0.5135917663574219\n",
      "Epoch 45: train loss: 0.6541382074356079\n",
      "Epoch 45: train loss: 0.5586636066436768\n",
      "Epoch 45: train loss: 0.5166926980018616\n",
      "Epoch 45: train loss: 0.4332377016544342\n",
      "Epoch 45: train loss: 0.4493236541748047\n",
      "Epoch 45: train loss: 0.5389684438705444\n",
      "Epoch 45: train loss: 0.4463210999965668\n",
      "Epoch 45: train loss: 0.47352397441864014\n",
      "Epoch 45: train loss: 0.5660696625709534\n",
      "Epoch 45: train loss: 0.6143056750297546\n",
      "Epoch 45: train loss: 0.43342772126197815\n",
      "Epoch 45: train loss: 0.6209991574287415\n",
      "Epoch 45: train loss: 0.4709194600582123\n",
      "Epoch 45: train loss: 0.4498099386692047\n",
      "Epoch 45: train loss: 0.6758298277854919\n",
      "Epoch 45: train loss: 0.5877862572669983\n",
      "Epoch 45: train loss: 0.46412932872772217\n",
      "Epoch 45: train loss: 0.49254417419433594\n",
      "Epoch 45: train loss: 0.6159806847572327\n",
      "Epoch 45: train loss: 0.4651030898094177\n",
      "Epoch 45: train loss: 0.5189402103424072\n",
      "Epoch 45: train loss: 0.722370982170105\n",
      "Epoch 45: train loss: 0.35728874802589417\n",
      "Epoch 45: train loss: 0.6103286743164062\n",
      "Epoch 45: train loss: 0.6633772850036621\n",
      "Epoch 45: train loss: 0.5619171857833862\n",
      "Epoch 45: train loss: 0.46283072233200073\n",
      "Epoch 45: train loss: 0.5594795346260071\n",
      "Epoch 45: train loss: 0.43653979897499084\n",
      "Epoch 45: train loss: 0.5268204808235168\n",
      "Epoch 45: train loss: 0.6333739161491394\n",
      "Epoch 45: train loss: 0.5734284520149231\n",
      "Epoch 45: train loss: 0.5240787863731384\n",
      "Epoch 45: train loss: 0.5649092793464661\n",
      "Epoch 45: train loss: 0.6204614043235779\n",
      "Epoch 45: train loss: 0.48900651931762695\n",
      "Epoch 45: train loss: 0.6056955456733704\n",
      "Epoch 45: train loss: 0.43950116634368896\n",
      "Epoch 45: train loss: 0.5627144575119019\n",
      "Epoch 45: train loss: 0.4834917187690735\n",
      "Epoch 45: train loss: 0.43087199330329895\n",
      "Epoch 45: train loss: 0.47216397523880005\n",
      "Epoch 45: train loss: 0.5075591802597046\n",
      "Epoch 45: train loss: 0.4926512837409973\n",
      "Epoch 45: train loss: 0.7101644277572632\n",
      "Epoch 45: train loss: 0.3480055034160614\n",
      "Epoch 45: train loss: 0.4349347949028015\n",
      "Epoch 45: train loss: 0.5512547492980957\n",
      "Epoch 45: train loss: 0.5955577492713928\n",
      "Epoch 45: train loss: 0.5628277063369751\n",
      "Epoch 45: train loss: 0.48444995284080505\n",
      "Epoch 45: train loss: 0.4717375338077545\n",
      "Epoch 45: train loss: 0.41983261704444885\n",
      "Epoch 45: train loss: 0.43789705634117126\n",
      "Epoch 45: train loss: 0.638875424861908\n",
      "Epoch 45: train loss: 0.5947723388671875\n",
      "Epoch 45: train loss: 0.5993538498878479\n",
      "Epoch 45: train loss: 0.5571300983428955\n",
      "Epoch 45: train loss: 0.5085647702217102\n",
      "Epoch 45: train loss: 0.6307793855667114\n",
      "Epoch 45: train loss: 0.5856778621673584\n",
      "Epoch 45: train loss: 0.5148242115974426\n",
      "Epoch 45: train loss: 0.6515613198280334\n",
      "Epoch 45: train loss: 0.5993870496749878\n",
      "Epoch 45: train loss: 0.5914769172668457\n",
      "Epoch 46: train loss: 0.5737472772598267\n",
      "Epoch 46: train loss: 0.565930187702179\n",
      "Epoch 46: train loss: 0.5514763593673706\n",
      "Epoch 46: train loss: 0.43518856167793274\n",
      "Epoch 46: train loss: 0.540000319480896\n",
      "Epoch 46: train loss: 0.5170936584472656\n",
      "Epoch 46: train loss: 0.5993031859397888\n",
      "Epoch 46: train loss: 0.44617974758148193\n",
      "Epoch 46: train loss: 0.5149297118186951\n",
      "Epoch 46: train loss: 0.2713489234447479\n",
      "Epoch 46: train loss: 0.5446140170097351\n",
      "Epoch 46: train loss: 0.5368598699569702\n",
      "Epoch 46: train loss: 0.480061411857605\n",
      "Epoch 46: train loss: 0.6047794222831726\n",
      "Epoch 46: train loss: 0.6725980043411255\n",
      "Epoch 46: train loss: 0.4858971834182739\n",
      "Epoch 46: train loss: 0.6115877628326416\n",
      "Epoch 46: train loss: 0.315951406955719\n",
      "Epoch 46: train loss: 0.5277007222175598\n",
      "Epoch 46: train loss: 0.4574122130870819\n",
      "Epoch 46: train loss: 0.5137428045272827\n",
      "Epoch 46: train loss: 0.6244999766349792\n",
      "Epoch 46: train loss: 0.4185898005962372\n",
      "Epoch 46: train loss: 0.6416881680488586\n",
      "Epoch 46: train loss: 0.33351635932922363\n",
      "Epoch 46: train loss: 0.5981425046920776\n",
      "Epoch 46: train loss: 0.6886631846427917\n",
      "Epoch 46: train loss: 0.4245873987674713\n",
      "Epoch 46: train loss: 0.6609218716621399\n",
      "Epoch 46: train loss: 0.5702313780784607\n",
      "Epoch 46: train loss: 0.5134042501449585\n",
      "Epoch 46: train loss: 0.7243382930755615\n",
      "Epoch 46: train loss: 0.5414572954177856\n",
      "Epoch 46: train loss: 0.5527893900871277\n",
      "Epoch 46: train loss: 0.45305970311164856\n",
      "Epoch 46: train loss: 0.5297176837921143\n",
      "Epoch 46: train loss: 0.5020294189453125\n",
      "Epoch 46: train loss: 0.5964776873588562\n",
      "Epoch 46: train loss: 0.5177450180053711\n",
      "Epoch 46: train loss: 0.733824610710144\n",
      "Epoch 46: train loss: 0.5410647392272949\n",
      "Epoch 46: train loss: 0.5074674487113953\n",
      "Epoch 46: train loss: 0.47113466262817383\n",
      "Epoch 46: train loss: 0.5295882225036621\n",
      "Epoch 46: train loss: 0.5009866952896118\n",
      "Epoch 46: train loss: 0.5306960940361023\n",
      "Epoch 46: train loss: 0.6850935220718384\n",
      "Epoch 46: train loss: 0.5922337770462036\n",
      "Epoch 46: train loss: 0.5225877165794373\n",
      "Epoch 46: train loss: 0.659993588924408\n",
      "Epoch 46: train loss: 0.47387582063674927\n",
      "Epoch 46: train loss: 0.4499695897102356\n",
      "Epoch 46: train loss: 0.6010812520980835\n",
      "Epoch 46: train loss: 0.5131832957267761\n",
      "Epoch 46: train loss: 0.4076544940471649\n",
      "Epoch 46: train loss: 0.5660542845726013\n",
      "Epoch 46: train loss: 0.5176770091056824\n",
      "Epoch 46: train loss: 0.5137067437171936\n",
      "Epoch 46: train loss: 0.6904417276382446\n",
      "Epoch 46: train loss: 0.3672090470790863\n",
      "Epoch 46: train loss: 0.6913289427757263\n",
      "Epoch 46: train loss: 0.45451173186302185\n",
      "Epoch 46: train loss: 0.5602424740791321\n",
      "Epoch 46: train loss: 0.5585753321647644\n",
      "Epoch 46: train loss: 0.5003480911254883\n",
      "Epoch 46: train loss: 0.7811935544013977\n",
      "Epoch 46: train loss: 0.5646562576293945\n",
      "Epoch 46: train loss: 0.5068361759185791\n",
      "Epoch 46: train loss: 0.6026825904846191\n",
      "Epoch 46: train loss: 0.5118968486785889\n",
      "Epoch 46: train loss: 0.6366908550262451\n",
      "Epoch 46: train loss: 0.6224874258041382\n",
      "Epoch 46: train loss: 0.5276525020599365\n",
      "Epoch 46: train loss: 0.5878697037696838\n",
      "Epoch 46: train loss: 0.5622060894966125\n",
      "Epoch 46: train loss: 0.5463691353797913\n",
      "Epoch 46: train loss: 0.5841466784477234\n",
      "Epoch 46: train loss: 0.5818180441856384\n",
      "Epoch 46: train loss: 0.5231579542160034\n",
      "Epoch 46: train loss: 0.4275943338871002\n",
      "Epoch 46: train loss: 0.6451911926269531\n",
      "Epoch 46: train loss: 0.5682649612426758\n",
      "Epoch 46: train loss: 0.49877434968948364\n",
      "Epoch 46: train loss: 0.4929344952106476\n",
      "Epoch 46: train loss: 0.4437636137008667\n",
      "Epoch 46: train loss: 0.6566353440284729\n",
      "Epoch 46: train loss: 0.4807923436164856\n",
      "Epoch 46: train loss: 0.5111849904060364\n",
      "Epoch 46: train loss: 0.5138959288597107\n",
      "Epoch 46: train loss: 0.6427214741706848\n",
      "Epoch 46: train loss: 0.539919912815094\n",
      "Epoch 46: train loss: 0.5248671174049377\n",
      "Epoch 46: train loss: 0.5472268462181091\n",
      "Epoch 46: train loss: 0.506833016872406\n",
      "Epoch 46: train loss: 0.6265711188316345\n",
      "Epoch 46: train loss: 0.48545384407043457\n",
      "Epoch 46: train loss: 0.835332989692688\n",
      "Epoch 46: train loss: 0.4935648739337921\n",
      "Epoch 46: train loss: 0.536663293838501\n",
      "Epoch 46: train loss: 0.4859924018383026\n",
      "Epoch 46: train loss: 0.4969481825828552\n",
      "Epoch 46: train loss: 0.4831733703613281\n",
      "Epoch 46: train loss: 0.620638370513916\n",
      "Epoch 46: train loss: 0.38658368587493896\n",
      "Epoch 46: train loss: 0.6093272566795349\n",
      "Epoch 46: train loss: 0.5093786716461182\n",
      "Epoch 46: train loss: 0.3388809561729431\n",
      "Epoch 46: train loss: 0.5338887572288513\n",
      "Epoch 46: train loss: 0.48039767146110535\n",
      "Epoch 46: train loss: 0.6110031008720398\n",
      "Epoch 46: train loss: 0.4958379566669464\n",
      "Epoch 46: train loss: 0.4443228840827942\n",
      "Epoch 46: train loss: 0.6437259912490845\n",
      "Epoch 46: train loss: 0.5283040404319763\n",
      "Epoch 46: train loss: 0.3432079553604126\n",
      "Epoch 46: train loss: 0.38358572125434875\n",
      "Epoch 46: train loss: 0.504637598991394\n",
      "Epoch 46: train loss: 0.4734465479850769\n",
      "Epoch 46: train loss: 0.448772668838501\n",
      "Epoch 46: train loss: 0.5948072075843811\n",
      "Epoch 46: train loss: 0.4891165792942047\n",
      "Epoch 46: train loss: 0.544289231300354\n",
      "Epoch 46: train loss: 0.5257259607315063\n",
      "Epoch 46: train loss: 0.47879400849342346\n",
      "Epoch 47: train loss: 0.7470234632492065\n",
      "Epoch 47: train loss: 0.5415694713592529\n",
      "Epoch 47: train loss: 0.3421129286289215\n",
      "Epoch 47: train loss: 0.5670416355133057\n",
      "Epoch 47: train loss: 0.40995413064956665\n",
      "Epoch 47: train loss: 0.4512709975242615\n",
      "Epoch 47: train loss: 0.536986231803894\n",
      "Epoch 47: train loss: 0.6149762868881226\n",
      "Epoch 47: train loss: 0.5877808332443237\n",
      "Epoch 47: train loss: 0.6308408379554749\n",
      "Epoch 47: train loss: 0.39919912815093994\n",
      "Epoch 47: train loss: 0.5630325675010681\n",
      "Epoch 47: train loss: 0.5568284392356873\n",
      "Epoch 47: train loss: 0.6163057088851929\n",
      "Epoch 47: train loss: 0.5890918374061584\n",
      "Epoch 47: train loss: 0.5189074873924255\n",
      "Epoch 47: train loss: 0.5871410965919495\n",
      "Epoch 47: train loss: 0.6319661736488342\n",
      "Epoch 47: train loss: 0.4757433831691742\n",
      "Epoch 47: train loss: 0.6233067512512207\n",
      "Epoch 47: train loss: 0.4585708677768707\n",
      "Epoch 47: train loss: 0.4288271367549896\n",
      "Epoch 47: train loss: 0.5801560282707214\n",
      "Epoch 47: train loss: 0.5897716283798218\n",
      "Epoch 47: train loss: 0.6079760193824768\n",
      "Epoch 47: train loss: 0.6629447937011719\n",
      "Epoch 47: train loss: 0.6305796504020691\n",
      "Epoch 47: train loss: 0.5484452843666077\n",
      "Epoch 47: train loss: 0.4494023025035858\n",
      "Epoch 47: train loss: 0.5687554478645325\n",
      "Epoch 47: train loss: 0.4674360156059265\n",
      "Epoch 47: train loss: 0.5458138585090637\n",
      "Epoch 47: train loss: 0.6817326545715332\n",
      "Epoch 47: train loss: 0.5006588101387024\n",
      "Epoch 47: train loss: 0.5252436399459839\n",
      "Epoch 47: train loss: 0.4810892641544342\n",
      "Epoch 47: train loss: 0.41244077682495117\n",
      "Epoch 47: train loss: 0.3990524709224701\n",
      "Epoch 47: train loss: 0.5185139179229736\n",
      "Epoch 47: train loss: 0.5771487355232239\n",
      "Epoch 47: train loss: 0.5156139135360718\n",
      "Epoch 47: train loss: 0.5853064060211182\n",
      "Epoch 47: train loss: 0.45540350675582886\n",
      "Epoch 47: train loss: 0.46255481243133545\n",
      "Epoch 47: train loss: 0.5568475127220154\n",
      "Epoch 47: train loss: 0.4779333770275116\n",
      "Epoch 47: train loss: 0.47631600499153137\n",
      "Epoch 47: train loss: 0.6661530137062073\n",
      "Epoch 47: train loss: 0.6793999671936035\n",
      "Epoch 47: train loss: 0.5275887250900269\n",
      "Epoch 47: train loss: 0.42811551690101624\n",
      "Epoch 47: train loss: 0.5349684953689575\n",
      "Epoch 47: train loss: 0.7301918864250183\n",
      "Epoch 47: train loss: 0.5952031016349792\n",
      "Epoch 47: train loss: 0.7418539524078369\n",
      "Epoch 47: train loss: 0.4862808585166931\n",
      "Epoch 47: train loss: 0.40220895409584045\n",
      "Epoch 47: train loss: 0.7281138896942139\n",
      "Epoch 47: train loss: 0.48269766569137573\n",
      "Epoch 47: train loss: 0.6773108243942261\n",
      "Epoch 47: train loss: 0.43359681963920593\n",
      "Epoch 47: train loss: 0.5261170864105225\n",
      "Epoch 47: train loss: 0.6037262678146362\n",
      "Epoch 47: train loss: 0.43564119935035706\n",
      "Epoch 47: train loss: 0.5505123138427734\n",
      "Epoch 47: train loss: 0.4586096405982971\n",
      "Epoch 47: train loss: 0.42517852783203125\n",
      "Epoch 47: train loss: 0.5557176470756531\n",
      "Epoch 47: train loss: 0.5228046178817749\n",
      "Epoch 47: train loss: 0.5491316318511963\n",
      "Epoch 47: train loss: 0.5682356953620911\n",
      "Epoch 47: train loss: 0.47707632184028625\n",
      "Epoch 47: train loss: 0.4665732979774475\n",
      "Epoch 47: train loss: 0.44344738125801086\n",
      "Epoch 47: train loss: 0.41446951031684875\n",
      "Epoch 47: train loss: 0.591136634349823\n",
      "Epoch 47: train loss: 0.5226771831512451\n",
      "Epoch 47: train loss: 0.6049206852912903\n",
      "Epoch 47: train loss: 0.5990084409713745\n",
      "Epoch 47: train loss: 0.5563514232635498\n",
      "Epoch 47: train loss: 0.6836013197898865\n",
      "Epoch 47: train loss: 0.596526563167572\n",
      "Epoch 47: train loss: 0.5910163521766663\n",
      "Epoch 47: train loss: 0.6222865581512451\n",
      "Epoch 47: train loss: 0.6104012727737427\n",
      "Epoch 47: train loss: 0.4478680491447449\n",
      "Epoch 47: train loss: 0.5233270525932312\n",
      "Epoch 47: train loss: 0.5820416808128357\n",
      "Epoch 47: train loss: 0.6023491024971008\n",
      "Epoch 47: train loss: 0.5999718904495239\n",
      "Epoch 47: train loss: 0.46168237924575806\n",
      "Epoch 47: train loss: 0.4531720280647278\n",
      "Epoch 47: train loss: 0.4902524948120117\n",
      "Epoch 47: train loss: 0.6106740236282349\n",
      "Epoch 47: train loss: 0.6050095558166504\n",
      "Epoch 47: train loss: 0.710997998714447\n",
      "Epoch 47: train loss: 0.5706707835197449\n",
      "Epoch 47: train loss: 0.6153473854064941\n",
      "Epoch 47: train loss: 0.8150464296340942\n",
      "Epoch 47: train loss: 0.6261724233627319\n",
      "Epoch 47: train loss: 0.4732782542705536\n",
      "Epoch 47: train loss: 0.659910261631012\n",
      "Epoch 47: train loss: 0.40135297179222107\n",
      "Epoch 47: train loss: 0.5134706497192383\n",
      "Epoch 47: train loss: 0.5026363730430603\n",
      "Epoch 47: train loss: 0.5481601357460022\n",
      "Epoch 47: train loss: 0.4671170711517334\n",
      "Epoch 47: train loss: 0.4211071729660034\n",
      "Epoch 47: train loss: 0.47632184624671936\n",
      "Epoch 47: train loss: 0.407810777425766\n",
      "Epoch 47: train loss: 0.46307215094566345\n",
      "Epoch 47: train loss: 0.6657849550247192\n",
      "Epoch 47: train loss: 0.4733494818210602\n",
      "Epoch 47: train loss: 0.5113930106163025\n",
      "Epoch 47: train loss: 0.4191367030143738\n",
      "Epoch 47: train loss: 0.6098900437355042\n",
      "Epoch 47: train loss: 0.4256513714790344\n",
      "Epoch 47: train loss: 0.48602551221847534\n",
      "Epoch 47: train loss: 0.40884941816329956\n",
      "Epoch 47: train loss: 0.5560397505760193\n",
      "Epoch 47: train loss: 0.43419918417930603\n",
      "Epoch 47: train loss: 0.41719284653663635\n",
      "Epoch 47: train loss: 0.4523445963859558\n",
      "Epoch 47: train loss: 0.28452742099761963\n",
      "Epoch 48: train loss: 0.5926889777183533\n",
      "Epoch 48: train loss: 0.4955110549926758\n",
      "Epoch 48: train loss: 0.49490949511528015\n",
      "Epoch 48: train loss: 0.5768052339553833\n",
      "Epoch 48: train loss: 0.5676550269126892\n",
      "Epoch 48: train loss: 0.7584455013275146\n",
      "Epoch 48: train loss: 0.4917185306549072\n",
      "Epoch 48: train loss: 0.4523754417896271\n",
      "Epoch 48: train loss: 0.5391737818717957\n",
      "Epoch 48: train loss: 0.3263437747955322\n",
      "Epoch 48: train loss: 0.7147940993309021\n",
      "Epoch 48: train loss: 0.4277827739715576\n",
      "Epoch 48: train loss: 0.5444180965423584\n",
      "Epoch 48: train loss: 0.5192087888717651\n",
      "Epoch 48: train loss: 0.5999679565429688\n",
      "Epoch 48: train loss: 0.4274943768978119\n",
      "Epoch 48: train loss: 0.5907535552978516\n",
      "Epoch 48: train loss: 0.8013871312141418\n",
      "Epoch 48: train loss: 0.5889619588851929\n",
      "Epoch 48: train loss: 0.3856416344642639\n",
      "Epoch 48: train loss: 0.4588969647884369\n",
      "Epoch 48: train loss: 0.5628150105476379\n",
      "Epoch 48: train loss: 0.44174301624298096\n",
      "Epoch 48: train loss: 0.3225051164627075\n",
      "Epoch 48: train loss: 0.5668792724609375\n",
      "Epoch 48: train loss: 0.5585482716560364\n",
      "Epoch 48: train loss: 0.6242846846580505\n",
      "Epoch 48: train loss: 0.472125768661499\n",
      "Epoch 48: train loss: 0.45267459750175476\n",
      "Epoch 48: train loss: 0.6117311120033264\n",
      "Epoch 48: train loss: 0.6777450442314148\n",
      "Epoch 48: train loss: 0.40371572971343994\n",
      "Epoch 48: train loss: 0.43894416093826294\n",
      "Epoch 48: train loss: 0.5210292339324951\n",
      "Epoch 48: train loss: 0.5803083777427673\n",
      "Epoch 48: train loss: 0.6857991814613342\n",
      "Epoch 48: train loss: 0.5292934775352478\n",
      "Epoch 48: train loss: 0.44345149397850037\n",
      "Epoch 48: train loss: 0.6009165048599243\n",
      "Epoch 48: train loss: 0.45074787735939026\n",
      "Epoch 48: train loss: 0.5531269907951355\n",
      "Epoch 48: train loss: 0.4824916422367096\n",
      "Epoch 48: train loss: 0.5571824312210083\n",
      "Epoch 48: train loss: 0.562920331954956\n",
      "Epoch 48: train loss: 0.5628592371940613\n",
      "Epoch 48: train loss: 0.5927149653434753\n",
      "Epoch 48: train loss: 0.610819399356842\n",
      "Epoch 48: train loss: 0.6867855191230774\n",
      "Epoch 48: train loss: 0.4857847988605499\n",
      "Epoch 48: train loss: 0.4341091811656952\n",
      "Epoch 48: train loss: 0.4493946433067322\n",
      "Epoch 48: train loss: 0.5236942768096924\n",
      "Epoch 48: train loss: 0.618985652923584\n",
      "Epoch 48: train loss: 0.434998482465744\n",
      "Epoch 48: train loss: 0.62770676612854\n",
      "Epoch 48: train loss: 0.5680449604988098\n",
      "Epoch 48: train loss: 0.6359661221504211\n",
      "Epoch 48: train loss: 0.4907171428203583\n",
      "Epoch 48: train loss: 0.465524286031723\n",
      "Epoch 48: train loss: 0.42999032139778137\n",
      "Epoch 48: train loss: 0.5096718072891235\n",
      "Epoch 48: train loss: 0.4642907679080963\n",
      "Epoch 48: train loss: 0.46409669518470764\n",
      "Epoch 48: train loss: 0.5299285054206848\n",
      "Epoch 48: train loss: 0.4414447247982025\n",
      "Epoch 48: train loss: 0.6194927096366882\n",
      "Epoch 48: train loss: 0.46786776185035706\n",
      "Epoch 48: train loss: 0.4111834764480591\n",
      "Epoch 48: train loss: 0.5175097584724426\n",
      "Epoch 48: train loss: 0.7764610648155212\n",
      "Epoch 48: train loss: 0.6713076829910278\n",
      "Epoch 48: train loss: 0.49670302867889404\n",
      "Epoch 48: train loss: 0.6016210317611694\n",
      "Epoch 48: train loss: 0.35703152418136597\n",
      "Epoch 48: train loss: 0.5092715620994568\n",
      "Epoch 48: train loss: 0.5282004475593567\n",
      "Epoch 48: train loss: 0.5498160123825073\n",
      "Epoch 48: train loss: 0.37207597494125366\n",
      "Epoch 48: train loss: 0.4499002993106842\n",
      "Epoch 48: train loss: 0.6947801113128662\n",
      "Epoch 48: train loss: 0.5728415846824646\n",
      "Epoch 48: train loss: 0.48590999841690063\n",
      "Epoch 48: train loss: 0.5552498698234558\n",
      "Epoch 48: train loss: 0.5746906995773315\n",
      "Epoch 48: train loss: 0.5655449628829956\n",
      "Epoch 48: train loss: 0.5081376433372498\n",
      "Epoch 48: train loss: 0.43232932686805725\n",
      "Epoch 48: train loss: 0.5795570611953735\n",
      "Epoch 48: train loss: 0.645632266998291\n",
      "Epoch 48: train loss: 0.5461449027061462\n",
      "Epoch 48: train loss: 0.6454851031303406\n",
      "Epoch 48: train loss: 0.6084237098693848\n",
      "Epoch 48: train loss: 0.6400765180587769\n",
      "Epoch 48: train loss: 0.5741799473762512\n",
      "Epoch 48: train loss: 0.5628066062927246\n",
      "Epoch 48: train loss: 0.49956774711608887\n",
      "Epoch 48: train loss: 0.4992004632949829\n",
      "Epoch 48: train loss: 0.39103788137435913\n",
      "Epoch 48: train loss: 0.5437702536582947\n",
      "Epoch 48: train loss: 0.3742055296897888\n",
      "Epoch 48: train loss: 0.6001948118209839\n",
      "Epoch 48: train loss: 0.5427746772766113\n",
      "Epoch 48: train loss: 0.503980278968811\n",
      "Epoch 48: train loss: 0.6104133725166321\n",
      "Epoch 48: train loss: 0.5136981010437012\n",
      "Epoch 48: train loss: 0.6048809885978699\n",
      "Epoch 48: train loss: 0.5758127570152283\n",
      "Epoch 48: train loss: 0.38435396552085876\n",
      "Epoch 48: train loss: 0.4966447353363037\n",
      "Epoch 48: train loss: 0.48640093207359314\n",
      "Epoch 48: train loss: 0.3683844208717346\n",
      "Epoch 48: train loss: 0.4366300404071808\n",
      "Epoch 48: train loss: 0.4809083044528961\n",
      "Epoch 48: train loss: 0.4026510715484619\n",
      "Epoch 48: train loss: 0.4452483057975769\n",
      "Epoch 48: train loss: 0.5696813464164734\n",
      "Epoch 48: train loss: 0.6794686317443848\n",
      "Epoch 48: train loss: 0.8289515376091003\n",
      "Epoch 48: train loss: 0.8095215559005737\n",
      "Epoch 48: train loss: 0.4346767067909241\n",
      "Epoch 48: train loss: 0.48516762256622314\n",
      "Epoch 48: train loss: 0.6380341053009033\n",
      "Epoch 48: train loss: 0.5001765489578247\n",
      "Epoch 48: train loss: 0.6223430633544922\n",
      "Epoch 49: train loss: 0.5302668213844299\n",
      "Epoch 49: train loss: 0.5161316990852356\n",
      "Epoch 49: train loss: 0.502793550491333\n",
      "Epoch 49: train loss: 0.6256464719772339\n",
      "Epoch 49: train loss: 0.5699336528778076\n",
      "Epoch 49: train loss: 0.5456578731536865\n",
      "Epoch 49: train loss: 0.4508680999279022\n",
      "Epoch 49: train loss: 0.5027743577957153\n",
      "Epoch 49: train loss: 0.4225754737854004\n",
      "Epoch 49: train loss: 0.44023606181144714\n",
      "Epoch 49: train loss: 0.5307400226593018\n",
      "Epoch 49: train loss: 0.42929551005363464\n",
      "Epoch 49: train loss: 0.47382766008377075\n",
      "Epoch 49: train loss: 0.46244320273399353\n",
      "Epoch 49: train loss: 0.5260332822799683\n",
      "Epoch 49: train loss: 0.4354044198989868\n",
      "Epoch 49: train loss: 0.5714482665061951\n",
      "Epoch 49: train loss: 0.5932557582855225\n",
      "Epoch 49: train loss: 0.6468497514724731\n",
      "Epoch 49: train loss: 0.5466925501823425\n",
      "Epoch 49: train loss: 0.47093141078948975\n",
      "Epoch 49: train loss: 0.49686992168426514\n",
      "Epoch 49: train loss: 0.7142108678817749\n",
      "Epoch 49: train loss: 0.48507770895957947\n",
      "Epoch 49: train loss: 0.4725415110588074\n",
      "Epoch 49: train loss: 0.5167604088783264\n",
      "Epoch 49: train loss: 0.41443055868148804\n",
      "Epoch 49: train loss: 0.6738570928573608\n",
      "Epoch 49: train loss: 0.46780630946159363\n",
      "Epoch 49: train loss: 0.5422499775886536\n",
      "Epoch 49: train loss: 0.6359269618988037\n",
      "Epoch 49: train loss: 0.4761899411678314\n",
      "Epoch 49: train loss: 0.4250735640525818\n",
      "Epoch 49: train loss: 0.6122499108314514\n",
      "Epoch 49: train loss: 0.7331789135932922\n",
      "Epoch 49: train loss: 0.477598637342453\n",
      "Epoch 49: train loss: 0.7373050451278687\n",
      "Epoch 49: train loss: 0.6117756962776184\n",
      "Epoch 49: train loss: 0.5664670467376709\n",
      "Epoch 49: train loss: 0.48359763622283936\n",
      "Epoch 49: train loss: 0.6676735877990723\n",
      "Epoch 49: train loss: 0.7040172815322876\n",
      "Epoch 49: train loss: 0.576298713684082\n",
      "Epoch 49: train loss: 0.7031233310699463\n",
      "Epoch 49: train loss: 0.5534800887107849\n",
      "Epoch 49: train loss: 0.45413753390312195\n",
      "Epoch 49: train loss: 0.4496648609638214\n",
      "Epoch 49: train loss: 0.46742698550224304\n",
      "Epoch 49: train loss: 0.5506778955459595\n",
      "Epoch 49: train loss: 0.6186516880989075\n",
      "Epoch 49: train loss: 0.5380955338478088\n",
      "Epoch 49: train loss: 0.4924945533275604\n",
      "Epoch 49: train loss: 0.6672089099884033\n",
      "Epoch 49: train loss: 0.4953272044658661\n",
      "Epoch 49: train loss: 0.4972144365310669\n",
      "Epoch 49: train loss: 0.6000078320503235\n",
      "Epoch 49: train loss: 0.516142725944519\n",
      "Epoch 49: train loss: 0.6131675839424133\n",
      "Epoch 49: train loss: 0.666290283203125\n",
      "Epoch 49: train loss: 0.6933215856552124\n",
      "Epoch 49: train loss: 0.5468481183052063\n",
      "Epoch 49: train loss: 0.5933759808540344\n",
      "Epoch 49: train loss: 0.49044400453567505\n",
      "Epoch 49: train loss: 0.6198878884315491\n",
      "Epoch 49: train loss: 0.4875944256782532\n",
      "Epoch 49: train loss: 0.5493451356887817\n",
      "Epoch 49: train loss: 0.47687020897865295\n",
      "Epoch 49: train loss: 0.5848772525787354\n",
      "Epoch 49: train loss: 0.5418673753738403\n",
      "Epoch 49: train loss: 0.6483165621757507\n",
      "Epoch 49: train loss: 0.5341753363609314\n",
      "Epoch 49: train loss: 0.5109636187553406\n",
      "Epoch 49: train loss: 0.5975558757781982\n",
      "Epoch 49: train loss: 0.5589035153388977\n",
      "Epoch 49: train loss: 0.5180217027664185\n",
      "Epoch 49: train loss: 0.5702131986618042\n",
      "Epoch 49: train loss: 0.6847115159034729\n",
      "Epoch 49: train loss: 0.5815593600273132\n",
      "Epoch 49: train loss: 0.6343368291854858\n",
      "Epoch 49: train loss: 0.5811660885810852\n",
      "Epoch 49: train loss: 0.5854822993278503\n",
      "Epoch 49: train loss: 0.5379078388214111\n",
      "Epoch 49: train loss: 0.7416375279426575\n",
      "Epoch 49: train loss: 0.4161975085735321\n",
      "Epoch 49: train loss: 0.5858594179153442\n",
      "Epoch 49: train loss: 0.5256228446960449\n",
      "Epoch 49: train loss: 0.5381554365158081\n",
      "Epoch 49: train loss: 0.6363649368286133\n",
      "Epoch 49: train loss: 0.42425867915153503\n",
      "Epoch 49: train loss: 0.4553665518760681\n",
      "Epoch 49: train loss: 0.5649914741516113\n",
      "Epoch 49: train loss: 0.637400209903717\n",
      "Epoch 49: train loss: 0.5107080936431885\n",
      "Epoch 49: train loss: 0.5282273292541504\n",
      "Epoch 49: train loss: 0.5003453493118286\n",
      "Epoch 49: train loss: 0.5671368837356567\n",
      "Epoch 49: train loss: 0.46401146054267883\n",
      "Epoch 49: train loss: 0.5849032998085022\n",
      "Epoch 49: train loss: 0.5207446217536926\n",
      "Epoch 49: train loss: 0.573273777961731\n",
      "Epoch 49: train loss: 0.4794515371322632\n",
      "Epoch 49: train loss: 0.5730078816413879\n",
      "Epoch 49: train loss: 0.36226359009742737\n",
      "Epoch 49: train loss: 0.5305816531181335\n",
      "Epoch 49: train loss: 0.6088412404060364\n",
      "Epoch 49: train loss: 0.6203547716140747\n",
      "Epoch 49: train loss: 0.34622153639793396\n",
      "Epoch 49: train loss: 0.390460342168808\n",
      "Epoch 49: train loss: 0.48652884364128113\n",
      "Epoch 49: train loss: 0.4450896084308624\n",
      "Epoch 49: train loss: 0.3632185161113739\n",
      "Epoch 49: train loss: 0.5597153306007385\n",
      "Epoch 49: train loss: 0.5210039019584656\n",
      "Epoch 49: train loss: 0.5597797632217407\n",
      "Epoch 49: train loss: 0.5946875810623169\n",
      "Epoch 49: train loss: 0.4610167443752289\n",
      "Epoch 49: train loss: 0.5851654410362244\n",
      "Epoch 49: train loss: 0.42770132422447205\n",
      "Epoch 49: train loss: 0.3659210503101349\n",
      "Epoch 49: train loss: 0.35231488943099976\n",
      "Epoch 49: train loss: 0.44303733110427856\n",
      "Epoch 49: train loss: 0.768909752368927\n",
      "Epoch 49: train loss: 0.39176374673843384\n",
      "Epoch 49: train loss: 0.3682090938091278\n",
      "Evaluations on training data\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " bad credit (0)      0.758     0.743     0.750      2045\n",
      "good credit (1)      0.730     0.744     0.737      1902\n",
      "\n",
      "       accuracy                          0.744      3947\n",
      "      macro avg      0.744     0.744     0.744      3947\n",
      "   weighted avg      0.744     0.744     0.744      3947\n",
      "\n",
      "Evaluations on testing data\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " bad credit (0)      0.776     0.746     0.760       511\n",
      "good credit (1)      0.738     0.769     0.753       476\n",
      "\n",
      "       accuracy                          0.757       987\n",
      "      macro avg      0.757     0.757     0.757       987\n",
      "   weighted avg      0.758     0.757     0.757       987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get a clf#\n",
    "torch.manual_seed(101)\n",
    "np.random.seed(1)\n",
    "random_state = check_random_state(10)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "d = dataset\n",
    "torch_model = proplace.train_clf(d.X1_train, d.y1_train, d.X1_test, d.y1_test, 20, epochs=50, data_name=\"heloc\", save_clf=False,\n",
    "                        load_clf=False)\n",
    "model = proplace.InnModel(dataset, torch_model, 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [02:00<00:00, 12.04s/it]\n",
      "100%|| 10/10 [00:59<00:00,  5.92s/it]\n"
     ]
    }
   ],
   "source": [
    "m2s = proplace.retrain_models(dataset, 20, 50) + proplace.retrain_models_leave_some_out(dataset, 20, 50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare for exps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from exputils import *\n",
    "clf = model\n",
    "test_xs_vals, test_xs, test_xs_carla, utildataset, nodes = get_test_data(model, m2s, dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Baselines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2437it [01:30, 26.93it/s]\n",
      "50it [00:22,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "1.0 >>> validity\n",
      "1.0 >>> robustness - M2 validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:07,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.008631857750211542 >>> robustness - delta validity, avg bound\n",
      "0.05655135967360235 >>> l1 cost\n",
      "1.0 >>> percentage of inliers dataset class 1 points\n",
      "1.0371449953252874 >>> avg lof dataset class 1 points\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ours\n",
    "rnnce_ces, treer, X_class1_clf_robust = run_rnnce(d, clf, nodes, utildataset, 0.025, test_xs_vals)\n",
    "proplace_ces = run_proplace(clf, nodes, utildataset, 0.025, treer, X_class1_clf_robust, test_xs_vals, k=23)\n",
    "proplace_scores = eval_ces(clf, m2s, proplace_ces, d, utildataset, test_xs_vals, 0.025)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "============================\n",
      "1.0 >>> validity\n",
      "0.491 >>> robustness - M2 validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:06,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 -1.2393089529414312 >>> robustness - delta validity, avg bound\n",
      "0.04541721560210278 >>> l1 cost\n",
      "0.96 >>> percentage of inliers dataset class 1 points\n",
      "1.1614613877646853 >>> avg lof dataset class 1 points\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wach_ces = run_wachter(clf, test_xs_carla)\n",
    "wach_scores = eval_ces(clf, m2s, wach_ces, d, utildataset, test_xs_vals,  delta=0.025)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [06:34,  7.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "1.0 >>> validity\n",
      "0.798 >>> robustness - M2 validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:06,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 -1.0424438425285794 >>> robustness - delta validity, avg bound\n",
      "0.037883652215162454 >>> l1 cost\n",
      "0.96 >>> percentage of inliers dataset class 1 points\n",
      "1.0979807426319854 >>> avg lof dataset class 1 points\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rbr_ces = run_rbr(clf, d, random_state, test_xs_vals)\n",
    "rbr_scores = eval_ces(clf, m2s, rbr_ces, d, utildataset, test_xs_vals, 0.025)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2437it [00:07, 342.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1492, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:02, 22.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "1.0 >>> validity\n",
      "1.0 >>> robustness - M2 validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:06,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 -0.15940037399372659 >>> robustness - delta validity, avg bound\n",
      "0.07321793284645818 >>> l1 cost\n",
      "1.0 >>> percentage of inliers dataset class 1 points\n",
      "1.0375535083833867 >>> avg lof dataset class 1 points\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "robx_ces = run_robx(clf, d, test_xs_vals)\n",
    "robx_scores = eval_ces(clf, m2s, robx_ces, d, utildataset, test_xs_vals, 0.025)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Start generating LIME coefficients [model.py get_counterfactuals]\n",
      "[INFO] Finished generating LIME coefficients [model.py get_counterfactuals]\n",
      "============================\n",
      "0.98 >>> validity\n",
      "0.9800000000000002 >>> robustness - M2 validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:06,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9795918367346939 2.490644636973457 >>> robustness - delta validity, avg bound\n",
      "0.10923561830902402 >>> l1 cost\n",
      "0.30612244897959184 >>> percentage of inliers dataset class 1 points\n",
      "1.5730714233034004 >>> avg lof dataset class 1 points\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "roar_params = {\n",
    "        \"lr\": 0.008,\n",
    "        \"lambda_\": 0.02,\n",
    "        \"delta_max\": 0.01,\n",
    "        \"norm\": 1,\n",
    "        \"t_max_min\": 3,\n",
    "        \"loss_type\": \"MSE\",\n",
    "        \"y_target\": [1],\n",
    "        \"binary_cat_features\": False,\n",
    "        \"loss_threshold\": 1e-3,\n",
    "        \"discretize\": False,\n",
    "        \"sample\": False,\n",
    "        \"lime_seed\": 0,\n",
    "        \"seed\": 0,\n",
    "    }\n",
    "roar_ces = run_roar(clf, test_xs_carla, roar_params)\n",
    "roar_scores = eval_ces(clf, m2s, roar_ces, d, utildataset, test_xs_vals, delta=0.025)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:59, 59.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [02:00, 60.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [03:02, 61.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [04:05, 62.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [05:10, 62.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [06:14, 63.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [07:15, 62.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [08:18, 62.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [09:17, 61.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [10:16, 60.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [11:18, 61.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [12:19, 61.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [13:21, 61.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [14:23, 61.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [15:25, 61.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [16:28, 61.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [17:31, 62.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [18:33, 62.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [19:35, 62.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [20:40, 62.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [21:42, 62.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [22:42, 61.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [23:44, 61.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [24:47, 62.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [25:50, 62.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [26:53, 62.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [27:55, 62.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [28:59, 62.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [30:03, 63.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [31:05, 63.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [32:09, 63.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [33:13, 63.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [34:18, 63.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [35:22, 63.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [36:24, 63.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [37:28, 63.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [38:29, 62.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [39:33, 63.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [40:37, 63.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [41:42, 63.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [42:43, 63.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [43:43, 62.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [44:44, 61.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [45:45, 61.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [46:47, 61.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [47:47, 61.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [48:48, 61.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [49:52, 62.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [50:57, 62.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n",
      "[WARNING] No encoder specified. Using k-d trees to represent class prototypes. [cfproto.py fit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [52:01, 62.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "1.0 >>> validity\n",
      "1.0 >>> robustness - M2 validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:06,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.6957160545189738 >>> robustness - delta validity, avg bound\n",
      "0.05713099042960892 >>> l1 cost\n",
      "0.92 >>> percentage of inliers dataset class 1 points\n",
      "1.2137494690524604 >>> avg lof dataset class 1 points\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "protor_ces = run_proto_r(clf, d, utildataset, test_xs_vals, nodes, delta_target=0.025)\n",
    "protor_scores = eval_ces(clf, m2s, protor_ces, d, utildataset, test_xs_vals, 0.025)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [01:59,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "1.0 >>> validity\n",
      "1.0 >>> robustness - M2 validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:06,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.27668403822021 >>> robustness - delta validity, avg bound\n",
      "0.043571706243953505 >>> l1 cost\n",
      "0.08 >>> percentage of inliers dataset class 1 points\n",
      "2.483606514151016 >>> avg lof dataset class 1 points\n",
      "============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "milpr_ces = run_milpr(clf, d, nodes, utildataset, 0.04, test_xs_vals)\n",
    "milpr_scores = eval_ces(clf, m2s, milpr_ces, d, utildataset, test_xs_vals, 0.025)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------------------+---------------+-------+-------------------+---------------+\n",
      "| name     |   validity |   delta validity |   M2 validity |    l1 |   %inlier class 1 |   lof class 1 |\n",
      "+==========+============+==================+===============+=======+===================+===============+\n",
      "| wach     |       1    |             0    |         0.491 | 0.045 |             0.96  |         1.161 |\n",
      "| rbr      |       1    |             0    |         0.798 | 0.038 |             0.96  |         1.098 |\n",
      "| robx     |       1    |             0.3  |         1     | 0.073 |             1     |         1.038 |\n",
      "| roar     |       0.98 |             0.98 |         0.98  | 0.109 |             0.306 |         1.573 |\n",
      "| proto-r  |       1    |             1    |         1     | 0.057 |             0.92  |         1.214 |\n",
      "| milp-r   |       1    |             1    |         1     | 0.044 |             0.08  |         2.484 |\n",
      "| proplace |       1    |             1    |         1     | 0.057 |             1     |         1.037 |\n",
      "+----------+------------+------------------+---------------+-------+-------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "# make table\n",
    "from tabulate import tabulate\n",
    "scores_names = [\"name\", \"validity\", \"delta validity\", \"M2 validity\", \"l1\", \"%inlier class 1\", \"lof class 1\"]\n",
    "scores_table = [scores_names,\n",
    "                np.concatenate((['wach'], np.round(wach_scores, 3))),\n",
    "                np.concatenate((['rbr'], np.round(rbr_scores, 3))),\n",
    "                np.concatenate((['robx'], np.round(robx_scores, 3))),\n",
    "                np.concatenate((['roar'], np.round(roar_scores, 3))),\n",
    "                np.concatenate((['proto-r'], np.round(protor_scores, 3))),\n",
    "                np.concatenate((['milp-r'], np.round(milpr_scores, 3))),\n",
    "                np.concatenate((['proplace'], np.round(proplace_scores, 3))), ]\n",
    "print(tabulate(scores_table, headers='firstrow', tablefmt='outline'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
